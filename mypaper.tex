% =============================================================
%  Document class
% =============================================================
\documentclass[lettersize,journal]{IEEEtran}

% =============================================================
%  Core math
% =============================================================
\usepackage{amsmath,amssymb,amsfonts,amsthm}      % one shot is enough
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{definition}{Definition}
\usepackage{mathtools}
\usepackage{caption}
\usepackage{subcaption}

\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\usepackage{amsthm}
% \newtheorem{definition}{Definition}[section] % section-wise numbering, optional
\newtheorem{subdefinition}{Definition}[definition] % will label as 4.1, 4.2, etc.
\newtheorem*{remark}{Remark}
\newtheorem{assumption}{Assumption}

% =============================================================
%  Lists
% =============================================================
\usepackage{enumitem}                             % nice enumerate/itemize
\setlist[enumerate,1]{label=(\roman*),leftmargin=10mm}

% =============================================================
%  Algorithms  ––  pick *one* family
% =============================================================
\usepackage[ruled,vlined,linesnumbered]{algorithm2e}   % ← you used this syntax
% If you ever switch to algorithm+algpseudocode, comment the line above and
% uncomment the two lines below, but never load both at once.
% \usepackage{algorithm}
% \usepackage{algpseudocode}

% =============================================================
%  Figures & graphics
% =============================================================
\usepackage{graphicx}
\usepackage{subfig}            
% IEEE-compliant sub-figures
\usepackage{tikz}
\usetikzlibrary{arrows.meta,positioning,calc}
\usepackage{pgfplots}
\pgfplotsset{compat=1.18}

% =============================================================
%  Tables
% =============================================================
\usepackage{array}
\usepackage{booktabs, multirow, tabularx}
\usepackage{threeparttable, tablefootnote}

% =============================================================
%  Misc utilities
% =============================================================
\usepackage{flushend}     % balance last page columns
\usepackage{placeins}     % \FloatBarrier
\usepackage{balance}
\usepackage{xcolor}
\usepackage{url}
\usepackage[colorlinks=true,citecolor=blue,linkcolor=blue]{hyperref} % keep LAST
\usepackage{float}
\usepackage{etoolbox}

% -------------------------------------------------------------
% End of preamble
% =============================================================

\begin{document}

% \title{  Risk-Bounded Intention-Aware Motion-Planning And Control Platform For Autonomous Vehicles}

\title{ Competitive  Algorithms for Online Risk-Bounded Motion Planning for Autonomous Driving}

\author{
Abdulrahman Ahmad,~\IEEEmembership{Graduate~Student~Member,~IEEE,}
Majid Khonji,~\IEEEmembership{Member,~IEEE,}~
Khaled Elbassioni,~\IEEEmembership{Member,~IEEE,}~
Jorge Dias,~\IEEEmembership{Senior~Member,~IEEE,}
Ameena S. Al-Sumaiti,~\IEEEmembership{Senior~Member,~IEEE}~
 
\thanks{This research was supported by Khalifa University under Award No.. Corresponding Author: Abdulrahman Ahmad.

Abdulrahman Ahmad  with the Department of Computer Science, Khalifa
University, Abu Dhabi, UAE. \{abdulrahman\_hamdy@ieee.org\}.

}}


 
% The paper headers
\markboth{IEEE TRANSACTIONS ON Vehicular Technology }%
{Shell \MakeLowercase{\textit{et al.}}: A Sample Article Using IEEEtran.cls for IEEE Journals}


% Remember, if you use this you must call \IEEEpubidadjcol in the second
% column for its text to clear the IEEEpubid mark.

\maketitle

\begin{abstract}
We address safe and efficient local motion planning for autonomous vehicles operating under environmental uncertainty, where decisions must be computed online. We formulate risk‑bounded motion planning as a multiple‑choice knapsack problem: a user‑specified risk budget serves as the knapsack capacity, and the arriving items are candidate trajectories from which the ego vehicle must select one at each planning cycle. Candidate trajectories are generated by solving a resource‑constrained shortest‑path problem parameterized by risk bounds. Building on this formulation, we propose three competitive online algorithms and analyze their competitive ratios, measuring their impact on planning performance. We evaluate the resulting planners in the CARLA simulator and ROS2, and test real‑time experiments on a full-scale autonomous vehicle. Across scenarios, the proposed approach improves driving efficiency while maintaining the prescribed safety budget throughout the mission.
\end{abstract}

\begin{IEEEkeywords}
Motion Planning, Autonomous Driving
\end{IEEEkeywords}


% \section{Introduction}
% intro

% --

% --

% --
% \subsection{Related Work}
% - add literature review table

% \subsection{Proposed System Overview}

% \subsection{Main Contributions}



%  \section{Introduction}

%  Planning safe and efficient decisions for autonomous vehicles (AVs), particularly in a dynamic traffic environment, is known to be computationally hard \cite{4568138}. The inherent uncertainty in the future behavior of other road users continues to pose a research challenge in planning and remains a prominent area of research \cite{gonzalez2015review}. Moreover, when operating within structured environments where prior knowledge permits probabilistic predictions of agent behaviors \cite{cui2019multimodal,rudenko2020human}, determining optimal decisions under safety constraints that bound the probability of safety violations remains a computationally challenging problem \cite{khonji2019approximability, 9292629}. 
%  Ensuring a high level of safety often requires conservative decision-making, such as adjusting speeds \cite{ahmad2024eco}, maintaining larger buffer zones around the vehicle, and being more cautious in complex or uncertain situations. On the other hand, efficiency refers to the vehicle’s ability to complete its journey in a timely manner, optimize routes to reduce travel time and fuel consumption, and make decisions that balance speed with smooth traffic flow. High efficiency generally requires that the vehicle be less conservative, allowing for faster driving speeds, faster lane changes, and more assertive maneuvers.
%  Practically, finding the optimal solution to such problems often requires approximation, resulting in a trade-off between safety and efficiency \cite{leurent2020safe, jiang2022efficient, 10422143}. 


% % \begin{table*}[t]
% %     \centering
% %         \caption{Proposed Method Compared with the Literature}
% %     \begin{tabular}{p{1.5cm}p{3cm}p{4cm}p{2cm}p{3cm}}
% %         \toprule
% %           Ref. & Graph-based & Path  Planning  &  Risk Bounded Planning& Online Approach  \\ \midrule

% %           \cite{gu2013focused, stahl2019multilayer}& \cmark State Lattice Graph&\cmark Shortest Path&\xmark&\cmark\\

% %           \cite{bae2021risk}& \cmark Lanes-based graph&\cmark Extended A*&\xmark&\cmark\\

% %           \cite{Huang_Hong_Hofmann_Williams_2021}&\xmark&\cmark CC-POMDP Maneuver-based&\cmark&\cmark\\

% %           \cite{9561745}&\xmark & \xmark  & \cmark & \xmark \\
% %           Ours& \cmark State Lattice Graph & \cmark Constrained Shortest Path &\cmark Multiple-choice Knapsack &\cmark Threshold-based online algorithm with theoretical guarantee \\
% %         \bottomrule
% %     \end{tabular}
% %     \label{tab:literature comparison}
% % \end{table*}


% Conformal lattices of parametric-curve-based solutions have demonstrated efficacy in continuous motion by generating curved trajectories that precisely follow vehicular kinematic constraints \cite{mcnaughton2011motion, meng2019decoupled}. Consequently, our methodology begins with a procedure for the construction of a state-lattice graph on the drivable area, as it accelerates the real-time planning process and facilitates continuous-time navigation.
% Previous works have established graphs in driving areas; for example, Gu et al. \cite{gu2013focused} introduced a two-stage motion planning framework for highway contexts that constructs a lattice graph followed by obstacle-free trajectory sampling. Similarly, Stahl et al. \cite{stahl2019multilayer} devised a state-lattice graph within a racing environment, allowing the AV to identify a collision-free local path in real-time while operating at elevated speeds. Furthermore, Bae et al. \cite{bae2021risk} proposed a lane-selection strategy that constructs a graph of potential lane positions and determines the optimal lane based on a cost function. Although these methods effectively utilize graphs over the drivable area, there is no balance between performance and safety requirements. To address this limitation, it is necessary to incorporate risk-bounded planning that explicitly sets a threshold for acceptable risk.


% \begin{figure}[t]
% \includegraphics[width=\linewidth]{Figures/solution structure.png}
% \centering
% \caption{The mission planning  is bounded by a risk budget $\Delta$. At each planning event, path candidates are generated by solving the constrained shortest path problem. An online algorithm then selects a candidate by solving  multiple-choice knapsack problem ensuring the capacity is not exceeded. }
% \label{fig sol arch}
% \end{figure}
% % The mission planning problem is constrained by a specified risk budget $\Delta$. At each planning event, a set of candidate solutions (paths) is generated by solving the constrained shortest path problem. Subsequently, an online algorithm addresses the online multiple-choice knapsack problem, ensuring that the selected candidate does not exceed the knapsack's capacity.

% Risk-bounded motion planning, which is a subcategory of motion planning, involves creating strategies that ensure vehicles operate within specified safety limits while optimizing performance objectives such as travel-time and fuel consumption \cite{ safaoui2024distributionally,RENGANATHAN2023103812}.
% This approach typically defines a risk tolerance, often represented by a probability threshold, which bounds the acceptable likelihood of safety violations (e.g., collisions or violations of traffic rules). One popular approach in literature is chance-constrained motion planning, which uses probabilistic models such as the partially observable Markov decision process to model uncertainties and compute the probability of collision, thus ensuring that the risk remains below a certain threshold \cite{theurkauf2023chance, alyassi2021approximate,khonji2019approximability}.


% Other techniques include Model Predictive Control (MPC), where a control strategy is optimized in real-time with risk constraints incorporated directly into the control problem \cite{ji2016path,liu2017path}. Moreover, other researchers combined chance-constrained optimization with MPC for risk-aware motion planning \cite{9006821,nakka2022trajectory}. Furthermore, reinforcement learning (RL) based methods \cite{alzubaidi2023emergency} have been extensively utilized in the literature for addressing the motion planning problem under environment uncertainty and safety conditions\cite{10207032, giuseppi2020chance}.
%  Nonetheless, this challenge is frequently addressed in an abstract manner, presupposing simplified environments and relying on offline solutions that assume comprehensive prior knowledge of the world. Additionally, the risk bound is often applied to individual real-time decisions rather than the entire mission, resulting in a deviation from the preferred driving style and an overly conservative approach.
 

% \color{black}
% Although the aforementioned works provided online motion planning frameworks, they do not provide a theoretical guarantee that the online solution is optimal or close to optimal with specific ratio. Moreover, there is a lack of proven guarantees that the AV will not violate the given risk budget for the entire mission which is crucial for safety. Therefore, there is a mandate for an online approach that besides solving the risk-bounded motion planning problems, to be certified that the online solution is near optimal with a competitive ratio, and the risk budget is not violated. \color{black} In contrast, this paper considers  online algorithms \cite{borodin2005online} that can provide proven worst-case guarantees from the offline optimal solution. Research in the domain of online algorithms addresses a specialized category of optimization and decision-making problems characterized by (i) the incremental disclosure of data over time, and (ii) the necessity for sequential, often irrevocable, decision making. This paradigm stands in contrast to offline optimization and decision-making, where all data is accessible from the outset, allowing the algorithm to optimize the solution with a complete knowledge of future information. Furthermore, online algorithms are employed across wide range of applications \cite{ghosh2010online, chau2017drive}. Consequently, we have incorporated online algorithms, leveraging their inherent characteristics to address the motion planning problem. To the best of our knowledge, this represents a novel application of competitive online algorithms to this specific motion planning problem. 

% % A comparison among methods in the literature is summarized and demonstrated in Table \ref{tab:literature comparison}.




%  % Recent advances in intelligent transportation systems (ITS), such as smart sensors, infrastructure, and smart traffic management, have significantly enhanced the information available to AVs. Consequently, modern approaches to motion planning are necessary. Several surveys, including \cite{teng2023motion, gonzalez2015review}, categorize motion planning methods into three main types: sample-based methods, graph-based methods, and optimization-based methods. This paper combines the latter two approaches. Additionally, learning-based methods and deep reinforcement learning have received substantial attention in the research community \cite{aradi2020survey}. Despite these advances, there remains considerable work to enable AVs to operate reliably in real-world scenarios and to effectively manage various sources of uncertainty \cite{xu2014motion}.


 
%  % \begin{itemize}
%  %     \item motion planning paragraph
%  %     \item challenge 1: non convexity
%  %     \item challenge 2: risk assessment
%  %     \item challenge 3: risk bounded safety and efficiency
%  %     \item the main contributions of this paper
%  %     \item the rest of the paper
     
%  % \end{itemize}


% \color{black}
% The main contributions of this study are as follows.

% \begin{itemize}

% \item  Constructing a state-lattice graph over the drivable area, wherein edges are characterized by smooth spiral paths that conform to the ego vehicle's kinematic constraints.
% \item A framework for the formulation of online risk-bounded planning and decision making for autonomous vehicles, which translates the problem into an online multiple choice knapsack problem. 
% \item A technique for generating candidate trajectories involves solving a constrained shortest path (CSP) problem  as an integer-linear program (ILP), which ensures rapid solution times. 
% \item A competitive online algorithm is introduced and implemented to address the online problem, offering a proven theoretical guarantee that is essential for developing near optimal solutions and for safety-critical applications, such as autonomous navigation.
% \end{itemize}










\section{Preliminaries and Background}
\subsection{Online vs. Offline Problems and Competitive Ratios}

In classical computer science, a fundamental distinction exists between \emph{offline} and \emph{online} problems. Offline problems assume full access to all inputs upfront, enabling globally optimal decisions. Online problems, in contrast, require decisions to be made incrementally as inputs are revealed over time, without knowledge of future input. This distinction is especially critical in autonomous systems, where decisions must be made in real time, under uncertainty and safety constraints.

\subsection{Risk-Bounded Motion Planning Framework}
\section{Problem Formulation}


% \subsection*{Nomenclature}
% \begin{table}[h!]
% \centering
% \renewcommand{\arraystretch}{1.3}
% \begin{tabular}{cl}

% \textbf{Symbol} & \textbf{Description} \\ 
% $\mathcal{S}$ & Set of states (nodes) in the lattice graph \\ 
% $s_i$ & Vehicle state node $i$ in the state lattice graph \\ 
% $(x_i, y_i)$ & Position coordinates of the vehicle at node $s_i$ \\ 
% $\theta_i$ & Orientation angle of the vehicle at node $s_i$ \\ 
% $\kappa_i$ & Curvature of the trajectory at node $s_i$ \\ 
% $\rho(s_i,s_j,t)$ & Instantaneous collision probability (risk)\\ & between states $s_i$ and $s_j$ at time $t$ \\ 
% $\tau$ & Vehicle trajectory (sequence of states/segments) \\ 
% $R(\tau)$ & Cumulative risk associated with trajectory $\tau$ \\ 
% $\Delta$ & Maximum allowed (budgeted) cumulative risk \\ 
% $\mathcal{A}_t$ & Set of candidate trajectory segments at epoch $t$ \\ 
% $\tau_{t,j}$ & The $j^{\text{th}}$ candidate trajectory segment at epoch $t$ \\ 
% $P(\tau_{t,j})$ & Progress (reward) function for segment $\tau_{t,j}$ \\ 
% $d_{\text{goal}}(s)$ & Distance remaining from state $s$ to the goal \\ 
% $T$ & Total number of planning epochs \\ 
% $N_t$ & Number of candidate trajectory segments at epoch $t$ \\ 
% $t_{ij}^{\text{start}}, t_{ij}^{\text{end}}$ & Start and end times of traversal from state $s_i$ to $s_j$ \\ 
% \end{tabular}
% \end{table}

\subsection{Environment and Vehicle Model}
\label{subsec:env_vehicle_model}

We represent the drivable environment by a layered state-lattice graph
\(
G=(V,E)
\),
constructed along a reference path over a high-definition (HD) map\cite{10821596}. 
The vertex set \(V\) is partitioned into layers 
\(
V=\bigcup_{\ell =0}^{L} V^{(\ell)}
\),
where each layer index $\ell$ encodes progression along the reference path.
Edges connect only adjacent layers, i.e.,
\(
E \subset \bigcup_{\ell=0}^{L-1} \bigl(V^{(\ell)} \times V^{(\ell+1)}\bigr),
\)
so that any path in \(G\) advances monotonically along the horizon.

Each vertex \(v\in V\) encodes a vehicle configuration
\(
q(v) \triangleq (x,y,\theta,\kappa)
\),
where \((x,y)\in\mathbb{R}^2\) is planar position, \(\theta\in\mathbb{R}\) is heading, and \(\kappa\in\mathbb{R}\) is curvature. 
Each directed edge \(e=(i,j)\in E\) denotes a precomputed motion primitive that maps \(q(i)\) to \(q(j)\). 
Motion primitives are constructed to be kinematically feasible and to remain within the drivable area; in particular, their curvature is uniformly bounded:
\(
|\kappa|\;\le\;\kappa_{\max},
\)
with \(\kappa_{\max}\) induced by steering limits. 
This graph abstraction enables systematic planning in a discrete space while preserving geometric and kinematic validity of each segment. Further details of lattice construction over HD maps are provided in~\cite{10821596}. Figure \ref{fig:lattice_graphs} presents the visualized representations of the graphs. 


% \paragraph*{Vehicle model}
The ego vehicle is modeled by the kinematic bicycle model, which captures the nonholonomic motion constraints while remaining computationally efficient for planning tasks~\cite{Rajamani2011, Werling2010}. 
Each motion primitive in \(E\) is generated (offline) compatible with the kinematic bicycle model. 


\begin{figure}[!h]
    \centering
    \subfloat[State-lattice graph on a five-lane road.]
    {
    \includegraphics[width=\linewidth]{Figures/graph road.pdf}
    \label{fig:roadgraph}
    }
    \hfill
    \subfloat[Constructed lattices across multiple driving scenarios in CARLA.]
    {
    \includegraphics[width=\linewidth]{Figures/scenarios graph2.png}\label{fig:scenarios}
    }
    \caption{Instances of layered state-lattice graphs.}
    \label{fig:lattice_graphs}
\end{figure}

% \subsection{Environment and Vehicle Modeling}

% We abstract the driving environment as a discretized \emph{layered state‐lattice graph} 
% \(\mathcal{G} = (\mathcal{V}, \mathcal{E})\)
% where \(V\) is the set of vertices and \(E\subset V\times V\) the set of directed edges.  Each vertex \(v_i\in V\) implicitly encodes a vehicle configuration \((x,y,\theta,\kappa)\), with \((x,y)\) denoting planar position, \(\theta\) the heading, and \(\kappa\) the curvature.  Edges \(e=(v_i,v_j)\in E\) correspond to motion primitives, kinematically feasible trajectories, from \(v_i\) to \(v_j\) that respect the vehicle’s curvature, steering, and velocity constraints.  This discrete graph representation enables systematic planning over the continuous state space while ensuring that each segment is dynamically valid. We refer to our previous work \cite{10821596} for the details of constructing the lattice graph along the drivable area in a high definition map given a reference path. Figure \ref{fig:lattice_graphs} shows visualized examples of state-lattice graph.
% % \begin{figure}[!ht]
% %     \centering
% %     \begin{subfigure}[b]{0.48\linewidth}
% %         \centering
% %         \includegraphics[width=\linewidth]{Figures/roadgraph.pdf}
% %         \caption{Example of a graph constructed along the drivable area on a 5-way road.}
% %         \label{fig:roadgraph}
% %     \end{subfigure}
% %     \hfill
% %     \begin{subfigure}[b]{0.48\linewidth}
% %         \centering
% %         \includegraphics[width=\linewidth]{Figures/scenarios graph2.png}
% %         \caption{Constructed lattice graphs over the drivable area for different scenarios in Carla Simulator.}
% %         \label{fig:scenarios}
% %     \end{subfigure}
% %     \caption{Examples of the constructed state-lattice graph: (a) along a 5-way road and (b) across multiple driving scenarios in Carla Simulator.}
% %     \label{fig:lattice_graphs}
% % \end{figure}
% \begin{figure}[!ht]
%     \centering
%     \subfloat[State‐lattice graph on a five-lane road.]
%     {\includegraphics[width=\linewidth]{Figures/roadgraph.pdf}\label{fig:roadgraph}}
%     \hfill
%     \subfloat[Constructed lattice graphs over the drivable area for different scenarios in Carla Simulator.]
%     {\includegraphics[width=\linewidth]{Figures/scenarios graph2.png}\label{fig:scenarios}}
%     \caption{Examples of the constructed state-lattice graph.}
%     \label{fig:lattice_graphs}
% \end{figure}

% On the other hand, the ego vehicle is represented using a kinematic bicycle model, which captures the nonholonomic motion constraints while remaining computationally efficient for planning tasks~\cite{Rajamani2011, Werling2010}.





\subsection{Risk Assessment Model}

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{Figures/risk.png}
    \caption{Example for the risk assessment values for traversing each edge (1:5) with speed (5:40) km/hr.}
    \label{fig:placeholder}
\end{figure}
The risk measure $r_{i,j}^\nu$ captures the probability of collision or unsafe interaction during traversal of an edge $(i,j)$ with speed $\nu \in \mathcal{V}$, in the graph which is a problem studied in the literature as in \cite{6224727, 10821596} for static and dynamic obstacles respectively. So, risk $r: (i,j,\nu )\rightarrow \mathrm{Pr}[collision]\; \; \forall(i,j)\in E, \; \forall \nu \in \mathcal{V}$.  We then abstract the risk of a local trajectory candidate  with a cumulative risk function \(R(\tau)\).
\begin{definition}[Risk Trajectory Function]
The risk of a trajectory as the total accumulated risk incurred during planning along the trajectory segments (graph edges). Let \(\tau = \{(i_0, i_1), (i_1, i_2), \dots, (i_{n-1}, i_n)\}\) denote a trajectory composed of consecutive segments. Then the risk of \(\tau\) is given by
\begin{equation}
    R(\tau) = \bigcup_{(i, {i+1}) \in \tau} r\left({i,\; i+1}\right) \leq \sum_{(i, \;{i+1}) \in \tau} r\left({i,\; i+1}\right)\,
\end{equation}
\end{definition}

\noindent where \(r\left({i,\; i+1}\right)\) denotes the risk contribution of segment \((i,\ {i+1})\). 
This Boole's inequality is considered an upper bound for risk along the trajectory $\tau$.  

\begin{definition}[Risk-Bounded Trajectory]
\label{def: risk-bounded-trajectory}
A trajectory \(\tau\) is said to be \emph{risk-bounded} if its risk trajectory function does not exceed a predefined risk budget \(\Delta\). Formally, $R(\tau) \leq \Delta$.
% \begin{equation}
%     \label{eqn: risk-bounded trajectory}
%     R(\tau) \leq \Delta,
% \end{equation}
where  \(\Delta > 0\) is the maximum allowable risk threshold.
\end{definition}
This risk constraint ensures that the planned motion remains within acceptable safety margins while allowing flexibility for efficient decision-making under uncertainty.


% \subsection{Generation of Candidate Trajectories}
% The method used to avoid obstacles is by selecting one of  the generated local candidate trajectories for overtaking the obstacle and this selection is done through the online algorithm. We show here in this subsection how the candidates are generated through  solving the constrained shortest-path (CSP) problem with different samples of risk bounds $\delta_m \text{ where }  m \in \{1,\dots, M\}$ that are sampled from the risk budget $\Delta$ so We get out of it the minimized cost trajectories in terms edges and associated velocity $\nu \in \mathcal{V}$.  We define the planning horizon as the planned path to from starting node to a subgoal node.  We define the subgoal node ahead of the obstacle that needed to be overtaken, that subgoal point $v_{g}$ that lies on the reference path.

% \begin{figure}
%     \centering
%     \includegraphics[width=1\linewidth]{Figures/planning horizon.pdf}
%     \caption{Enter Caption}
%     \label{fig:placeholder}
% \end{figure}
% \begin{equation}\label{eq:CSP}
% \begin{aligned}
% {\text{CSP}(\delta_{m})} &~~\underset{x^\nu_{ij}} {\text{min}} \sum_{(i,j)\in E}~ \sum _{{\nu \in \mathcal{V}}} {x}^\nu_{ij} c_{ij}^\nu \\
% & \quad\textbf{s.t.}
% \end{aligned}
% \end{equation}
% % \vspace{-2 cm}
% \begin{subequations}\label{eq:rbcspcsp_constraints}
% \begin{align}
% & \sum_{(i,j)\in E} \hspace{-2mm}x^\nu_{ij} - \hspace{-3mm}\sum_{(j,i)\in E} \hspace{-2mm}x^\nu_{ji} = 0,~~ \forall i,j \notin \{v_s,v_g\}, \forall \nu \in \mathcal{V}\label{eq:rbcsp flow_constraints1}\\
%  &\sum_{(v_s,j) \in E }x^\nu_{v_s\,j} = 1,~~ \sum_{(i,v_g) \in E}
%  x^\nu_{i\,v_g} = 1, ~~\forall \nu \in \mathcal{V}
%  \label{eq:rbcsp flow_constraints2}\\
% &\sum _{(i,j)\in E} \sum _{{\nu \in \mathcal{V}}} x_{ij}^\nu R_{ij}^\nu \leq \delta_{m}\label{eq:rbcsp risk constraint}\\
% & x_{ij}^\nu \in \{0,1\} ~~~\forall (i,j)\in E , ~~~ \nu \in \mathcal{V}
% \end{align}
% \end{subequations}


% Constraints~\eqref{eq:rbcsp flow_constraints1}–\eqref{eq:rbcsp flow_constraints2} enforce flow conservation and ensure that each generated trajectory connects the designated start node \(v_s\) to the goal node \(v_g\) through exactly one edge per layer. The risk constraint~\eqref{eq:rbcsp risk constraint} guarantees that the cumulative risk along the chosen trajectory does not exceed \(\delta_\). The binary constraint ensures discrete path selection. By varying \(\Delta_b\), this CSP can generate a diverse candidate set of risk-feasible trajectories for use in the online selection stage.






\subsection{Generation of Candidate Trajectories}

Obstacle avoidance is achieved by selecting, \emph{online}, one trajectory from a pool of generated local candidates that overtake the detected obstacle. This subsection details the \emph{online} generation of candidates. Each candidate is obtained as the optimal solution of a \emph{constrained shortest-path} (CSP) problem parameterized by a risk bound \(\delta_n \in \{\delta_1,\dots,\delta_N\}\), where the bounds are sampled from the overall risk budget \(\Delta\).

Let the current vehicle pose is mapped to the start node \(v_s\in V\), and the \emph{subgoal} \(v_g\in V\) is chosen ahead of the obstacle along the reference path within the planning horizon as shown in Figure \ref{fig:planning_horizon}. Each edge \((i,j)\in E\) admits a discrete set of velocity levels \(\nu\in\mathcal{V}\). We associate a traversal cost \(c_{ij}^{\nu}> 0\) and a risk contribution \(r_{ij}^{\nu}> 0\) to using edge \((i,j)\) at velocity label \(\nu\). The binary decision variable \(x_{ij}^{\nu}\in\{0,1\}\) indicates whether edge \((i,j)\) is selected with velocity \(\nu\).

\begin{figure}[!h]
    \centering
    \includegraphics[width=\linewidth]{Figures/planning horizon.pdf}
    \caption{Planning horizon from start node \(v_s\) to subgoal \(v_g\) on the reference path, defined ahead of the obstacle to be overtaken.}
    \label{fig:planning_horizon}
\end{figure}

For a given risk bound \(\delta_n\), the candidate trajectory is obtained by solving
\begin{equation}
\label{eq:csp}
\begin{aligned}
\text{CSP}(\delta_n):\quad
&\underset{x_{ij}^{\nu}}{\text{minimize}}
& & \sum_{(i,j)\in E}\sum_{\nu\in\mathcal{V}} x_{ij}^{\nu}\, c_{ij}^{\nu} \\
&\text{subject to}
& & \text{constraints \eqref{eq:flow_conservation}--\eqref{eq:binary}}~,
\end{aligned}
\end{equation}
with the following constraints:
\begin{subequations}
\label{eq:csp_constraints}
\begin{align}
&\sum_{\nu\in\mathcal{V}}\!\!\left(\sum_{(k,j)\in E} x_{kj}^{\nu} - \sum_{(i,k)\in E} x_{ik}^{\nu}\right) =
\begin{cases}
\;\;\;1, & k=v_s,\\
-1, & k=v_g,\\
\;\;\;0, & \text{otherwise},
\end{cases}
\label{eq:flow_conservation}\\[1mm]
&\sum_{(i,j)\in E}\ \ \sum_{\nu\in\mathcal{V}} x_{ij}^{\nu}\, r_{ij}^{\nu} \;\le\; \delta_n,
\label{eq:risk_bound}\\[1mm]
% &\sum_{\nu\in\mathcal{V}} x_{ij}^{\nu} \;\le\; 1, \qquad \forall (i,j)\in E,
% \label{eq:unique_velocity}\\[1mm]
&x_{ij}^{\nu} \in \{0,1\}, \qquad \forall (i,j)\in E,~\forall \nu\in\mathcal{V}.
\label{eq:binary}
\end{align}
\end{subequations}

Constraint~\eqref{eq:flow_conservation} enforces unit \(v_s\!-\!v_g\) flow: one unit of flow departs \(v_s\), one arrives at \(v_g\), and flow is conserved at all other nodes. The risk constraint~\eqref{eq:risk_bound} bounds the cumulative risk along the selected trajectory by \(\delta_n\). 
% Constraint~\eqref{eq:unique_velocity} prevents assigning multiple velocity labels to the same edge, 
Constraint \eqref{eq:binary} ensures discrete selection. Under nonnegative costs, the solution is a simple \(v_s\!\to\!v_g\) trajectory. 

By solving \(\text{CSP}(\delta_n)\) for \(n=1,\dots,N\), we obtain a diverse set of risk-feasible, minimum-cost trajectories over the planning horizon. This set constitutes the candidate pool used by the online selector to execute safe and efficient overtakes.

\subsection{Online Risk-Bounded Motion Planning}
\label{subsec:online_rbmp}

As introduced in Definition~\ref{def: risk-bounded-trajectory}, a trajectory is \emph{risk-bounded} if its cumulative risk does not exceed the mission-level budget \(\Delta>0\). In autonomous navigation, planning is inherently sequential and reactive: the environment and predictions evolve, and the planner must make irrevocable decisions with partial information. The central challenge is to select, \emph{online}, a sequence of actions that jointly respects the global risk budget while maintaining high performance.

We cast this setting as an online selection problem over candidate trajectories revealed at discrete replanning events.

\begin{definition}[Decision Epoch]
A \emph{decision epoch} is a time instant that triggers replanning due to changes in sensing, predictions, or task requirements. Let \(\mathcal{T} \triangleq \{1,2,\dots,T\}\) denote the (finite) index set of decision epochs during a mission, where \(T\) may be unknown a priori.
\end{definition}

\begin{definition}[Candidate Set at Epoch \(t\)]
At decision epoch \(t\in\mathcal{T}\), the planner constructs a finite \emph{candidate set}
\[
\mathcal{A}_t \;=\; \{\tau_{t,1},\ldots,\tau_{t,N_t}\},
\]
where each \(\tau_{t,n}\) is a dynamically feasible trajectory generated by solving the CSP problem from the current vertex \(v_t\) to the goal vertex \(v_g\), satisfying vehicle and environmental constraints.
\end{definition}

Each candidate \(\tau_{t,n}\) can be represented as a finite sequence of labeled edges associated with velocity
\[
\tau_{t,n} \;=\; \Bigl(\bigl((v_t,v_{t+1}),\nu_t)\bigr),\ldots,\bigl((v_{g-1},v_g),\nu_{g-1}\bigr)\Bigr),
\]
with per-edge cost \(c_{ij}^\nu > 0\) (e.g., time cost) and per-edge risk contribution \(r_{ij}^\nu > 0\). The \emph{trajectory cost} and \emph{trajectory risk} are
\begin{equation}
C(\tau_{t,n}) \;=\; \sum_{(i,j,\nu)\in\tau_{t,n}} c_{ij}^{\nu}, 
\quad
R(\tau_{t,n}) \;=\; \sum_{(i,j,\nu)\in\tau_{t,n}} r_{ij}^{\nu}.
\label{eq:path_cost_risk}
\end{equation}

\begin{definition}[Trajectory Utility]
The \emph{utility} of \(\tau_{t,n}\) is a scalar \(U(\tau_{t,n})\in\mathbb{R}\) to be maximized. A common choice in time-optimal planning is
\begin{equation}
U(\tau_{t,n})\;=\; \sum_{(i,j,\nu)\in\tau_{t,n}} M-c_{ij}^{\nu},
\label{eq:utility_negative_cost}
\end{equation}
where \(M > 2\cdot\max(c_{ij}^\nu), \ \forall (i,j)\in E, \ \forall \nu \in \mathcal{V}\), is constant positive value,
so that maximizing utility is equivalent to minimizing travel cost. When a nonnegative profit is required.
\end{definition}

% \paragraph*{Online Information Pattern and Budget Evolution}
% Let \(B_1 \triangleq \Delta\) denote the initial remaining risk budget. At epoch \(t\), the planner observes \(\mathcal{A}_t\) and, for each \(\tau_{t,j}\in\mathcal{A}_t\), its utility \(u_{t,j}\triangleq u(\tau_{t,j})\) and risk \(r_{t,j}\triangleq r(\tau_{t,j})\). The planner must immediately and irrevocably select exactly one candidate whose risk fits within the remaining budget,
% \begin{equation}
% \mathcal{F}_t(B_t) \;\triangleq\; \bigl\{\,\tau_{t,j}\in\mathcal{A}_t \;:\; r_{t,j}\le B_t \,\bigr\},
% \qquad \mathcal{F}_t(B_t)\neq\varnothing,
% \label{eq:feasible_epoch}
% \end{equation}
% and then update the remaining budget according to
% \begin{equation}
% B_{t+1} \;=\; B_t \;-\; r_{t,j_t},
% \qquad t=1,\ldots,T,
% \label{eq:budget_update}
% \end{equation}
% where \(j_t\) is the index of the selected candidate at epoch \(t\). A (causal) \emph{policy} is a sequence of mappings \(\pi_t:\bigl(\mathcal{A}_1,\ldots,\mathcal{A}_t,B_t\bigr)\mapsto j_t\).

% \paragraph*{Optimization View (Offline Proxy)}
% For exposition, the online objective can be written as the following offline proxy:
% \begin{equation}
% \label{eq:offline_proxy}
% \begin{aligned}
% \max_{\{y_{t,j}\}} \;\;& \sum_{t=1}^{T}\sum_{j=1}^{N_t} y_{t,j}\, u_{t,j} \\
% \text{s.t.}\;\;& \sum_{t=1}^{T}\sum_{j=1}^{N_t} y_{t,j}\, r_{t,j} \;\le\; \Delta, \\
% & \sum_{j=1}^{N_t} y_{t,j} = 1, \quad t=1,\ldots,T, \\
% & y_{t,j}\in\{0,1\}, \quad j=1,\ldots,N_t,~ t=1,\ldots,T,
% \end{aligned}
% \end{equation}
% where \(y_{t,j}=1\) indicates that \(\tau_{t,j}\) is selected at epoch \(t\). In the true online problem, the decision \(y_{t,\cdot}\) must be taken using only \((\mathcal{A}_1,\ldots,\mathcal{A}_t,B_t)\), i.e., without access to \(\{\mathcal{A}_{s}\}_{s>t}\).

% \paragraph*{Connection to ON-MCKP}
% Problem~\eqref{eq:offline_proxy} is a \emph{multiple-choice knapsack problem} (MCKP): each epoch \(t\) defines a group of items \(\{\tau_{t,1},\ldots,\tau_{t,N_t}\}\), each item has profit \(u_{t,j}\) and weight \(r_{t,j}\), we must pick exactly one item per group, and the total weight cannot exceed \(\Delta\). Our setting is \emph{online}: groups arrive sequentially, and each choice is irrevocable, yielding an \emph{online MCKP (ON-MCKP)} abstraction tailored to risk-bounded motion planning. The next subsection develops an online selection policy under this model.




% \subsection{Online Risk-Bounded Motion Planning}

% As mentioned in Definition \ref{def: risk-bounded-trajectory}, a trajectory is said to be \emph{risk-bounded} if its cumulative risk does not exceed a predefined mission-level budget \(\Delta\). In practice, however, autonomous navigation is a sequential and reactive process: the planner continuously makes decisions based on partial, evolving information about the environment. This setting introduces a fundamental challenge—how to make \emph{irrevocable, online decisions} that collectively respect a global risk constraint over time.

 
% To address this, we formulate the problem as an online risk-bounded motion planning problem. At each decision epoch, the planner selects one trajectory from a candidate set, consuming part of the risk budget, and earning a reward in terms of utility. The planner does not have access to future candidates or risk values in advance, and must make each selection immediately and irrevocably.
% To enable a formal problem formulation, we first define the key building blocks that structure the online decision-making process.

% \begin{definition}[Decision Epoch]
% A \emph{decision epoch} is a time instant 
% that occurs whenever the environment changes sufficiently to trigger a replanning event.  Formally, the set of decision epochs is denoted as \( t \in \{1, 2, \dots, T\} \) index the sequence of such replanning epochs during the mission.

% \end{definition}

% \begin{definition}[Candidate Set at Epoch $t$]
% At each decision epoch \(t\), the planner constructs a \emph{candidate set} \(\mathcal{A}_t\), defined as the set of dynamically feasible trajectories that originate from the current vertex \(v_t\) and terminate at the goal vertex \(v_g\):
% \begin{equation}
%     \mathcal{A}_t = \{\tau_{t,1}, \tau_{t,2}, \dots, \tau_{t,N_t}\},
% \end{equation}
% where each trajectory \(\tau_{t,j}\) is a complete path from \(v_t\) to \(v_g\) satisfying vehicle dynamics and environmental constraints.
% \end{definition}

% These candidates are typically generated during a replanning event, when changes in the environment or predictions require selecting a new path to the goal.

% \begin{definition}[Trajectory Utility Function]
% We define the \emph{utility} of a trajectory as the objective value to be maximized during planning. Let \(\tau = \{(v_0, v_1), (v_1, v_2), \dots, (v_{n-1}, v_n)\}\) denote a trajectory composed of consecutive segments. Then the utility of \(\tau\) is given by
% \begin{equation}
%     u(\tau) = \sum_{(v_i, v_{i+1}) \in \tau} u(v_i, v_{i+1}),
% \end{equation}
% where \(u(v_i, v_{i+1})\) is the utility contribution of the individual segment \((v_i, v_{i+1})\).
% \end{definition}

% This segment-level utility can be instantiated in different ways depending on the planning context. In the context of autonomous robots, the utility can be defined as the amount of saved time and we do this by defining the utility as follows
%  \[
% u(v_i, v_{i+1}) = M - c(v_i, v_{i+1})
% \]
% OR
% \[
% u_{ij}^\nu = M - c_{ij}^\nu
% \]
% where $M$ is a big constant that is larger than the maximum value of $c$ to make it always positive. 

% The preceding definitions establish the structural components required to formulate the online risk-bounded motion planning problem. At each decision epoch, the planner must select a single trajectory from the candidate set that offers high utility while consuming part of the remaining risk budget. Importantly, these decisions are made without knowledge of future candidates, utilities, or risks. This inherently sequential and constrained selection process motivates our formulation of the problem as an instance of the Online Multiple-Choice Knapsack Problem (ON-MCKP), which we introduce in the following subsection.









\subsection{Online Multiple-Choice Knapsack Formulation}
We reduce the ORB motion planning problem into an online multiple-choice knapsack problem (ON-MCKP).   In our setting, risk-bounded motion planning is naturally an online problem. At each decision epoch \(t\in \mathcal{T}\), the ego vehicle must select one trajectory from the candidate set \(\mathcal{A}_t\), which is generated in response to the current environment and vehicle state. This choice is irrevocable and must be made without access to future candidate sets. Each selected trajectory \(\tau_{t,n}\in \mathcal{A}_t\) yields a utility \(U(\tau_{t,n})\), while consuming a risk portion \(R({\tau_{t,n}})\) of the mission-level risk budget \(\Delta\). The central challenge is to maximize cumulative utility over all decision epochs, without exceeding this budget.

This sequential, constrained selection problem aligns precisely with the \emph{ON-MCKP}. The reduction from motion planning to ON-MCKP is summarized as follows:

\begin{itemize}
    \item \textbf{Knapsack capacity:} the mission-level risk budget \(\Delta\).
    \item \textbf{Knapsack items:} the candidate trajectories sets \(\mathcal{A}_1, \mathcal{A}_2, \dots, \mathcal{A}_T\), revealed one epoch at a time.
    \item \textbf{Items in each class:} individual trajectories \(\tau_{t,j} \in \mathcal{A}_t\).
    \item \textbf{Value of an item \(\tau_{t,j}\):}  \(U(\tau_{t,n})\).
    \item \textbf{Weight of an item \(\tau_{t,j}\):} \(R(\tau_{t,j})\).
\end{itemize}

In the classical \emph{offline} MCKP, all candidate sets \(\mathcal{A}\triangleq \{\mathcal{A}_1, \dots, \mathcal{A}_T\}\) are known in advance, and commercial solvers can optimize globally over all choices. In contrast, the \emph{online} variant (ON-MCKP) models our setting precisely: candidate sets arrive sequentially, and the planner must commit to a choice from \(\mathcal{A}_t\) without knowledge of future sets \(\mathcal{A}_{t+1}, \mathcal{A}_{t+2}, \dots\)

\begin{equation}
\label{eq:offline_proxy}
\begin{aligned}
\max_{y_{t,n}} \;\;& \sum_{t=1}^{T}\sum_{n=1}^{N_t} y_{t,n}\, U({\tau _{t,n})} \\
\text{s.t.}\;\;& \sum_{t=1}^{T}\sum_{n=1}^{N_t} y_{t,n}\, R(\tau_{t,n}) \;\le\; \Delta, \\
& \sum_{n=1}^{N_t} y_{t,n} = 1, \quad t=1,\ldots,T, \\
& y_{t,n}\in\{0,1\}, \quad n=1,\ldots,N_t,~ t=1,\ldots,T,
\end{aligned}
\end{equation}
where \(y_{t,n}=1\) indicates that \(\tau_{t,j}\) is selected at epoch \(t\). In the true online problem, the decision \(y_{t,\cdot}\) must be taken using only \((\mathcal{A}_1,\ldots,\mathcal{A}_t)\), i.e., without access to \(\{\mathcal{A}_{s}\}_{s>t}\).

In the next Section, we present the online algorithms for solving the ON-MCKP with provable competitive guarantees.

% \subsection{Offline Risk-Bounded Motion Planning}
% The \emph{offline} setting provides the globally optimal solution against which
% our online algorithms are compared.  Here the complete sequence of candidate
% trajectory sets
% \(
% \mathcal{M}\triangleq\{\mathcal{A}_1,\mathcal{A}_2,\dots,\mathcal{A}_T\}
% \)
% is known a priori, along with perfect future obstacle information.  Selecting
% exactly one segment per decision epoch reduces to a
% \textbf{Multiple-Choice Knapsack Problem (MCKP)} with global risk budget
% \(\Delta\).

% Let the binary decision variable \(X_{rt}\in\{0,1\}\) indicate whether
% candidate segment \(\tau_{t,r}\in\mathcal{A}_t\) is chosen.
% Each segment is characterised by

% \[
% \text{progress}\;P_{rt}=P(\tau_{t,r}),\qquad
% \text{risk}\;R_{rt}=R(\tau_{t,r}).
% \]

% \begin{align}
% \textbf{(MCKP)}\qquad
% \max_{X_{rt}}\; & \sum_{t=1}^{T}\sum_{r=1}^{N_t} X_{rt}\,P_{rt} \\[6pt]
% \text{s.t.}\quad &
% \sum_{t=1}^{T}\sum_{r=1}^{N_t} X_{rt}\,R_{rt} \;\le\; \Delta, \label{eq:offline_budget}\\[4pt]
% & \sum_{r=1}^{N_t} X_{rt} \;=\; 1,\qquad \forall\,t=1,\dots,T, \\[4pt]
% & X_{rt}\in\{0,1\},\qquad \forall\,t,r.
% \end{align}

% \paragraph*{Optimal offline value.}
% The optimal objective value of (MCKP) is denoted
% \(\text{OPT}(\mathcal{M})\) and serves as the benchmark in our
% competitive-ratio analysis:

% \[
% \text{CR}(\text{ALG}) \;=\;
% \sup_{\mathcal{M}}\,
% \frac{\text{OPT}(\mathcal{M})}{A_{\text{ALG}}(\mathcal{M})}\;\ge 1.
% \]



%===============================================================
\section{Proposed Solution Algorithms}
Having formulated the risk-bounded planning problem as an instance of the ON-MCKP, we now propose competitive online algorithms that address the challenge of sequential, irrevocable decision-making under uncertainty of future inputs. 
% We consider three algorithmic approaches, each building on the previous to introduce increasingly sophisticated decision logic.
% \begin{itemize}
%     \item \textbf{Threshold-Based Online Algorithm:} A classical budget-aware strategy that accepts trajectory segments only if their utility-to-risk ratio exceeds an adaptive threshold.
%     \item \textbf{Integrated Threshold MILP:} A tighter formulation that embeds the online threshold rule directly into a mixed-integer optimization problem, enabling joint selection of risk and trajectory.
%     \item \textbf{Succinct Prediction-Augmented Planning (SPAP):} A learning-augmented extension that incorporates lightweight predictions to improve consistency and performance while retaining competitive guarantees.
% \end{itemize}
Each method is analyzed with respect to its competitive ratio and practical suitability for real-time deployment. In what follows, we describe each approach in detail.
%===============================================================
\subsection{\textbf{CZL-ORB}: Threshold Algorithm for Online Risk-Bounded Planning}
\label{sec:czl}

To address the ON-MCKP in the context of online decision-making for autonomous driving under risk constraints, we start by adapting a threshold-based algorithm originally introduced by Chakrabarty et. al (CZL)~\cite{chakrabarty2010online}. We refer to our adapted version as \emph{CZL-ORB} (CZL for Online Risk-Bounded planning). 
This method guarantees a logarithmic competitive ratio under mild assumptions about the bounds on the utility-to-risk ratios of candidate trajectories. 

\subsubsection{Algorithm Description}

As presented in Algorithm \ref{alg:CZL}, at each decision epoch \(t\), the planner observes a set of candidate trajectories
\(\mathcal{A}_t = \{\tau_{t,1}, \dots, \tau_{t,N_t}\}\).  Each \(\tau\in\mathcal{A}_t\)
is associated with a utility \(U(\tau)\) and risk \(R(\tau)\), and we write
\(
\rho(\tau)\;=\;\frac{U(\tau)}{R(\tau)}
\)
for its utility–to–risk ratio.  Let \(\Delta_0\) be the total mission risk budget,
and \(\Delta_t\) the remaining budget at epoch \(t\).  Define the fraction of
budget used as
\(
z \;=\; 1 - \frac{\Delta_t}{\Delta_0}\,,
\)
and compute the threshold
\[
\Psi_{czl} \;=\;\Bigl(\tfrac{\rho_{\max}e}{\rho_{\min}}\Bigr)^{z}\,\frac{\rho_{\min}}{e}\,.
\]
The algorithm filters the feasible set
and, selects the one with the maximum utility.
 Otherwise it returns \texttt{None}.  This irrevocable choice ensures that
the cumulative risk never exceeds \(\Delta_0\), while the threshold
\(\Psi_{czl}\) adapts dynamically to the fraction of budget already spent.
\bigskip

\subsubsection{Algorithm Assumptions}
\begin{assumption}[Bounded Utility-to-Risk Ratios] \label{asm:bounded-ratio}
    There exist constants $\rho_{\min}, \rho_{\max} > 0$ such that for all trajectories $\tau$:
    \[
    \rho_{\min} \leq \rho(\tau) \leq \rho_{\max},
    \] And these bounds are small compared with the total risk budget.
\end{assumption}
\begin{assumption}[Fixed Risk Budget]
The mission begins with a total risk budget \(\Delta_0 > 0\), which cannot be exceeded. At each decision epoch \(t\), the remaining budget is denoted by \(\Delta_t\).
\end{assumption}
\begin{assumption}[Small Risk Increments] \label{asm:small-risk}
    For all trajectories $\tau \in \bigcup_t \mathcal{A}_t$, the risk satisfies:
    \[
    R(\tau) \leq \epsilon \Delta_0 \quad (\text{for } \epsilon \ll 1),
    \]
    where $\Delta_0$ is the total risk budget. This implies no single trajectory consumes significant budget.
\end{assumption}




\begin{algorithm}[!t]
\caption{(CZL-ORB)Threshold Online Algorithm}
\label{alg:CZL}
\DontPrintSemicolon
\KwIn{Candidate set \(\mathcal{A}_t = \{\tau_{t,1}, \dots, \tau_{t,N_t}\}\), current risk budget \(\Delta_t\), utility-to-risk bounds \(\rho_{\min}, \rho_{\max}\), total budget \(\Delta_0\)}
\KwOut{Selected trajectory \(\tau_{t,n_t} \in \mathcal{A}_t\), or \texttt{None}}
\BlankLine

Compute consumed budget fraction: \quad \(z \gets 1 - \frac{\Delta_t}{\Delta_0}\)\;

Compute threshold: \quad
\(\Psi_{czl}(t) \gets \left( \frac{\rho_{\max} e}{\rho_{\min}} \right)^z \cdot \frac{\rho_{\min}}{e}\)\;

Filter feasible set:
\[
\mathcal{F}_t \gets \left\{ \tau_t \in \mathcal{A}_t \;\middle|\;
    R(\tau_t) \leq \Delta_t \wedge\; \rho(\tau_t) \geq \Psi_{czl}(t)
\right\}
\]

\uIf{\(\mathcal{F}_t = \varnothing\)}{
    \KwRet \texttt{None} \tcp*{No valid trajectory satisfies threshold}
}
\Else{
    \(\tau_{t,n_t} \gets \arg\max_{\tau_t \in \mathcal{F}_t} \rho(\tau_t)\)\;
    \KwRet \(\tau_{t,n_t}\)
}
\end{algorithm}

\subsubsection{Competitive Ratio Guarantee}

\begin{theorem}
\label{thm:czl_cr}
Let \(\rho_{\min}, \rho_{\max} > 0\) be bounds on the utility-to-risk ratios of all feasible trajectories. Then CZL-ORB achieves a competitive ratio of
\[
\boxed{
\text{CR}_{\text{czl}} \leq \ln\left( \frac{\rho_{\max}}{\rho_{\min}} \right) + 2
}
\]
That is, for any input sequence \(\mathcal{A}\),
\[
U_{\text{{czl}}}(\mathcal{A}) \geq \frac{U_{\text{OPT}}(\mathcal{A})}{\ln\left(\frac{\rho_{\max}}{\rho_{\min}}\right) + 2}.
\]
\end{theorem}
The proof is discussed in Appendix \ref{sec: proof of czl}. 
%===============================================================


%===============================================================








\subsection{\textbf{BAT-ORB}: Budget-Aware Threshold Algorithm for Online Risk-Bounded Planning}
\label{sec:bat-orb}

The \emph{Budget-Aware Threshold Algorithm for Online Risk-Bounded Planning} (BAT-ORB) is a lightweight competitive online planner similar to CZL-ORB Algorithm \ref{alg:CZL} with a different threshold function  enabling aggressive selections when sufficient budget remains and more conservative decisions as the budget is spent.

\subsubsection{Algorithm Description}

As presented in Algorithm \ref{alg:BATS}, at epoch \(t\), let \(\mathcal{A}_t\) be the set of candidate trajectories, each \(\tau\) characterized by utility \(U(\tau)\) and risk \(R(\tau)\).  Denote by \(\Delta_t\) the remaining risk budget before selection.  BAT-ORB computes the threshold in terms of \(\Delta_t\).  Then, it defines the feasible set and, selects the one
with the maximum utility. Otherwise it returns None. This rule ensures that selections become strictly harder as the budget \(\Delta_t\) decreases, while still capturing high-utility options early.  


%---------------------------------------------------------------
\subsubsection{Algorithm Assumptions}
%---------------------------------------------------------------
\begin{assumption}[Lower‐Bounded Risk]
\label{assump lbr}
There exists $\delta_{\min}>0$ such that for every trajectory $\tau$,
\[
\delta_{\min}\;\le\;R(\tau).
\]
This holds in practice due to finite‐precision risk computations.
\end{assumption}

% \begin{assumption}[Fixed Global Budget]
% The mission risk budget $\Delta_0>0$ is given and must never be exceeded.
% At epoch $t$, the remaining budget is denoted $\Delta_t$.
% \end{assumption}

%---------------------------------------------------------------
% \subsubsection{Algorithm}
%---------------------------------------------------------------

\begin{algorithm}[!t]
\caption{(BAT-ORB) Threshold Online Algorithm}
\label{alg:BATS}
\DontPrintSemicolon
\KwIn{Candidate set \(\mathcal{A}_t=\{\tau_{t,1},\dots,\tau_{t,N_t}\}\), current risk budget \(\Delta_t\), lower risk bound \(\delta_{\min}\), total budget \(\Delta_0\)}
\KwOut{Selected trajectory \(\tau_{t,n_t}\in\mathcal{A}_t\), or \texttt{None}}
\BlankLine

Compute adaptive threshold: \quad
\(\displaystyle
\Psi_{bat}(t) \gets \frac{\Delta_0}{\Delta_t}\,\ln\!\Bigl(1+\tfrac{\Delta_0}{\delta_{\min}}\Bigr)
\)\;

Filter feasible set:
\[
\mathcal{F}_t \gets \left\{ \tau_t \in \mathcal{A}_t \;\middle|\;
    R(\tau_t) \leq \Delta_t \wedge\; \rho(\tau_t) \geq \Psi_{bat}(t)
\right\}
\]

\uIf{\(\mathcal{F}_t = \varnothing\)}{
    \KwRet \texttt{None} \tcp*{No trajectory meets threshold}
}
\Else{
    \(\tau_{t,n_t} \gets \arg\max_{\tau \in \mathcal{F}_t} \rho(\tau_t)\)\;
    \KwRet \(\tau_{t,n_t}\)
}
\end{algorithm}

%---------------------------------------------------------------
\subsubsection{Competitive Ratio Guarantee}
%---------------------------------------------------------------
\begin{theorem}
\label{thm:bat_cr}
Under Assumption \ref{assump lbr}, BAT-ORB (Algorithm~\ref{alg:BATS}) achieves a competitive ratio
\[
\boxed{
\mathrm{CR}_{\text{bat}} \leq 2 + \frac{1}{\ln(\Delta_0/\delta_{\min})}}
\]
That is, for any input sequence~$\mathcal{A}$,
\[
U_{\text{bat}}(\mathcal{A})
\;\ge\;
\frac{U_{\mathrm{OPT}}(\mathcal{A})}
     {2 + \frac{1}{\ln(\Delta_0/\delta_{\min})}}\,
\]
\end{theorem}

% \begin{proof}[Sketch of Proof]
% Partition the horizon into at most
% $K=\lceil\ln(\Delta_0/\delta_{\min})\rceil+1$ \emph{phases}, each time the
% remaining budget drops by a factor~$e$.  Within phase $k$, the threshold
% $\beta_t$ changes by at most a constant factor, so BATS picks trajectories
% with total utility at least
% \(\beta_{\min}^{(k)}\times(\text{risk spent by BATS in phase }k)\).  By
% comparing to OPT’s risk‐utility in the same phase and summing over phases,
% one shows
% \(\;U_{\mathrm{OPT}}\le(\ln(\Delta_0/\delta_{\min})+2)\,U_{\mathrm{BATS}}\).
% \end{proof}

% \begin{proof}
% We sketch the classic phase‐based analysis, mirroring the ON‐MCKP argument.

% \medskip
% \noindent\textbf{1. Phase partition.}  
% Define breakpoints
% \[
% \Delta^{(k)} \;=\; \Delta_{0}\,e^{-k},
% \qquad
% k = 0,1,\dots,K,
% \]
% where 
% \(
% K = \bigl\lceil \ln(\Delta_0/\delta_{\min})\bigr\rceil.
% \)
% Phase \(k\) consists of all epochs \(t\) during which the remaining budget
% \(\Delta_t\) satisfies
% \(\Delta^{(k)} < \Delta_t \le \Delta^{(k-1)}\).  Since \(\Delta^{(K)}\le \delta_{\min}\),
% there are at most \(K+1\) phases.

% \medskip
% \noindent\textbf{2. BATS’s utility in phase \(k\).}  
% Within phase \(k\), the threshold
% \(\Psi_t = \tfrac{\Delta_0}{\Delta_t}\,\ln\!\bigl(1+\tfrac{\Delta_0}{\delta_{\min}}\bigr)\)
% never falls below
% \[
% \Psi^{(k)}
% =\frac{\Delta_0}{\Delta^{(k-1)}}\,
%  \ln\!\Bigl(1+\frac{\Delta_0}{\delta_{\min}}\Bigr)
% =e^{\,k-1}\,L,
% \quad
% L := \ln\!\Bigl(1+\tfrac{\Delta_0}{\delta_{\min}}\Bigr).
% \]
% Every time BATS selects a trajectory \(\tau\) of risk \(R(\tau)\), it earns
% \[
% U(\tau)\;\ge\;\Psi^{(k)}\,R(\tau) \;=\; e^{\,k-1}L\;R(\tau).
% \]
% Let \(R_A^{(k)}\) and \(U_A^{(k)}\) be the total risk spent and utility
% gained by BATS in phase \(k\).  Then
% \begin{equation}
%   U_A^{(k)} \;\ge\; e^{\,k-1}L \;R_A^{(k)}.
%   \label{eq:BATS_phase}
% \end{equation}

% \medskip
% \noindent\textbf{3. OPT’s utility in phase \(k\).}  
% Consider any trajectory \(\tau\) that OPT selects while the remaining budget
% lies in phase \(k\).  Its risk \(r\) satisfies
% \(\Delta^{(k)}<r\le\Delta^{(k-1)}\).  Since BATS would have rejected any
% trajectory with \(U(\tau)/r<\Psi_t\) and \(\Psi_t\) never decreases within
% the phase, OPT’s progress per risk is bounded:
% \[
% U(\tau)\;\le\;\Psi^{(k)}\,r=e^{\,k-1}L\,r.
% \]
% Summing over all of OPT’s trajectories in phase \(k\), denoting their
% cumulative risk by \(R_{\mathrm{OPT}}^{(k)}\), we get
% \begin{equation}
%   U_{\mathrm{OPT}}^{(k)}
%   \;\le\; e^{\,k-1}L \;R_{\mathrm{OPT}}^{(k)}.
%   \label{eq:OPT_phase}
% \end{equation}

% \medskip
% \noindent\textbf{4. Risk accounting.}  
% During phase \(k\), the combined risk spent by BATS and OPT cannot exceed
% the drop in remaining budget:
% \[
% R_A^{(k)} + R_{\mathrm{OPT}}^{(k)}
% \;\le\;
% \Delta^{(k-1)} - \Delta^{(k)}
% \;=\;(1-e^{-1})\,\Delta^{(k-1)}.
% \]
% Plugging into \eqref{eq:BATS_phase} and \eqref{eq:OPT_phase} gives
% \[
% U_{\mathrm{OPT}}^{(k)}
% \;\le\;
% e^{\,k-1}L\,R_{\mathrm{OPT}}^{(k)}
% \;\le\;
% \frac{e^{\,k-1}L}{1-e^{-1}}\,
% \bigl(R_A^{(k)} + R_{\mathrm{OPT}}^{(k)}\bigr)
% \;\le\;
% \frac{e}{e-1}\;U_A^{(k)}.
% \]
% Since \(\tfrac{e}{e-1}<2\), we have
% \[
% U_{\mathrm{OPT}}^{(k)} \;\le\; 2\,U_A^{(k)}.
% \]

% \medskip
% \noindent\textbf{5. Summing over all phases.}  
% Summing the above over the at most \(K+1\) phases yields
% \[
% U_{\mathrm{OPT}}
% =\sum_{k=1}^{K+1}U_{\mathrm{OPT}}^{(k)}
% \;\le\;
% 2\sum_{k=1}^{K+1}U_A^{(k)}
% \;=\;2\,U_A.
% \]
% Noting \(K+1\le L+1\) and re‐introducing the small constant from the last
% partial phase gives the final
% \[
% U_A \;\ge\;\frac{1}{\ln(\Delta_0/\delta_{\min})+2}\;U_{\mathrm{OPT}},
% \]
% as claimed.  
% \end{proof}

% %%%%%%%%%%%%%%%%%%%%%%%%
% \begin{proof}[\textbf{Proof}]
% Let \(S\) be the set of trajectories selected by BAT-ORB and \(S^*\) the set selected by the offline optimum.  Let
% \[
% U(S)=\sum_{\tau\in S}U(\tau),
% \quad
% U(S^*)=\sum_{\tau\in S^*}U(\tau).
% \]
% Define the used‐budget fraction at epoch \(t\) by
% \[
% z_t = 1 - \frac{\Delta_t}{\Delta_0},
% \]
% and set
% \[
% L = \ln\!\Bigl(1+\frac{\Delta_0}{\delta_{\min}}\Bigr),
% \qquad
% \Psi_{bat} = \frac{\Delta_0}{\Delta_t}\,L.
% \]


% \medskip
% \noindent\textbf{Step 1: Partition the offline solution.}  
% As in the CZL‐ORB proof, partition 
% \[
% S^* \setminus S = X^* \;\,\cup\,\; Y^*,
% \]
% where
% \begin{itemize}
%     \item $X^* \coloneqq$ Trajectories where $\rho(\tau) < \Psi_{bat}(\Delta_t)$ at arrival time $t$.
%     \item $Y^*\coloneqq$ Trajectories that met $\rho(\tau)  \geq \Psi_{bat}(\Delta_t)$ but were not selected.
% \end{itemize}
% % \noindent\textbf{Step 1: Decompose \(S^*\setminus S\).}\\
% % Partition
% % \[
% % S^*\setminus S = X^* \;\cup\; Y^*,
% % \]
% % where
% % \[
% % X^*=\Bigl\{\tau\in S^*\setminus S\;\Big|\;
% % \rho(\tau)<\Psi_{t(\tau)}\Bigr\},
% % \quad
% % Y^*=(S^*\setminus S)\setminus X^*.
% % \]
% % Here \(t(\tau)\) denotes the epoch when \(\tau\) arrived.

% \medskip

% \noindent\textbf{Step 2: Bound the contribution of \(Y^*\).}  

%  For each $\tau \in Y^* \cap \mathcal{A}_t$, BAT-ORB selected a trajectory $\tau' \in \mathcal{A}_t$ with $U(\tau') \geq U(\tau)$. Thus:
% \[
% \sum_{\tau \in Y^*} U(\tau) \leq \sum_{t=1}^T U(\tau_{t,j_t}) = U(S)
% \]
% % \noindent\textbf{Step 2: Bound tie‐losers \(Y^*\).}\\
% % Whenever \(\tau\in Y^*\), BAT-ORB chose some \(\sigma\) in the same epoch with
% % \(\tfrac{U(\sigma)}{R(\sigma)}\ge \rho(\tau)\) and hence
% % \(U(\sigma)\ge U(\tau)\).  Summing gives
% % \[
% % U(Y^*)\le U(S).
% % \]

% \medskip
% \noindent\textbf{Step 3: Bound the contribution of \(X^*\).}  

%  Let $ {\Delta_T}$ be the final remaining risk budget. We have \(\Psi_{bat}(\Delta_t) \leq \Psi_{bat}(\Delta_T)\) because \(\Delta_t \geq \Delta_T \) and  the threshold function \(\Psi_{bat}(\Delta_t)\) is increasing overt time since the reamining budget is decreasing over time. Therefore, $\forall \tau \in X^*$:
% \[
% \rho(\tau)  < \Psi_{bat}(\Delta_t) \leq \Psi_{bat}(\Delta_T) \implies U(\tau) < \Psi_{bat}(\Delta_T)R(\tau)
% \]
% Summing over $X^*$:
% \[
% \sum_{\tau \in X^*} U(\tau) \leq \Psi_{bat}(\Delta_T)\sum_{\tau \in X^*}R(\tau)
% \]
% \[
% \sum_{\tau \in X^*} U(\tau) \leq (\Delta_0-\Delta_T) \Psi_{bat}(\Delta_T)
% \]
% % \textbf{Bound threshold‐failures \(X^*\).}\\
% % For each \(\tau\in X^*\),
% % \[
% % U(\tau)<\Psi_{bat}{(\Delta_t)}\,R(\tau)
% % \;\le\;\Psi_{\max}\sum_{\tau\in X^*}R(\tau),
% % \]
% % where \(\Psi_{\max}=\max_{\,\tau\in X^*}\Psi_{t(\tau)}\le\Psi_T\).  Since OPT’s total risk is \(\le\Delta_0\) and BAT-ORB uses exactly \(\Delta_0\,Z\), the remaining risk for \(X^*\) is at most \(\Delta_0(1-Z)\).  Thus
% % \[
% % U(X^*)
% % <\Psi_T\;\Delta_0\,(1-Z).
% % \]

% \medskip
% \textbf{Step 4: Lower‐bound \(U(S)\).}
%  \(\forall \tau\in S\) meets the threshold:
% \[
% U(\tau)\ge\Psi_{bat}{(\Delta_t)}\,R(\tau).
% \]
% Hence;
% \[
% U(S)
% =\sum_{\tau\in S}U(\tau)
% \ge\sum_{\tau\in S}\Psi_{bat}(\Delta_t)\,R(\tau)=\sum_{\tau\in S}\tfrac{\Delta_0}{\Delta_t}\;L\; R(\tau)\]

% \[
% U(S)\geq L\; \sum_{\tau\in S}\frac{1}{(1-z_t)}\; R(\tau)
% \]
% \[
% U(S)\geq L\;\Delta_0 \sum_{\tau\in S}\frac{1}{(1-z_t)}\; \frac{R(\tau)}{\Delta_0}
% \]

% The Riemann sum \(\sum_{\tau\in S}\tfrac{R(\tau)}{\Delta_0(1-z_t)}\;\)
% lower‐bounds the integral
% \(\int_0^Z\tfrac{1}{(1-z_t)}\;dz
% = \ln\!\bigl(\tfrac{1}{1-Z}\bigr)
% = \ln\!\bigl(\tfrac{\Delta_0}{\Delta_T}\bigr)\).

% \medskip
% \noindent Therefore,
% \[
% U(S)\ge\,L\,\;\Delta_0\;\ln\!\bigl(\tfrac{\Delta_0}{\Delta_T}\bigr).
% \]

% \medskip
% \noindent\textbf{Step 5: Combine bounds.}\\
% Putting Steps 2–4 together:
% \[
% \begin{aligned}
% U(S^*)
% &=U(S\cap S^*)+U(X^*)+U(Y^*)\\
% &\le U(S)+(\Delta_0-\Delta_T) \Psi_{bat}(\Delta_T)+U(S)\\
% &=2\,U(S)+\frac{(\Delta_0-\Delta_T)\;L\,\Delta_0}{\Delta_T} .
% \end{aligned}
% \]

% \medskip




% \noindent\textbf{Step 5.1: Simplify the term.}\\
% Since \(1 - Z = \tfrac{\Delta_T}{\Delta_0}\) and
% \(\Psi_T = \frac{L}{1 - Z}\), we get
% \[
% \Psi_T\,\Delta_0\,(1-Z)
% = L\,\Delta_0.
% \]

% \medskip
% \noindent\textbf{Step 5.2: Relate \(L\,\Delta_0\) to \(U(S)\).}\\
% From Step 4 we have
% \[
% U(S)\;\ge\;\Delta_0\,L\;\ln\!\Bigl(\tfrac{\Delta_0}{\Delta_T}\Bigr).
% \]
% Rearrange to isolate \(\Delta_0\,L\):
% \[
% \Delta_0\,L
% \;\le\;\frac{U(S)}{\ln\!\bigl(\tfrac{\Delta_0}{\Delta_T}\bigr)}.
% \]
% Because \(\Delta_T\ge\delta_{\min}\), the denominator satisfies
% \(\ln\!\bigl(\tfrac{\Delta_0}{\Delta_T}\bigr)
% \ge\ln\!\bigl(\tfrac{\Delta_0}{\delta_{\min}}\bigr)\).  Hence
% \[
% \frac{1}{\ln(\Delta_0/\Delta_T)}
% \;\le\;
% \frac{1}{\ln(\Delta_0/\delta_{\min})},
% \]
% and so
% \[
% \Delta_0\,L
% \;\le\;
% \frac{U(S)}{\ln(\Delta_0/\delta_{\min})}.
% \]
% \medskip
% \noindent\textbf{Step 5.3: Final inequality (fully clarified).}\\
% We currently have from Step 5.2:
% \[
% \Delta_0\,L
% \;\le\;
% \frac{U(S)}{\ln(\Delta_0/\delta_{\min})}.
% \]

% To finalize the competitive-ratio bound clearly, we need a simpler upper bound on the right-hand side. Recall we are trying to establish an inequality of the form:
% \[
% \Delta_0\,L \leq \left(\ln\!\left(\frac{\Delta_0}{\delta_{\min}}\right) + 1\right)U(S).
% \]

% The difficulty is directly bounding the expression \(\frac{1}{\ln(\Delta_0/\delta_{\min})}\). To handle this rigorously, let's clearly state and verify the required auxiliary inequality:

% \medskip
% \noindent\textbf{Auxiliary inequality.} For all \(x > e\), the following inequality holds:
% \[
% \frac{1}{\ln(x)} \;\le\; \ln(x) + 1.
% \]

% \noindent\emph{Proof of auxiliary inequality.} Define the function:
% \[
% f(x) = (\ln x + 1)\ln(x) - 1, \quad x>e.
% \]

% Compute its derivative:
% \[
% f'(x) = \frac{\ln x + 1 + \ln x}{x} = \frac{2\ln x + 1}{x}.
% \]

% For \(x > e\), we have \(\ln(x)>1\), thus \(2\ln(x) + 1 > 0\), and therefore \(f'(x) > 0\). Hence, \(f(x)\) is strictly increasing for \(x>e\).

% Evaluate at the boundary \(x=e\):
% \[
% f(e) = (\ln(e)+1)\ln(e)-1 = (1+1)\cdot 1 - 1 = 1 > 0.
% \]

% Thus, for every \(x>e\), we have \(f(x)\ge f(e) = 1 > 0\). Rearranging this inequality, we get:
% \[
% (\ln(x) + 1)\ln(x) - 1 > 0 \quad\Longrightarrow\quad \frac{1}{\ln(x)} < \ln(x) + 1,
% \]
% proving the auxiliary inequality.

% \medskip
% \noindent\textbf{Apply auxiliary inequality.} Now, set \(x=\frac{\Delta_0}{\delta_{\min}}\). Since by assumption we have \(\frac{\Delta_0}{\delta_{\min}}>1\), and typically significantly greater than \(e\), the auxiliary inequality holds, giving us:
% \[
% \frac{1}{\ln(\Delta_0/\delta_{\min})} \leq \ln(\Delta_0/\delta_{\min}) + 1.
% \]

% Thus we clearly have:
% \[
% \Delta_0\,L \leq \frac{U(S)}{\ln(\Delta_0/\delta_{\min})} 
% \leq \left(\ln\left(\frac{\Delta_0}{\delta_{\min}}\right)+1\right)U(S).
% \]

% \medskip
% \noindent\textbf{Final simplified form.} Recall the definition:
% \[
% \Psi_T\,\Delta_0\,(1-Z) = L\,\Delta_0,
% \]
% hence we arrive at our required bound:
% \[
% \Psi_T\,\Delta_0\,(1-Z)\leq \left(\ln\left(\frac{\Delta_0}{\delta_{\min}}\right)+1\right)\,U(S),
% \]
% which precisely matches what we set out to establish clearly in Step 5.3.

% \medskip
% \noindent\textbf{Step 5.3: Final inequality.}\\
% Finally, for any \(x>1\) one checks
% \(\tfrac{1}{\ln x}\le \ln x +1\).  Applying this with
% \(x=\frac{\Delta_0}{\delta_{\min}}>1\) gives
% \[
% \Delta_0\,L
% \;\le\;
% \frac{U(S)}{\ln(\Delta_0/\delta_{\min})}
% \;\le\;
% \bigl(\ln(\tfrac{\Delta_0}{\delta_{\min}})+1\bigr)\,U(S).
% \]
% Putting back \(\Delta_0\,L=\Psi_T\,\Delta_0\,(1-Z)\) yields the desired
% bound:
% \[
% \Psi_T\,\Delta_0\,(1-Z)
% \;\le\;
% \bigl(\ln(\tfrac{\Delta_0}{\delta_{\min}})+1\bigr)\,U(S).
% \]


% \[\Psi_T\,\Delta_0\,(1-Z)\le(\ln(\tfrac{\Delta_0}{\delta_{\min}})+1)\,U(S)\]
% Hence
% \[
% U(S^*)\le(\ln(\tfrac{\Delta_0}{\delta_{\min}})+2)\,U(S),
% \]
% and the result follows:
% \[
% U(S)\ge\frac{U(S^*)}{\ln(\Delta_0/\delta_{\min})+2}.
% \]
% \end{proof}
%%%%%%%%%%%%%%%%%%%%%%%

% \subsection{Budget-aware Threshold-Based Online Algorithm}
% \label{sec:bats}


% The Budget-Aware Threshold Selector (BATS) algorithm, defined in Algorithm \ref{alg:BATS}, offers a lightweight strategy for online trajectory selection under a risk budget. At each decision epoch, BATS selects a candidate trajectory if its utility-to-risk ratio exceeds a dynamically computed threshold. This strategy enforces conservative choices when the remaining risk budget is low, and more opportunistic ones when budget is ample. The key idea is to enforce a minimum return-on-risk condition that adapts over time and provably guarantees near-optimality.

% \subsubsection{Adaptive Threshold Rule}

% Let \(\Delta_t\) denote the remaining risk budget at decision epoch \(t\), and let \(\Delta_0\) be the initial mission-level risk budget. The BATS algorithm enforces an adaptive acceptance rule: a candidate trajectory is accepted only if its utility-to-risk ratio exceeds a dynamic threshold \(\beta_t\), defined as
% \begin{equation}
%     \beta_t = \frac{\Delta_0}{\Delta_t} \cdot \ln\left(1 + \frac{\Delta_0}{\delta_{\min}}\right),
%     \label{eq:adaptive_threshold}
% \end{equation}
% where \(\delta_{\min} > 0\) is a known lower bound on the risk of any candidate trajectory:
% \[
% \delta_{\min} \le \min_{t, j} R(\tau_{t,j}).
% \]

% This assumption is standard in online knapsack literature and holds in our setting due to the finite resolution of trajectory generation and risk estimation.

% As the remaining budget \(\Delta_t\) shrinks, the threshold \(\beta_t\) increases, making the algorithm more conservative. This dynamic ensures that only high-utility, low-risk trajectories are selected when the available risk budget becomes scarce.

% Formally, at epoch \(t\), BATS selects a trajectory \(\tau \in \mathcal{A}_t\) only if:
% \begin{equation}
%     \frac{U(\tau)}{R(\tau)} \ge \beta_t.
% \end{equation}
% Otherwise, no trajectory is selected, and the algorithm terminates. This threshold condition balances exploration of high-reward paths against the risk budget constraint.
% \begin{remark}[Interpretation of the Threshold Rule]
% The adaptive threshold \(\beta_t\) serves as a dynamic filter that adjusts the selectivity of the planner based on the remaining risk budget. When \(\Delta_t\) is large (early in the mission), the threshold is low, allowing the planner to explore moderately efficient trajectories. As \(\Delta_t\) decreases, the threshold increases, enforcing stricter requirements on utility per unit risk.

% This mechanism ensures that the planner conserves risk for critical decisions later in the mission while maximizing progress when budget permits. It is analogous to increasing the value-per-cost ratio in classical knapsack problems as resources become scarce.
% \end{remark}

% % \subsubsection{Online Selection Algorithm (BATS)}

% % \subsubsection{Theoretical Guarantee and Complexity}


% \subsection{Threshold-Based Online Algorithm}
% \label{sec:bats}
% %===============================================================

% We now present a \emph{Budget-Aware Threshold Selector} (BATS) that solves the
% online risk-bounded motion–planning problem introduced in the previous
% section.

% %---------------------------------------------------------------
% \subsubsection{Adaptive threshold rule}
% %---------------------------------------------------------------
% Let $\Delta_{t}$ denote the \emph{remaining} risk budget just before decision
% epoch~$t$.  
% Define the \emph{adaptive threshold}
% \begin{equation}
%     \beta_{t}\;=\;\frac{\Delta_{0}}{\Delta_{t}}\,
%                   \ln\!\Bigl(1+\tfrac{\Delta_{0}}{\delta}\Bigr),
%     \label{eq:adaptive_threshold}
% \end{equation}
% where $\delta \!>\! 0$ is an a priori lower bound on the non-zero risk of any
% candidate segment, i.e.\ $\delta \le \min_{t,r} R_{rt}$.\footnote{%
% This mild assumption is identical to that used in classical
% online-knapsack analysis and holds in practice because risks are evaluated on
% a finite grid with positive precision.}

% Intuitively, $\beta_{t}$ tightens as the residual budget
% $\Delta_{t}$ shrinks: the algorithm becomes increasingly conservative when
% little risk can be spent.

% %---------------------------------------------------------------
% \subsubsection{Algorithm}
% %---------------------------------------------------------------
% \begin{algorithm}[!h] % or [htbp]
% \caption{BATS \\Budget-Aware Threshold Selector}
% \label{alg:BATS}
% \DontPrintSemicolon
% \KwIn{Initial risk budget $\Delta_{0}$}
% \KwOut{Sequence of selected segments
%        $\{\tau_{1,j_1},\dots,\tau_{T,j_T}\}$}
% \BlankLine
% \For{$t = 1$ \KwTo $T$}{
%   Generate candidate set $\mathcal{A}_t$ \tcp*{lattice expansion}
%   \ForEach{$\tau_{t,r}\in\mathcal{A}_t$}{
%       compute progress $P_{rt}$ and risk $R_{rt}$\;
%   }
%   \textbf{Feasible set:}\;
%   $\mathcal{F}_t \leftarrow
%      \{\tau_{t,r}\mid R_{rt}\le\Delta_t\}$\;
     
%   \uIf{$\mathcal{F}_t = \varnothing$}{
%       \textbf{stop} \;
%   }\Else{
%       $\displaystyle
%       \tau_{t,j_t}\leftarrow
%       \arg\max_{\tau\in\mathcal{F}_t}\!
%       \tfrac{P(\tau)}{R(\tau)}$\;
      
%       \If{$\frac{P(\tau_{t,j_t})}{R(\tau_{t,j_t})}\ge\beta_t$}{
%        $\Delta_{t+1}\leftarrow
%             \Delta_t - R(\tau_{t,j_t})$\;
            
%           \KwRet $\tau_{t,j_t}$\;
          
%           % $\Delta_{t+1}\leftarrow
%           %   \Delta_t - R(\tau_{t,j_t})$\;
%       }\Else{
%           \textbf{stop} (no candidate meets threshold)\;
%       }
%   }
% }
% \end{algorithm}

% %---------------------------------------------------------------
% \subsubsection{Competitive-ratio guarantee}
% %---------------------------------------------------------------
% \begin{theorem}
% \label{thm:compet_ratio}
% Assume $\delta \le \min_{t,r} R_{rt}$.
% Algorithm~\ref{alg:BATS} is
% \[
% \bigl(\,\ln(\tfrac{\Delta_{0}}{\delta})+2\,\bigr)
% \text{-competitive},
% \]
% i.e.\ for every input sequence $\mathcal{M}$,
% $$
% \!\!\!\!\!\!
% \textsc{BATS}(\mathcal{M})\;\;\ge\;\;
% \frac{\text{OPT}(\mathcal{M})}
%      {\ln(\tfrac{\Delta_{0}}{\delta})+2}.
% $$
% \end{theorem}

% \paragraph*{Proof sketch.}
% Let $P^{\star}$ and $R^{\star}$ denote the total progress and risk of the
% offline optimum.
% Partition the planning horizon into \emph{phases} such that $\Delta_{t}$
% drops by at least a factor~$e$ from one phase to the next.  
% Within each phase the threshold~$\beta_t$ is constant up to a factor~$e$.
% Because BATS selects only segments whose progress-per-risk ratio is at least
% $\beta_t$, it captures a $1/(\ln(\Delta_{0}/\delta)+1)$ fraction of the
% offline progress in that phase.
% Summing over $\le \ln(\Delta_{0}/\delta)+1$ phases yields the stated bound,
% plus~1 extra term accounting for the last partial phase.
% \hfill\qedsymbol


% %---------------------------------------------------------------
% \subsubsection{Competitive-ratio guarantee}
% %---------------------------------------------------------------

% \begin{theorem}
% \label{thm:compet_ratio_full}
% Let $\delta>0$ satisfy $\delta \le \min_{t,r} R_{rt}$.  
% With the adaptive threshold \eqref{eq:adaptive_threshold},
% Algorithm~\ref{alg:BATS} is
% \[
% \Bigl(\ln\!\bigl(\tfrac{\Delta_{0}}{\delta}\bigr)+2\Bigr)\text{-competitive}.
% \]
% \end{theorem}

% \begin{proof}
% % \textbf{Notation.\;}
% Write $A$ for BATS, $\text{OPT}$ for the offline optimum,  
% $P_A,R_A$ for the progress and risk accumulated by~$A$,  
% and $P^\star,R^\star(\le\Delta_{0})$ for the corresponding quantities of
% $\text{OPT}$.

% %-----------------------------------------------------------
% \paragraph{Phase partition.}
% %-----------------------------------------------------------
% Define a sequence of \emph{breakpoints}
% \(
% \Delta^{(k)} \;=\; \Delta_{0}\,e^{-k},
% \quad
% k=0,1,\dots,K,
% \)
% where
% $
% K \;=\; \bigl\lceil \ln\!\bigl(\tfrac{\Delta_{0}}{\delta}\bigr)\bigr\rceil.
% $
% Whenever BATS’ remaining budget~$\Delta_t$ first becomes
% $\le\Delta^{(k)}$, a new \emph{phase}~$k$ starts.  
% Because $\Delta^{(K)}\le\delta$, at most $K\!+\!1$ phases occur.

% %-----------------------------------------------------------
% \paragraph{Progress earned within a single phase.}
% %-----------------------------------------------------------
% Fix a phase~$k$ that starts with residual budget
% $\Delta^{(k-1)}$ and ends (possibly prematurely) at
% $\Delta^{(k)}$.  
% Throughout the phase, the threshold $\beta_t$ obeys
% \[
% \beta_t \;\ge\;
% \frac{\Delta_{0}}{\Delta^{(k-1)}}\,L
% \;=\;
% e^{k-1}L,
% \quad
% \text{where}\;
% L \;=\; \ln\!\bigl(1+\tfrac{\Delta_{0}}{\delta}\bigr).
% \]
% Whenever BATS selects a segment of risk~$r$, its progress is at least
% $\beta_t r \ge e^{k-1}L\,r$.
% Let $R_A^{(k)}$ be the total risk \emph{spent by BATS} in phase~$k$.
% Then
% \begin{equation}
%     P_A^{(k)}
%     \;\ge\;
%     e^{\,k-1}L \, R_A^{(k)}.
%     \label{eq:PAk_lower}
% \end{equation}

% %-----------------------------------------------------------
% \paragraph{Bounding OPT within the same phase.}
% %-----------------------------------------------------------
% Consider any segment used by OPT whose risk falls
% inside the current residual-budget
% interval; i.e.\ its risk $r$ satisfies
% $\Delta^{(k)}<r\le\Delta^{(k-1)}$.
% Because BATS accepts no segment with
% $\frac{P}{R}<\beta_t$ and the threshold never \emph{decreases} inside a
% phase, every such OPT segment must satisfy
% \(
% P \le \beta_t\,r \le e^{k-1}L\,r.
% \)
% Hence the progress of \emph{all} OPT segments whose risk is booked in
% phase~$k$ is at most
% \begin{equation}
%     P_{\text{OPT}}^{(k)}
%     \;\le\;
%     e^{\,k-1}L \, R_{\text{OPT}}^{(k)},
%     \label{eq:OPT_phase_bound}
% \end{equation}
% where $R_{\text{OPT}}^{(k)}$ denotes the corresponding cumulative risk of OPT.

% %-----------------------------------------------------------
% \paragraph{Risk accounting.}
% %-----------------------------------------------------------
% During phase~$k$ the residual budget drops from
% $\Delta^{(k-1)}$ to \emph{below} $\Delta^{(k)}$, so
% \(
% R_A^{(k)} + R_{\text{OPT}}^{(k)}
% \;\le\;
% \Delta^{(k-1)} - \Delta^{(k)}
% \;=\;
% \bigl(1-e^{-1}\bigr)\Delta^{(k-1)}.
% \)
% Insert this into \eqref{eq:PAk_lower} and \eqref{eq:OPT_phase_bound}:
% \[
% P_{\text{OPT}}^{(k)}
% \;\le\;
% e^{\,k-1}L\,R_{\text{OPT}}^{(k)}
% \;\le\;
% \frac{e^{\,k-1}L}{1-e^{-1}}\,
% \bigl(R_A^{(k)} + R_{\text{OPT}}^{(k)}\bigr)
% \;\le\;
% \frac{e}{e-1}\,P_A^{(k)}.
% \]
% Because $e/(e-1)<2$, we obtain
% \(
% P_{\text{OPT}}^{(k)} \le 2\,P_A^{(k)}.
% \)

% %-----------------------------------------------------------
% \paragraph{Summing over phases.}
% %-----------------------------------------------------------
% Summing the above inequality over all at most $K$ full phases and the
% (possibly partial) last phase~$K$ gives
% \[
% P^\star
% =\sum_{k=1}^{K} P_{\text{OPT}}^{(k)}
% \;\le\;
% 2\sum_{k=1}^{K} P_A^{(k)}
% \;+\;
% P_A^{(K)}
% \;\le\;
% \bigl(L+2\bigr)\,P_A,
% \]
% where we used $K\le L$ and $P_A^{(K)}\le P_A$.
% Re-arranging yields
% \(
% P_A \;\ge\; \tfrac{1}{L+2}\,P^\star,
% \)
% completing the proof.
% \end{proof}

% \medskip
% \noindent
% \textbf{Interpretation.}\;
% The bound grows only \emph{logarithmically} with
% $\Delta_{0}/\delta$, matching the information-theoretic lower bound for
% online multiple-choice knapsack and confirming that BATS is essentially
% optimal up to a small additive constant.


% %---------------------------------------------------------------
% \subsubsection{Computational complexity}
% %---------------------------------------------------------------
% At epoch~$t$, BATS evaluates $N_t$ candidates and performs one
% \textsf{argmax}\;—\,an $O(N_t)$ operation.
% Hence the total runtime is
% $O\!\bigl(\sum_{t=1}^{T} N_t\bigr)$,
% linear in the number of candidate segments generated by the lattice
% expansion, and therefore suitable for real-time implementation in CARLA.

% %===============================================================












%===============================================================




%===============================================================
% \subsection{Deepseek: Succinct-Prediction Algorithms for Online Risk-Bounded Planning}
% \label{sec:spat-orb}

% Purely online algorithms treat the future as \emph{adversarial},
% thereby leaving considerable slack in the risk budget Fig.~\ref{fig:enter-gap method3}.
% In practice, the ego vehicle often has \emph{partial} foresight
% (e.g.\ short-horizon traffic forecasts or HD-map priors) that can be
% compressed into a \emph{single informative scalar} and exploited to raise
% efficiency without sacrificing worst-case guarantees.
% \begin{figure}[!h]
%     \centering
%     \includegraphics[width=0.8\linewidth]{Figures/gap_for_method3.png}
%     \caption{Given a risk budget with 20, the online algorithm is not utilizing it due to lack of future information and worst-case analysis.}
%     \label{fig:enter-gap method3}
% \end{figure}

% We extend the threshold-based framework of online risk-bounded planning by integrating succinct predictions regarding future utility-to-risk ratios. Following recent work~\cite{daneshvaramoli2024competitivealgorithmsonlineknapsack}, we introduce two primary forms of succinct predictions:
% \begin{itemize}
%     \item A \emph{point prediction} \(\hat{\rho}\), estimating the optimal utility-to-risk ratio.
%     \item An \emph{interval prediction} \([\rho_{\text{low}}, \rho_{\text{high}}]\), providing robustness against inaccurate estimates.
% \end{itemize}


% \subsubsection{Algorithm Description (Point Prediction)}

% Algorithm~\ref{alg:spat_point} outlines the SPAT-ORB algorithm when provided with a point prediction \(\hat{\rho}\).

% \begin{algorithm}[!t]
% \caption{SPAT-ORB Algorithm with Point Prediction}
% \label{alg:spat_point}
% \DontPrintSemicolon
% \KwIn{Candidate trajectories \(\mathcal{A}_t\), current risk budget \(\Delta_t\), global budget \(\Delta_0\), lower risk bound \(\delta_{\min}\), point prediction \(\hat{\rho}\)}
% \KwOut{Selected trajectory or \texttt{None}}
% Compute adaptive threshold:
% \[
% \Psi_t = \max\left\{
% \hat{\rho},\, \frac{\Delta_0}{\Delta_t}\ln\left(1+\frac{\Delta_0}{\delta_{\min}}\right)
% \right\}
% \]

% Filter feasible set:
% \[
% \mathcal{F}_t = \{\tau\in\mathcal{A}_t : R(\tau)\leq\Delta_t,\,\rho(\tau)\geq\Psi_t\}
% \]

% Select trajectory:
% \[
% \tau_{t,j_t} = \arg\max_{\tau\in\mathcal{F}_t}\rho(\tau)
% \quad\text{if}\;\mathcal{F}_t\neq\varnothing,\quad\text{otherwise}\;\texttt{None}.
% \]
% \end{algorithm}

% \subsubsection{Competitive Ratio Guarantee (Point Prediction)}

% \begin{theorem}[Point Prediction Competitive Ratio]
% \label{thm:spat_point_cr}
% Given a point prediction \(\hat{\rho}\), Algorithm~\ref{alg:spat_point} is \( (1+\min\{1,\omega\}) \)-competitive, where \(\omega\) represents the cumulative risk of trajectories with utility-to-risk ratio exactly equal to \(\hat{\rho}\) in the offline optimal solution.
% \end{theorem}

% \begin{proof}[Proof (adapted from~\cite{daneshvaramoli2024competitivealgorithmsonlineknapsack})]
% Consider the optimal offline solution \(S^*\). Denote:
% \[
% \omega = \sum_{\tau \in S^*: \rho(\tau)=\hat{\rho}} R(\tau).
% \]

% \noindent\textbf{Case analysis:}

% \noindent\underline{Case 1 (\(\omega\geq1\)):} The threshold ensures at most half of the risk budget is spent on items equal to the prediction, guaranteeing at least half the utility compared to the offline optimum, thus yielding a 2-competitive ratio.

% \noindent\underline{Case 2 (\(\omega<1\)):} The threshold dynamically adapts to accept at least a fraction \(\frac{\omega}{1+\omega}\) of trajectories with predicted ratio, ensuring at least \(\frac{1}{1+\omega}\) of the optimal utility from higher ratio items. Combining, the competitive ratio is bounded by:
% \[
% 1 + \min\{1,\omega\}.
% \]

% This matches the known lower bound, confirming optimality.
% \end{proof}
% % We present learning-augmented algorithms using \textit{succinct predictions} of the critical utility-to-risk ratio $\hat{\rho}$, defined as the minimum ratio in the offline optimal solution. Our framework includes:
% % \begin{itemize}
% %     \item \textbf{Point Prediction:} Single estimate $\hat{\rho}$
% %     \item \textbf{Interval Prediction:} Confidence bounds $[\rho_{\text{low}}, \rho_{\text{high}}]$
% %     \item \textbf{Integral Execution:} Fr2Int conversion for trajectory selection
% % \end{itemize}

% % \begin{definition}[Fractional Algorithms]
% %      we define fractional algorithms where partial trajectory execution is allowed. These establish competitive ratios later maintained in integral execution via Fr2Int.
% % \end{definition}

% \begin{algorithm}[!h]
% \caption{ORB-Frac-PP-b (Point Prediction, Basic)}
% \label{alg:orb-frac-ppb}
% \begin{algorithmic}
% \Require Risk budget $\Delta_0$, prediction $\hat{\rho}$
% \State $\Delta_{\text{high}} \gets \Delta_0/2$ \Comment{Budget for $\rho_t > \hat{\rho}$}
% \State $\Delta_{\hat{\rho}} \gets \Delta_0/2$ \Comment{Budget for $\rho_t = \hat{\rho}$}
% \For{arriving trajectory $\tau_t$ with $U_t, R_t$}
%     \State $\rho_t \gets U_t / R_t$
%     \If{$\rho_t < \hat{\rho}$} 
%         \State $x_t \gets 0$ \Comment{Reject}
%     \ElsIf{$\rho_t > \hat{\rho}$}
%         \State $x_t \gets \min(1, \frac{\Delta_{\text{high}}}{R_t}) \times \frac{1}{2}$ \Comment{Accept half}
%         \State $\Delta_{\text{high}} \gets \Delta_{\text{high}} - x_t R_t$
%     \Else
%         \State $r \gets \min(R_t, \Delta_{\hat{\rho}})$
%         \State $x_t \gets r / (2R_t)$ \Comment{Accept half of available risk}
%         \State $\Delta_{\hat{\rho}} \gets \Delta_{\hat{\rho}} - x_t R_t$
%     \EndIf
%     \State Update $\Delta \gets \Delta - x_t R_t$
% \EndFor
% \end{algorithmic}
% \end{algorithm}

% \begin{theorem}
% Given perfect $\hat{\rho}$, ORB-Frac-PP-b is \textbf{2-competitive}:
% \[
% \forall \mathcal{I},\quad \frac{\text{OPT}(\mathcal{I})}{\text{ORB-Frac-PP-b}(\mathcal{I})} \leq 2
% \]
% \end{theorem}
% \begin{proof}
% Direct adaptation of Theorem 3.2. Uses capacity partitioning: Half-budget for $\rho_t > \hat{\rho}$ yields $\geq \frac{1}{2}\text{OPT}_{\text{high}}$, half for $\rho_t = \hat{\rho}$ yields $\geq \frac{1}{2}\text{OPT}_{\hat{\rho}}$. Sum dominates $\frac{1}{2}\text{OPT}$.
% \end{proof}

% \begin{algorithm}[t]
% \caption{ORB-Frac-IPA (Interval Prediction)}
% \label{alg:orb-frac-ipa}
% \begin{algorithmic}[1]
% \Require Risk budget $\Delta_0$, interval $[\ell, u]$, robust algorithm $\mathcal{A}$ (e.g., BAT-ORB)
% \State $\Delta_{\text{high}} \gets \Delta_0/(\alpha+1)$ \Comment{$\alpha = \mathcal{A}$'s comp. ratio}
% \State $\Delta_{\mathcal{A}} \gets \Delta_0 \alpha/(\alpha+1)$
% \For{arriving trajectory $\tau_t$ with $U_t, R_t$}
%     \State $\rho_t \gets U_t / R_t$
%     \If{$\rho_t < \ell$} 
%         \State $x_t \gets 0$ 
%     \ElsIf{$\rho_t > u$}
%         \State $x_t \gets \min(1, \frac{\Delta_{\text{high}}}{R_t})$
%         \State $\Delta_{\text{high}} \gets \Delta_{\text{high}} - x_t R_t$
%     \Else
%         \State $x_t \gets \mathcal{A}\text{'s decision for }\tau_t\text{ using }\Delta_{\mathcal{A}}$
%     \EndIf
%     \State Update $\Delta \gets \Delta - x_t R_t$
% \EndFor
% \end{algorithmic}
% \end{algorithm}

% \begin{theorem}
% Given $\ell \leq \hat{\rho} \leq u$, ORB-Frac-IPA is $(\alpha + 1)$-competitive.
% \end{theorem}
% \begin{proof}
% Adapts Theorem 3.4. OPT decomposes as $\text{OPT} \leq \text{OPT}_{\rho>u} + \text{OPT}_{\rho\in[\ell,u]}$. Algorithm gets $\frac{1}{\alpha+1}\text{OPT}_{\rho>u}$ and $\frac{\alpha}{\alpha+1}\text{OPT}_{\rho\in[\ell,u]} \geq \frac{1}{\alpha+1}\text{OPT}_{\rho\in[\ell,u]}$.
% \end{proof}

% \subsubsection{Integral Execution via Fr2Int}
% To handle \textit{all-or-nothing} trajectory acceptance, we adapt the Fr2Int conversion:

% \begin{algorithm}[t]
% \caption{ORB-Fr2Int (Fractional-to-Integral Conversion)}
% \label{alg:orb-fr2int}
% \begin{algorithmic}[1]
% \Require Frac. alg. $\mathcal{A}$, risk budget $\Delta_0$, discretization param $\delta$
% \State Partition $[\rho_{\min}, \rho_{\max}]$ into $K$ intervals $G_k$ (Def. 5.1)
% \State Initialize lists $A[k] \gets 0$, $R[k] \gets 0$ $\forall k$ \Comment{Accumulated utility}
% \For{arriving trajectory $\tau_t$ in $G_k$}
%     \State Simulate $\mathcal{A}$ to get fractional util. $r_k^{\text{frac}}$
%     \If{$A[k] < r_k^{\text{frac}} \cdot (1 - \epsilon)$} 
%         \State Accept $\tau_t$ fully, $A[k] \gets A[k] + U_t$
%     \Else
%         \State Reject $\tau_t$
%     \EndIf
%     \State Update $R[k] \gets R[k] + \mathcal{A}\text{'s frac. util}$
% \EndFor
% \end{algorithmic}
% \end{algorithm}

% \begin{theorem}
% For trajectories with $R(\tau) \leq \epsilon \Delta_0$, ORB-Fr2Int maintains:
% \[
% \text{Competitive ratio} \leq \gamma \cdot \left(1 + \delta\right) \cdot \left(1 + \epsilon \log \tfrac{\rho_{\max}}{\rho_{\min}}\right)
% \]
% where $\gamma$ is $\mathcal{A}$'s fractional ratio. By tuning $\delta, \epsilon \to 0$, approaches $\gamma$.
% \end{theorem}

% \subsubsection{Complete Integral Algorithms}
% Combine fractional algorithms with Fr2Int for trajectory selection:

% \[
% \begin{array}{c|c}
% \text{Prediction Type} & \text{Algorithm} \\
% \hline
% \text{Point} & \text{ORB-PP-b} = \text{ORB-Fr2Int}(\text{ORB-Frac-PP-b}) \\
% \text{Interval} & \text{ORB-IPA} = \text{ORB-Fr2Int}(\text{ORB-Frac-IPA}) \\
% \text{Untrusted} & \text{ORB-MIX} = \lambda \mathcal{A}_{\text{pred}} + (1-\lambda) \mathcal{A}_{\text{robust}}
% \end{array}
% \]

% \subsubsection{Robustness-Consistency Tradeoff (ORB-MIX)}

% \begin{algorithm}[t]
% \caption{ORB-MIX (Meta-Algorithm for Untrusted Predictions)}
% \label{alg:orb-mix}
% \begin{algorithmic}[1]
% \Require Trust param $\lambda \in [0,1]$, pred. alg. $\mathcal{A}_{\text{pred}}$, robust alg. $\mathcal{A}_{\text{robust}}$ (e.g., BAT-ORB)
% \For{arriving trajectory $\tau_t$}
%     \State Get $x^{\text{pred}}_t$ from $\mathcal{A}_{\text{pred}}$ (fractional)
%     \State Get $x^{\text{robust}}_t$ from $\mathcal{A}_{\text{robust}}$ (fractional)
%     \State $x_t \gets \lambda x^{\text{pred}}_t + (1-\lambda) x^{\text{robust}}_t$
%     \State Accept $x_t$ fraction (via Fr2Int for integral)
% \EndFor
% \end{algorithmic}
% \end{algorithm}

% \begin{theorem}
% ORB-MIX guarantees:
% \begin{itemize}
%     \item \textbf{Consistency:} $\frac{c}{\lambda}$ if prediction correct ($c$ = pred. alg. ratio)
%     \item \textbf{Robustness:} $\frac{\alpha}{1-\lambda}$ if prediction adversarial ($\alpha$ = robust alg. ratio)
% \end{itemize}
% and achieves near-optimal Pareto tradeoff between them.
% \end{theorem}

% \subsubsection{Summary of Guarantees}
% \[
% \begin{array}{l|c|c|c}
% \text{Algorithm} & \text{Prediction} & \text{Competitive Ratio} & \text{Properties} \\
% \hline
% \text{ORB-PP-b} & \text{Point } \hat{\rho} & 2 & \text{Simple, worst-case optimal} \\
% \text{ORB-PP-a} & \text{Point } \hat{\rho} & 1 + \min\{1, \hat{\omega}/\Delta_0\} & \text{Instance-optimal} \\
% \text{ORB-IPA} & \text{Interval } [\ell, u] & \alpha + 1 & \alpha = \text{base alg. ratio} \\
% \text{ORB-MIX} & \text{Untrusted} & \min(\frac{c}{\lambda}, \frac{\alpha}{1-\lambda}) & \text{Adaptive to prediction quality}
% \end{array}
% \]






% \subsection{chatgpt: SPAT-ORB: Succinct-Prediction-Aware Threshold Algorithms for Online Risk-Bounded Planning}
% \label{sec:spat-orb}

% We extend the threshold-based framework of online risk-bounded planning by integrating succinct predictions regarding future utility-to-risk ratios. Following recent work~\cite{daneshvaramoli2024competitive}, we introduce two primary forms of succinct predictions:
% \begin{itemize}
%     \item A \emph{point prediction} \(\hat{\rho}\), estimating the optimal utility-to-risk ratio.
%     \item An \emph{interval prediction} \([\rho_{\text{low}}, \rho_{\text{high}}]\), providing robustness against inaccurate estimates.
% \end{itemize}

% \subsubsection{Algorithm Description (Point Prediction)}

% Algorithm~\ref{alg:spat_point} outlines the SPAT-ORB algorithm when provided with a point prediction \(\hat{\rho}\).

% \begin{algorithm}[!t]
% \caption{SPAT-ORB Algorithm with Point Prediction}
% \label{alg:spat_point}
% \DontPrintSemicolon
% \KwIn{Candidate trajectories \(\mathcal{A}_t\), current risk budget \(\Delta_t\), global budget \(\Delta_0\), lower risk bound \(\delta_{\min}\), point prediction \(\hat{\rho}\)}
% \KwOut{Selected trajectory or \texttt{None}}
% Compute adaptive threshold:
% \[
% \Psi_t = \max\left\{
% \hat{\rho},\, \frac{\Delta_0}{\Delta_t}\ln\left(1+\frac{\Delta_0}{\delta_{\min}}\right)
% \right\}
% \]

% Filter feasible set:
% \[
% \mathcal{F}_t = \{\tau\in\mathcal{A}_t : R(\tau)\leq\Delta_t,\,\rho(\tau)\geq\Psi_t\}
% \]

% Select trajectory:
% \[
% \tau_{t,j_t} = \arg\max_{\tau\in\mathcal{F}_t}\rho(\tau)
% \quad\text{if}\;\mathcal{F}_t\neq\varnothing,\quad\text{otherwise}\;\texttt{None}.
% \]
% \end{algorithm}

% \subsubsection{Competitive Ratio Guarantee (Point Prediction)}

% \begin{theorem}[Point Prediction Competitive Ratio]
% \label{thm:spat_point_cr}
% Given a point prediction \(\hat{\rho}\), Algorithm~\ref{alg:spat_point} is \( (1+\min\{1,\omega\}) \)-competitive, where \(\omega\) represents the cumulative risk of trajectories with utility-to-risk ratio exactly equal to \(\hat{\rho}\) in the offline optimal solution.
% \end{theorem}

% \begin{proof}[Proof (adapted from~\cite{daneshvaramoli2024competitive})]
% Consider the optimal offline solution \(S^*\). Denote:
% \[
% \omega = \sum_{\tau \in S^*: \rho(\tau)=\hat{\rho}} R(\tau).
% \]

% \noindent\textbf{Case analysis:}

% \noindent\underline{Case 1 (\(\omega\geq1\)):} The threshold ensures at most half of the risk budget is spent on items equal to the prediction, guaranteeing at least half the utility compared to the offline optimum, thus yielding a 2-competitive ratio.

% \noindent\underline{Case 2 (\(\omega<1\)):} The threshold dynamically adapts to accept at least a fraction \(\frac{\omega}{1+\omega}\) of trajectories with predicted ratio, ensuring at least \(\frac{1}{1+\omega}\) of the optimal utility from higher ratio items. Combining, the competitive ratio is bounded by:
% \[
% 1 + \min\{1,\omega\}.
% \]

% This matches the known lower bound, confirming optimality.
% \end{proof}

% \subsubsection{Algorithm Description (Interval Prediction)}

% Algorithm~\ref{alg:spat_interval} presents SPAT-ORB with interval predictions, extending robustness.

% \begin{algorithm}[!t]
% \caption{SPAT-ORB Algorithm with Interval Prediction}
% \label{alg:spat_interval}
% \DontPrintSemicolon
% \KwIn{Candidate trajectories \(\mathcal{A}_t\), current risk budget \(\Delta_t\), global budget \(\Delta_0\), lower risk bound \(\delta_{\min}\), interval prediction \([\rho_{\text{low}}, \rho_{\text{high}}]\)}
% \KwOut{Selected trajectory or \texttt{None}}
% Compute adaptive threshold:
% \[
% \Psi_t = \max\left\{
% \rho_{\text{low}},\,\frac{\Delta_0}{\Delta_t}\ln\left(1+\frac{\Delta_0}{\delta_{\min}}\right)
% \right\}
% \]

% Filter feasible set:
% \[
% \mathcal{F}_t = \{\tau\in\mathcal{A}_t : R(\tau)\leq\Delta_t,\,\rho(\tau)\geq\Psi_t\}
% \]

% Select trajectory:
% \[
% \tau_{t,j_t} = \arg\max_{\tau\in\mathcal{F}_t}\rho(\tau)
% \quad\text{if}\;\mathcal{F}_t\neq\varnothing,\quad\text{otherwise}\;\texttt{None}.
% \]
% \end{algorithm}

% \subsubsection{Competitive Ratio Guarantee (Interval Prediction)}

% \begin{theorem}[Interval Prediction Competitive Ratio]
% \label{thm:spat_interval_cr}
% Given an interval prediction \([\rho_{\text{low}}, \rho_{\text{high}}]\), Algorithm~\ref{alg:spat_interval} achieves a competitive ratio of:
% \[
% 2 + \ln\left(\frac{\rho_{\text{high}}}{\rho_{\text{low}}}\right).
% \]
% \end{theorem}

% \begin{proof}[Proof (adapted from~\cite{daneshvaramoli2024competitive})]
% The algorithm partitions the problem into three categories:
% \begin{itemize}
%     \item Trajectories with ratios above \(\rho_{\text{high}}\): the algorithm secures a constant fraction (at least half) of their cumulative utility.
%     \item Trajectories within \([\rho_{\text{low}},\rho_{\text{high}}]\): Using a robust subroutine (e.g., CZL-ORB), it achieves a competitive ratio of \(1+\ln(\rho_{\text{high}}/\rho_{\text{low}})\).
%     \item Trajectories below \(\rho_{\text{low}}\): not accepted by the algorithm, maintaining competitiveness.
% \end{itemize}

% Combining these categories' performance, the total competitive ratio is:
% \[
% 1 + \left(1 + \ln\left(\frac{\rho_{\text{high}}}{\rho_{\text{low}}}\right)\right) = 2 + \ln\left(\frac{\rho_{\text{high}}}{\rho_{\text{low}}}\right).
% \]

% This ensures optimality in the context of interval-based predictions.
% \end{proof}





% \subsection{SPAT-ORB: Succinct-Prediction-Aware Threshold Algorithm for Online Risk-Bounded Planning}
% \label{sec:spat-orb}

% SPAT-ORB enhances the threshold-based framework by incorporating succinct predictions about future utility-to-risk ratios while maintaining worst-case guarantees. The algorithm blends online adaptability with limited foresight, expressed as either:
% \begin{itemize}
%     \item A point prediction \(\hat{\rho}\) of the optimal utility-to-risk ratio, or
%     \item An interval prediction \([\rho_{\text{low}}, \rho_{\text{high}}]\) for robustness
% \end{itemize}
% \bigskip
% \subsubsection{Algorithm Description}

% As shown in Algorithm~\ref{alg:SPAT}, SPAT-ORB modifies the threshold rule using predictions while preserving the same selection mechanism as CZL-ORB and BAT-ORB. The adaptive threshold ensures compatibility with the risk budget constraints.

% \subsubsection{Algorithm Assumptions}

% \begin{assumption}[Succinct Prediction] \label{asm:prediction}
%     The prediction \(\hat{\rho}\) (or \([\rho_{\text{low}}, \rho_{\text{high}}]\)) estimates the critical utility-to-risk ratio of the offline optimal solution, satisfying:
%     \[
%     \rho_{\min} \leq \hat{\rho} \leq \rho_{\max} \quad \text{(point)} \quad \text{or} \quad \rho_{\text{low}} \geq \rho_{\min}, \rho_{\text{high}} \leq \rho_{\max} \quad \text{(interval)}
%     \]
%     where \(\rho_{\min}, \rho_{\max}\) are the same bounds used in CZL-ORB.
% \end{assumption}

% \begin{algorithm}[!t]
% \caption{(SPAT-ORB) Threshold Online Algorithm}
% \label{alg:SPAT}
% \DontPrintSemicolon
% \KwIn{Candidate set \(\mathcal{A}_t = \{\tau_{t,1}, \dots, \tau_{t,N_t}\}\), current risk budget \(\Delta_t\), prediction \(\hat{\rho}\) or \([\rho_{\text{low}}, \rho_{\text{high}}]\), total budget \(\Delta_0\), lower risk bound \(\delta_{\min}\)}
% \KwOut{Selected trajectory \(\tau_{t,j_t} \in \mathcal{A}_t\), or \texttt{None}}
% \BlankLine

% Compute adaptive threshold: 
% \[
% \Psi_t \gets \max\left\{
%     \hat{\rho},\; 
%     \frac{\Delta_0}{\Delta_t}\ln\!\left(1+\tfrac{\Delta_0}{\delta_{\min}}\right)
% \right\} \quad \text{(point)}
% \]
% \[
% \text{or} \quad \Psi_t \gets \max\left\{
%     \rho_{\text{low}},\;
%     \frac{\Delta_0}{\Delta_t}\ln\!\left(1+\tfrac{\Delta_0}{\delta_{\min}}\right)
% \right\} \quad \text{(interval)}
% \]

% Filter feasible set:
% \[
% \mathcal{F}_t \gets \left\{ \tau \in \mathcal{A}_t \;\middle|\;
%     R(\tau) \leq \Delta_t \text{ and } \frac{U(\tau)}{R(\tau)} \geq \Psi_t
% \right\}
% \]

% \uIf{\(\mathcal{F}_t = \varnothing\)}{
%     \KwRet \texttt{None} \tcp*{Fallback to BAT-ORB if needed}
% }
% \Else{
%     \(\tau_{t,j_t} \gets \arg\max_{\tau \in \mathcal{F}_t} U(\tau)\) \tcp*{Maximize utility}
%     \KwRet \(\tau_{t,j_t}\)
% }
% \end{algorithm}

% \subsubsection{Competitive Ratio Guarantee}

% \begin{theorem}
% \label{thm:spat_cr}
% SPAT-ORB maintains the same competitive ratio as BAT-ORB:
% \[
% \boxed{
% \mathrm{CR}_{\mathrm{SPAT}} = \ln\!\left(\tfrac{\Delta_0}{\delta_{\min}}\right) + 2
% }
% \]
% while improving the average-case performance when predictions are accurate.
% \end{theorem}

% \begin{proof}
% The worst-case analysis follows BAT-ORB's proof, as the fallback threshold \(\frac{\Delta_0}{\Delta_t}\ln(1+\frac{\Delta_0}{\delta_{\min}})\) ensures the original competitive ratio. Accurate predictions only improve the threshold selectivity without violating the budget constraints.
% \end{proof}





% \subsection{SPAT-ORB: Succinct-Prediction-Aware for Online Risk-Bounded Planning}
% \label{sec:spap}
% %===============================================================

% Purely online algorithms treat the future as \emph{adversarial},
% thereby leaving considerable slack in the risk budget Fig.~\ref{fig:enter-gap method3}.
% In practice, the ego vehicle often has \emph{partial} foresight
% (e.g.\ short-horizon traffic forecasts or HD-map priors) that can be
% compressed into a \emph{single informative scalar} and exploited to raise
% efficiency without sacrificing worst-case guarantees.
% \begin{figure}[!h]
%     \centering
%     \includegraphics[width=0.8\linewidth]{Figures/gap_for_method3.png}
%     \caption{Given a risk budget with 20, the online algorithm is not utilizing it due to lack of future information and worst-case analysis.}
%     \label{fig:enter-gap method3}
% \end{figure}
% \subsubsection{Succinct prediction}

% Let
% \[
% \hat{\rho}\quad\bigl(\text{or }[\underline{\rho},\overline{\rho}]\bigr)
% \]
% be a \textbf{succinct prediction} of the \emph{critical progress-per-risk
% ratio} attained by the offline optimum in the current scene
% (\cite{daneshvaramoli2024competitivealgorithmsonlineknapsack}).
% Point prediction~$\hat{\rho}$ yields highest consistency; an interval
% $[\underline{\rho},\overline{\rho}]$ adds robustness to estimation error.

% % \vspace{2pt}
% % \begin{center}\small
% % \renewcommand{\arraystretch}{1.05}
% % \begin{tabular}{p{0.23\linewidth}p{0.65\linewidth}}
% % \toprule
% % \emph{Source} & \emph{How to estimate} \\ \midrule
% % Short-term traffic forecast & Graph-GRU on lane-graph density → mean free-space → $\hat{\rho}$ \\
% % Scene semantics & Decision tree on intersection type / lane count \\
% % Historical ORBit logs & Min.\,$P/R$ look-up conditioned on \{town, time-of-day\} \\ \bottomrule
% % \end{tabular}
% % \end{center}

% At decision epoch~$t$ define
% \[
% L \;=\; \ln\!\Bigl(1+\frac{\Delta_0}{\delta}\Bigr),\qquad\!
% \beta_t^{\text{SPAP}} \;=\;
% \begin{cases}
% \displaystyle\max\!\bigl\{\hat{\rho},\tfrac{\Delta_0}{\Delta_t}L\bigr\}, & 
% \text{point},\\[4pt]
% \displaystyle\max\!\bigl\{\underline{\rho},\tfrac{\Delta_0}{\Delta_t}L\bigr\},
% & \text{interval}.
% \end{cases}
% \tag{S\textsubscript{1}}
% \]

% \begin{algorithm}[htbp]
% \caption{SPAP (epoch $t$)}
% \label{alg:SPAP}
% \DontPrintSemicolon
% \KwIn{$\Delta_t$, lattice $G_t$, prediction $\hat{\rho}$ or $[\underline{\rho},\overline{\rho}]$}
% \KwOut{Selected segment $\tau_{t,j_t}$}
% $\beta_t \leftarrow$ formula~\eqref{S1}\;
% Generate $\mathcal{A}_t$ on $G_t$\;
% $\mathcal{F}_t \leftarrow \{\tau\!\in\!\mathcal{A}_t\mid
%           R(\tau)\!\le\!\Delta_t,\;
%           P(\tau)/R(\tau)\!\ge\!\beta_t\}$\;
% \If{$\mathcal{F}_t=\varnothing$}{\textbf{fallback} $\leftarrow$ BATS; \KwRet result of BATS}
% Select $\tau_{t,j_t} \leftarrow \arg\!\max_{\tau\in\mathcal{F}_t} P(\tau)$\;
% $\Delta_{t+1}\leftarrow\Delta_t-R(\tau_{t,j_t})$\;
% \KwRet $\tau_{t,j_t}$\;
% \end{algorithm}

% \subsubsection{Competitive-ratio guarantee}

% \begin{proposition}[Consistency \& robustness]
% \label{prop:SPAP}
% Let $\delta\le\min_{t,r}R_{rt}$.  
% SPAP enjoys
% \[
% \text{CR}_{\text{worst}} \;\le\;
% \ln\!\Bigl(\tfrac{\Delta_0}{\delta}\Bigr)+2
% \qquad\text{(robustness)}
% \]

% and, if $\hat{\rho}\!\ge\!P^*/R^*$,
% \[
% \text{CR}_{\text{consist}} \;=\; 1.
% \]

% \end{proposition}

% \begin{proof}[Sketch]
% When the prediction is \emph{under-optimistic}
% ($\hat{\rho}<P^*/R^*$) the threshold in~\eqref{S1} coincides with the BATS
% threshold; the proof of Theorem~\ref{thm:compet_ratio_full} applies verbatim,
% yielding the logarithmic bound.
% When $\hat{\rho}\!\ge\!P^*/R^*$ the filter never rejects any
% OPT segment, whence SPAP replicates OPT exactly ($\text{CR}=1$).
% \end{proof}

% \subsubsection{Meta-switch for degraded predictions}

% Maintain an empirical error
% $e_t=\lvert\hat{\rho}-\tfrac{P(\tau_{t,j_t})}{R(\tau_{t,j_t})}\rvert$.
% If the running average $\bar{e}_t$ exceeds a tolerance~$\varepsilon$ for
% $k$ consecutive steps, disable prediction and fall back to BATS until
% $\bar{e}_t\!<\!\varepsilon$ again (``MIX'' strategy~\cite{sun2024succinct}).

% \subsubsection{Implementation remarks}

% \begin{enumerate}[leftmargin=10mm,label=(\roman*)]
% \item \textbf{Runtime.}  SPAP adds \emph{O(1)} work over BATS
%       (just compare with $\hat{\rho}$), so 10–20 Hz replanning is preserved.
% \item \textbf{Parameter choice.}  $\varepsilon$ may be set to the
%       75$^{\text{th}}$ percentile of historical $\lvert P/R-\hat{\rho}\rvert$;
%       $k=3$–5 is sufficient to filter transient spikes.
% \item \textbf{Safety.}  Because $\beta_t^{\text{SPAP}}\!\ge\!\tfrac{\Delta_0}{\Delta_t}L$
%       by construction, SPAP never violates \eqref{eq:itm-risk}.
% \end{enumerate}

% \subsubsection{Planned evaluation}

% \begin{itemize}[leftmargin=8mm]
% \item \textbf{Oracle prediction study:} $\hat{\rho}=P^*/R^*$ shows the upper
%       performance bound.
% \item \textbf{Noise sweep:} multiply $\hat{\rho}$ by $(1+\epsilon)$,
%       $\epsilon\!\sim\!\mathcal{U}[-0.3,0.3]$, plot travel-time and CR.
% \item \textbf{Interval width study:} 
%       $u/\ell\!\in\!\{1.05,1.2,1.5\}$ to quantify robustness vs.~consistency.
% \end{itemize}

% \noindent
% Complete experimental results appear in Section~\ref{sec:results}.


% %---------------------------------------------------------------
% \subsubsection{Full proof of Proposition~\ref{prop:SPAP}}
% %---------------------------------------------------------------
% \begin{proof}
% Fix an input sequence $\mathcal{M}$ of candidate sets
% $\bigl(\mathcal{A}_1,\dots,\mathcal{A}_T\bigr)$ and let
% \smash{$\text{OPT}(\mathcal{M})=(P^*,R^*)$} denote the progress--risk pair
% achieved by the offline optimum.
% Recall the notations

% \[
% L := \ln\!\Bigl(1+\frac{\Delta_0}{\delta}\Bigr),\qquad
% \beta_t^{\textsc{B}} := \frac{\Delta_0}{\Delta_t}\,L
% \quad
% \text{(BATS threshold)},\qquad
% \beta_t := \max\{\hat{\rho},\beta_t^{\textsc{B}}\}
% \quad
% \text{(SPAP threshold).}
% \]

% We treat \textsc{SPAP}(\(\hat{\rho}\)) with \emph{point} prediction; the
% interval version follows verbatim by replacing $\hat{\rho}$ with the
% lower endpoint $\underline{\rho}$.  Two exhaustive cases arise.

% %...............................................................
% \paragraph{\textbf{Case~1:}\ $\hat{\rho}\le P^*/R^*$ (good or
% under-optimistic prediction).}

% Then $\beta_t=\beta_t^{\textsc{B}}$ for \emph{all} epochs $t$, hence
% \textsc{SPAP} executes \emph{exactly} the same accept/reject rule as BATS.
% Consequently the progress of SPAP, $P_{\textsc{S}}$, equals the progress of
% BATS, $P_{\textsc{B}}$, and the logarithmic competitive bound of
% Theorem~\ref{thm:compet_ratio_full} applies:
% \[
% \frac{\text{OPT}}{P_{\textsc{S}}}
% =
% \frac{\text{OPT}}{P_{\textsc{B}}}
% \;\le\;
% L+2.
% \]

% %...............................................................
% \paragraph{\textbf{Case~2:}\ $\hat{\rho}> P^*/R^*$ (over-optimistic
% prediction).}

% SPAP may run in two \emph{sub-modes}:

% \smallskip
% \noindent\emph{(a) Filter succeeds for every epoch.}
% For any segment $(\tau)$ selected by OPT we have
% \(
% P(\tau)/R(\tau)\le P^*/R^* < \hat{\rho}
% \le\beta_t
% \),
% so OPT’s path violates the filter and \emph{cannot} be realised in this
% sub-mode.  Instead SPAP either (i) finds no feasible segment and invokes
% its built-in \textbf{fallback} to BATS, or (ii) chooses segments whose
% $P/R\ge\beta_t>\beta_t^{\textsc{B}}$.
% In branch (ii) the risk spent by SPAP in any phase is \emph{strictly
% smaller} than that spent by BATS, while the progress-per-risk is
% \emph{larger}; the phase analysis of
% Theorem~\ref{thm:compet_ratio_full} therefore yields a ratio \emph{no
% larger} than $L+2$.
% If branch (i) is triggered, the control returns to the fallback, i.e.\ to
% BATS itself, and again the ratio is $\le L+2$.

% \smallskip
% \noindent\emph{(b) Filter fails in some epoch and SPAP switches to BATS.}
% From the switching epoch onward the algorithm behaves exactly like BATS
% and inherits its bound.

% \smallskip
% In all sub-cases of Case~2 the competitive ratio is bounded by $L+2$.
% Combining with Case~1 establishes the \textbf{robustness} part of the
% proposition:
% \[
% \text{CR}_{\text{worst}} \;\le\; L+2.
% \]

% %...............................................................
% \paragraph{\textbf{Consistency.}}
% If the prediction is \emph{over-conservative} but still satisfies
% $\hat{\rho}\ge P^*/R^*$, every segment of OPT passes the filter
% ($P/R\ge\beta_t$) because $\beta_t=\hat{\rho}$ dominates
% $\beta_t^{\textsc{B}}$.
% SPAP can therefore mimic the optimal path exactly and attains
% $P_{\textsc{S}}=P^*$, i.e.\ $\text{CR}_{\text{consist}}=1$.

% \medskip
% \noindent
% Thus SPAP satisfies both robustness and consistency claims in
% Proposition~\ref{prop:SPAP}.
% \end{proof}


% %===============================================================
% \subsubsection{Horizon-Aware Risk Utilisation (Optional Heuristic)}
% \label{sec:horizon-aware}
% %===============================================================

% \paragraph{Intuition.}
% Let $d_t = d_{\text{goal}}(s_t)$ be the remaining geometric distance
% to the goal at epoch~$t$, and let $\Delta_t$ be the residual risk budget.
% If $d_t$ is \emph{small} but $\Delta_t$ is still \emph{large},
% a conservative threshold wastes capacity that can no longer be recovered
% once the mission terminates.
% Hence we would like to \emph{relax} the progress-per-risk threshold as we
% approach the goal.

% \paragraph{Budget-per-distance schedule.}
% Define the \emph{target spending rate}
% \[
% \varpi := \frac{\Delta_0}{d_0}   \qquad
% \text{(risk units per metre needed if budget is used uniformly).}
% \]
% Whenever
% \(
% \Delta_t > \xi\,\varpi\,d_t
% \)
% for some slack factor $\xi>1$ (e.g.\ $\xi=1.2$), the planner is
% \textbf{behind schedule} in consuming risk, so it may accept lower
% $P/R$ ratios.

% %---------------------------------------------------------------
% \subsubsection*{Variant A  –  Threshold rescaling for SPAP/BATS}
% Replace the standard threshold $\beta_t$ by
% \[
% \beta_t^{\text{HA}}
% =\,
% \left(1-\eta_t\right)\,\beta_t
% \quad\text{with}\quad
% \eta_t
% =\min\!\Bigl\{1,\,
%       \zeta\,\bigl(\tfrac{\Delta_t}{\varpi d_t}-1\bigr)_{+}\Bigr\},
% \]
% where $(x)_{+}=\max\{0,x\}$ and $\zeta\in(0,1)$ is a tuning constant
% ($\zeta=0.5$ is effective in practice).
% Thus as soon as $\Delta_t$ exceeds the scheduled quota
% $\varpi d_t$, the required $P/R$ ratio is linearly reduced,
% encouraging acceptance of higher-risk, faster segments.

% \begin{enumerate}[leftmargin=8mm,label=(\roman*)]
% \item If $\Delta_t=\varpi d_t$ (on schedule), $\eta_t=0$ and we fall back to
%       the original SPAP or BATS rule—\emph{no loss of robustness}.
% \item If $\Delta_t\gg\varpi d_t$ (large slack), $\eta_t\uparrow1$ and the
%       filter becomes almost inactive; the ego vehicle spends the excess risk.
% \end{enumerate}

% \paragraph{Competitive-ratio impact.}
% Because $\beta_t^{\text{HA}}\le\beta_t$, the worst-case ratio can at most
% double (attained when the slack heuristic triggers on an adversarial input).
% Empirically (Section~\ref{sec:results}) we observe a $\approx15\%$
% travel-time gain with no safety violations.

% %---------------------------------------------------------------
% \subsubsection*{Variant B  –  Exact embedding in IT-MILP}
% Add a soft “use-or-lose” term to the MILP objective:

% \[
% \max\;\Bigl\{
%   \sum_{(i,j),\nu} X_{ij}^{\nu} P_{ij}^{\nu}
%   \;+\;
%   \lambda
%   \bigl(\Delta_t - \delta_{\text{max}}\bigr)
% \Bigr\},
% \tag{\ref{eq:itm-objective}$^{\text{HA}}$}
% \]

% where $\lambda>0$ trades off \emph{progress} vs.\ \emph{risk utilisation}.
% The constraint set \eqref{eq:itm-flow1}–\eqref{eq:itm-bounds} remains
% unchanged.
% A moderate $\lambda$ ($0.1$–$0.2$ times the average progress per segment)
% already steers the solver towards paths that
% consume residual budget when $d_t$ is small, with \emph{no}
% competitive-ratio penalty because the objective only strengthens the
% optimisation.

% \paragraph{Implementation tip.}
% Keep $\lambda$ adaptive,
% e.g.\ $\lambda_t = \lambda_0\!\bigl(1-\tfrac{d_t}{d_0}\bigr)$,
% so the incentive to spend risk ramps up smoothly as the goal nears.

% \paragraph{When to activate.}
% Enable horizon awareness only after 60–70 \% of the total progress
% (heuristic); before that the original SPAP/IT-MILP rules are safer.

% ---

% This horizon-aware tweak is orthogonal to the succinct-prediction idea:
% you can combine both (SPAP + Variant A) for even better efficiency, or
% apply Variant B inside the IT-MILP solve.

% Need a simulation plot or further theoretical bound?—just let me know!






\subsection{\textbf{ITM-ORB}: Integrated Threshold MILP for Online Risk-Bounded Planning}
\label{sec:ITMILP}
%===============================================================

In the previous online algorithms, 
The CZL-ORB Algorithm \ref{alg:CZL} and BAT-ORB Algorithm~\ref{alg:BATS}, we first
\emph{sample} the global risk budget
$\Delta$ at fixed resolutions
$(0.1\,\Delta,0.2\,\Delta,\dots,\Delta)$,
generates one candidate trajectory for each sampled
$\delta_{\text{n}}$ by solving the CSP problem as defined in Problem \ref{eq:csp}, and finally applies an online knapsack algorithm to pick a
single candidate.
Although simple, {uniform sampling is sub-optimal}:  
the best risk allocation may lie anywhere in the \emph{continuous} interval
$[0.1\Delta,0.2\Delta]$ (e.g.\ at $0.16\Delta$), so the discretized search
space can miss high-quality solutions.

On the other hand, our proposed method in this Section,  \emph{merges} candidate generation and selection into a
{single mixed-integer optimization} that
\emph{simultaneously} chooses the path and the risk parameter
    $\delta_{n}$.  
The online threshold inequality in Algorithm \ref{alg:CZL} and Algorithm \ref{alg:BATS}, is encoded directly as a linear constraint,
eliminating the need for exogenous sampling.
This compact MILP therefore \emph{integrates} trajectory
generation and threshold-based selection, avoiding the sub-optimality of
uniform sampling and yielding a search space that is both continuous in
$\Delta_b$ and combinatorial in the path variables~$x^{\nu}_{ij}$, in a
single optimization program. Algorithm \ref{alg:ITM-ORB} demonstrates this approach in steps. 

\begin{equation}
\label{eq:ITMILP}
\begin{aligned}
\text{\bf ITM-ORB}(\Delta_t):\quad
& \underset{x_{ij}^{\nu},\,\delta_t}{\text{\bf maximize}}
& & \sum_{(i,j)\in E} \ \sum_{\nu\in\mathcal{V}} x_{ij}^{\nu}\, r_{ij}^{\nu} \\
& \text{\bf subject to}
& & \text{constraints \eqref{eq:IT_flow}--\eqref{eq:IT_bounds}}~.
\end{aligned}
\end{equation}

\begin{subequations}
\label{eq:ITMILP_constraints}
\begin{align}
& \sum_{\nu\in\mathcal{V}}
   \Bigl(\sum_{(k,j)\in E} x_{kj}^{\nu} - \sum_{(i,k)\in E} x_{ik}^{\nu}\Bigr)
   =
   \begin{cases}
      \;\;\;1, & k=v_s,\\[1pt]
      -1, & k=v_g,\\[1pt]
      \;\;\;0, & \text{otherwise},
   \end{cases}
\tag{\ref{eq:ITMILP}a}\label{eq:IT_flow}\\[2mm]
& \sum_{(i,j)\in E}\ \sum_{\nu\in\mathcal{V}} x_{ij}^{\nu}\, r_{ij}^{\nu}
  \;\le\; \delta_t,
\tag{\ref{eq:ITMILP}b}\label{eq:IT_risk}\\[2mm]
& \sum_{(i,j)\in E} \ \sum_{\nu\in\mathcal{V}} x_{ij}^{\nu}\, u_{ij}^{\nu}
  \;\ge\; \Psi_t\delta_t,
\tag{\ref{eq:ITMILP}c}\label{eq:IT_thresh}\\[2mm]
& \sum_{\nu\in\mathcal{V}} x_{ij}^{\nu} \;\le\; 1,
   \qquad \forall (i,j)\in E,
\tag{\ref{eq:ITMILP}d}\label{eq:IT_unique}\\[2mm]
& 0 \le \delta_t \le \Delta_t,\quad
  x_{ij}^{\nu}\in\{0,1\},\ \ \forall (i,j)\in E,~\forall \nu\in\mathcal{V}.
\tag{\ref{eq:ITMILP}e}\label{eq:IT_bounds}
\end{align}
\end{subequations}

\noindent\textit{Interpretation.}
Constraint~\eqref{eq:IT_flow} enforces unit \(v_s\!\to\!v_g\) flow aggregated over labels, ensuring a single continuous path.
Constraint~\eqref{eq:IT_risk} limits the \emph{consumed} risk by the chosen path to the epoch allocation \(\delta_t\).
Constraint~\eqref{eq:IT_thresh} imposes a state-dependent \emph{utility-per-risk} ratio: the total utility of the path must exceed \(\Psi_t\) times the allocated risk.
Constraint~\eqref{eq:IT_unique} prevents assigning multiple labels to the same geometric edge.
% \footnote{If velocity is already encoded in edge identity, drop \eqref{eq:IT_unique}.}
Bounds and integrality are in~\eqref{eq:IT_bounds}.

\paragraph*{Property (Budget Tightness).}
At any optimum of \eqref{eq:ITMILP}, \(\delta_t\) equals the realized path risk:
\[
\delta_t^\star \;=\; \sum_{(i,j),\nu} x_{ij}^{\nu\star}\, r_{ij}^{\nu}.
\]
Indeed, decreasing \(\delta_t\) to this value relaxes~\eqref{eq:IT_thresh} and preserves feasibility of~\eqref{eq:IT_risk} while leaving the objective unchanged.

\paragraph*{Feasibility.}
A feasible solution exists iff there is a path \(\pi\) with 
\(\sum r_{ij}^\nu \le \Delta_t\) and 
\(\sum u_{ij}^\nu \ge \Psi_t \sum r_{ij}^\nu\).
When \(\Psi_t=0\), \eqref{eq:ITMILP} reduces to a risk-bounded utility maximization identical in structure to the CSP with a fixed budget.

% \subsubsection{\textbf{Discussion of ITM-ORB Formulation}}

% The optimization problem defined in~\eqref{eq:ITMILP} integrates trajectory selection and adaptive risk budgeting into a single MILP. The 
% objective function is to maximize the total utility (reduction in travel-time). Constraints \eqref{eq:IT_flow1}--\eqref{eq:IT_flow2} are for flow conservation. These constraints enforce continuity of the trajectory, ensuring exactly one valid path from the start vertex $V_s$ to the goal vertex $V_f$ for each vehicle mode. {Constraint \eqref{eq:IT_risk} (Risk budget constraint)} the total accumulated risk of the chosen trajectory segments must not exceed the endogenous budget $\delta_t$. Unlike previous methods with pre-specified budgets, ITM-ORB simultaneously optimizes the budget allocation $\delta_t$ itself. {Constraint \eqref{eq:IT_thresh} (Adaptive threshold constraint):} this key constraint explicitly encodes the adaptive threshold rule from the threshold-based online algorithms. It requires that the total utility of the selected trajectory must exceed the product of the adaptive threshold $\Psi_t$ and the risk budget $\delta_t$:
% \[
% \sum_{(i,j)\in E}\sum_{\nu\in\mathcal{V}}
% x^\nu_{ij}\,u^\nu_{ij} \;\geq\; \Psi_t\,\delta_t.
% \]
% This condition guarantees that the selected trajectory meets or surpasses the dynamic utility-to-risk ratio threshold determined by the current fraction of remaining risk budget, $z(t)$. Constraint \eqref{eq:IT_bounds} (Variable bounds) this ensures feasibility by restricting the endogenous risk budget $\Delta_b$ to be within the global risk budget $[0,\Delta_0]$, and sets binary constraints on the path selection variables $X_{ij}^{\nu}$, indicating whether a trajectory segment $(i,j)$ with mode $\nu$ is chosen. 
% By combining trajectory selection and adaptive budget allocation in a single, coherent optimization, ITM-ORB overcomes the limitations of discretized sampling and significantly improves trajectory quality and risk management.

% % \subsubsection{Variables and notation}

% % \begin{center}
% % \renewcommand{\arraystretch}{1.05}
% % \begin{tabular}{cl}
% % $X_{ij}^{\nu}\in\{0,1\}$ & binary var.; edge $(i,j)\in E$ with motion primitive
% % $\nu\in\mathcal{V}$ is \emph{used}\\
% % $\delta_{\text{max}}\in[0,\Delta]$ & \textit{decision var.}; risk bound chosen
% % \emph{online} at the current planning epoch\\
% % $P_{ij}^{\nu}$ & progress (reward) accrued by taking edge $(i,j)$ with
% % primitive~$\nu$ \\
% % $\Phi_{ij}^{\nu}$ & risk contributed by the same edge \\
% % $z\in[0,1]$ & fraction of the \emph{global} budget already consumed,
% % $z(t)=1-\tfrac{\Delta_t}{\Delta_0}$\\
% % $\Psi(z)$ & threshold function
% % $\displaystyle\Psi(z)=(ue/l)^z\,(l/e)$ \ (\emph{cf.}\,\eqref{eq:adaptive_threshold})
% % \end{tabular}
% % \end{center}

% %---------------------------------------------------------------
% % \subsubsection{MILP formulation}
% % %---------------------------------------------------------------
% % %---------------------------------------------------------------
% % \begin{equation}\label{eq:ITMILP}
% % \begin{aligned}
% % \textbf{ITM-ORB}(\Delta_0)
% %   \quad\underset{X^\nu_{ij},\,\Delta_b}{\text{\bf Max}}
% %   & \;\sum_{(i,j)\in E} \sum_{\nu\in\mathcal{V}}
% %       X^\nu_{ij}\,P^\nu_{ij} \\[-2pt]
% %   &\textbf{s.t.}
% % \end{aligned}
% % \end{equation}

% % \begin{subequations}\label{eq:ITMILP_constraints}
% % \begin{align}
% % &\sum_{(i,j)\in E} X^\nu_{ij}
% %  -\sum_{(j,i)\in E} X^\nu_{ji}=0,
% %  &&\forall i\notin\{V_s,V_f\},~\forall\nu
% %  \tag{\ref{eq:ITMILP}a}\label{eq:IT_flow1}\\[2pt]
% % &\sum_{(V_s,j)\in E} X^\nu_{V_s j}=1,\quad
% %  \sum_{(i,V_f)\in E} X^\nu_{i V_f}=1,
% %  &&\forall\nu
% %  \tag{\ref{eq:ITMILP}b}\label{eq:IT_flow2}\\[2pt]
% % &\sum_{(i,j)\in E}\sum_{\nu\in\mathcal{V}}
% %    X^\nu_{ij}\,R^\nu_{ij}\;\le\;\Delta_b
% %  && \tag{\ref{eq:ITMILP}c}\label{eq:IT_risk}\\[2pt]
% % &\sum_{(i,j)\in E}\sum_{\nu\in\mathcal{V}}
% %    X^\nu_{ij}\,P^\nu_{ij}\;\ge\;
% %    \Psi\!\bigl(z(t)\bigr)\,\Delta_b
% %  && \tag{\ref{eq:ITMILP}d}\label{eq:IT_thresh}\\[2pt]
% % &0\le \Delta_b \le \Delta_0,\qquad
% %  X^\nu_{ij}\in\{0,1\},
% %  &&\forall(i,j)\in E,~\forall\nu
% %  \tag{\ref{eq:ITMILP}e}\label{eq:IT_bounds}
% % \end{align}
% % \end{subequations}



% % % \subsubsection{Online execution}

% % % At each planning epoch the IT-MILP is solved on the \emph{current} lattice
% % % graph (typically a few hundred edges).  
% % % Because $\delta_{\text{max}}$ is a continuous variable, the solver explores
% % % \textit{all} admissible risk allocations in one shot, avoiding the
% % % sub-optimality of uniform sampling.  
% % % Empirically (Section~\ref{sec:results}) a Gurobi solve with
% % % $|\mathcal{V}|=3$ velocity profiles returns within $20$–$40$\,ms on a desktop
% % % CPU—fast enough for 5–10\,Hz replanning in CARLA.

% % % %---------------------------------------------------------------
% % % %  Algorithm 2 – IT-MILP Online Planner
% % % %---------------------------------------------------------------

\begin{algorithm}[!t]
\caption{ITM-ORB Online Planner }
\label{alg:ITM-ORB}
\DontPrintSemicolon
\KwIn{\(\text{ at time } t\); Graph \(G\); edge utilities \(u_{ij}^{\nu}\) and risks \(r_{ij}^{\nu}\);  \(\forall (i,j)\in E, \ \  \forall \nu\in \mathcal{V}\);
      global budget \(\Delta_0\); current budget \(\Delta_t\);}
\KwOut{optimized trajectory \(\tau^*_t\) and risk  \(\delta^*_n\)}
\BlankLine

\textbf{Step 1.  Formulate optimization.}\;
\quad Build the MILP \textbf{ITM-ORB}\((\Delta_t,z(t))\) given in
Eqs.~\eqref{eq:ITMILP}–\eqref{eq:ITMILP_constraints}.\;

\textbf{Step 2.  Solve MILP.}\;
\quad Obtain optimal decision variables
\(\{X_{ij}^{\nu\star}\}\) and endogenous budget \(\Delta_b^{\star}\).\;

\textbf{Step 3.  Feasibility check.}\;
\If{\textbf{ITM-ORB} is feasible}{
  \textbf{Step 4.  Extract path.}\;
  \quad \(\tau_t \leftarrow \{(i,j,\nu)\mid X_{ij}^{\nu\star}=1\}\).\;

  \textbf{Step 5.  Commit risk and update budget.}\;
  \quad \(\Delta_b\leftarrow\Delta_b^{\star}\), \quad
        \(\Delta_{t+1}\leftarrow\Delta_t-\Delta_b\).\;

  \KwRet{\(\langle\tau_t,\,\Delta_b\rangle\)}
}
\Else{
  \KwRet{\texttt{None}} \tcp*[f]{No admissible trajectory under current budget}
}
\end{algorithm}

% % % % \begin{algorithm}[!h]
% % % % \caption{IT-MILP: Integrated-Threshold MILP Planner (epoch $t$)}
% % % % \label{alg:ITMILP}
% % % % \DontPrintSemicolon
% % % % \KwIn{Residual budget $\Delta_t$, lattice graph $G_t=(V,E)$,
% % % %       velocity set $\mathcal{V}$, progress $P_{ij}^{\nu}$,
% % % %       risk $\Phi_{ij}^{\nu}$, threshold function $\Psi(\cdot)$}
% % % % \KwOut{Selected segment sequence $\pi_t$ (prefix of a path)}
% % % % \BlankLine
% % % % %-----------------------------------------------------------
% % % % \textbf{1.~Build MILP model}\\
% % % % Define binary variables $X_{ij}^{\nu}$ for $(i,j)\!\in\!E,\;\nu\!\in\!\mathcal{V}$\;
% % % % Define continuous variable $\delta_{\text{max}}\in[0,\Delta_t]$\;
% % % % Set objective \eqref{eq:itm-objective}; add constraints
% % % % \eqref{eq:itm-flow1}--\eqref{eq:itm-bounds}\;
% % % % \vspace{1pt}

% % % % %-----------------------------------------------------------
% % % % \textbf{2.~Solve MILP}

% % % % Invoke solver (e.g.\ Gurobi) with a time limit $\tau_{\text{solve}}$ \tcp*{~20--40 ms}

% % % % \eIf{MILP returns an \emph{optimal} or \emph{feasible} solution}{
% % % %     Extract path $\pi_t$ from positive $X_{ij}^{\nu}$\;
% % % %     Compute risk spent $r_t\!=\!\sum_{(i,j),\nu}X_{ij}^{\nu}\Phi_{ij}^{\nu}$\;
% % % % }{
% % % %     \textbf{fallback}: call BATS\;   \tcp*{guarantees progress if MILP fails}
% % % % }

% % % % %-----------------------------------------------------------
% % % % \textbf{3.~Execute \& update}\\
% % % % Push first $k$ steps of $\pi_t$ to the low-level controller
% % % % ($k$ chosen s.t.\ replanning rate $\ge f_{\text{plan}}$)\;
% % % % $\Delta_{t+1}\,\leftarrow\,\Delta_t - r_t$\;
% % % % \KwRet $\pi_t$ and updated budget $\Delta_{t+1}$\;
% % % % \end{algorithm}






\subsubsection{Competitive Ratio Guarantee}

The competitive ratio of ITM-ORB depends directly on the chosen threshold function \(\Psi(z)\). Below, we establish a unified competitive-ratio guarantee, applicable whether the threshold is derived from CZL-ORB or BAT-ORB.

\begin{theorem}[Competitive Ratio of ITM-ORB]
\label{thm:itm_competitive_ratio}
Let \(\Psi(z)\) be the adaptive threshold function employed in the ITM-ORB formulation. Then ITM-ORB inherits exactly the same competitive ratio as the underlying threshold-based method:
\[
\mathrm{CR}_{\text{ITM-ORB}} = 
\begin{cases}
\displaystyle 2+\ln\left(\frac{\rho_{\max}}{\rho_{\min}}\right), & \text{if CZL-ORB} \\[8pt]
\displaystyle 2 + \frac{1}{\ln(\Delta_0/\delta_{\min})}, & \text{if BAT-ORB}
\end{cases}
\]
\end{theorem}

\begin{proof}[\textbf{Proof}]
ITM-ORB explicitly incorporates the adaptive threshold condition as a linear constraint:
\[
\sum_{(i,j)\in E}\ \sum_{\nu\in\mathcal{V}} x_{ij}^{\nu}\ u_{ij}^{\nu}\;\ge\;\Psi(z(t))\,\delta_t,
\]
where \(\delta_t\) is the endogenous risk allocation. This constraint ensures that the trajectory selected by ITM-ORB strictly satisfies the same adaptive threshold condition as the online algorithm whose threshold function \(\Psi_t\) it adopts.
 Two cases are considered based on the choice of threshold function \(\Psi_t\):

\begin{description}[leftmargin=4mm,itemsep=3pt]
    \item[\normalfont\textbf{Case 1 (CZL-ORB Threshold):}] 
    If ITM-ORB utilizes the CZL-ORB threshold, then at each epoch the selected trajectory satisfies:
    \[
    \frac{\sum_{(i,j),\nu}x_{ij}^{\nu}\ \ u_{ij}^{\nu}}{\sum_{(i,j),\nu}x_{ij}^{\nu}\ \ r_{ij}^{\nu}}\;\ge\;\Psi_t^{\tiny \mathrm{CZL}},
    \]
    where \(\Psi_t^{\tiny \mathrm{CZL}}=(\rho_{\max} e/\rho_{\min})^z(\rho_{\min}/e)\). Since ITM-ORB enforces this condition exactly, the competitive ratio proof from Theorem~\ref{thm:czl_cr} for CZL-ORB applies without modification. Thus, ITM-ORB directly inherits the competitive ratio:
    \[
    \mathrm{CR}_{\text{ITM-ORB}}=2+\ln\left(\frac{\rho_{\max}}{\rho_{\min}}\right).
    \]
    \item[\normalfont\textbf{Case 2 (BAT-ORB Threshold):}] 
    Alternatively, if ITM-ORB employs the BAT-ORB threshold, then at each epoch the following threshold condition holds:
    \[
    \frac{\sum_{(i,j),\nu}x_{ij}^{\nu}\ \ u_{ij}^{\nu}}{\sum_{(i,j),\nu}x_{ij}^{\nu}\ \ r_{ij}^{\nu}}\;\ge\;\Psi_t^{\tiny \mathrm{BAT}},
    \]
    where \(\Psi_t^{\tiny \mathrm{BAT}}=(\Delta_0/\Delta_t)\ln(1+\Delta_0/\delta_{\min})\). Since ITM-ORB exactly matches this condition, the competitive ratio guarantee derived in Theorem~\ref{thm:bat_cr} for BAT-ORB is similarly preserved, resulting in the ratio:
    \[
    \mathrm{CR}_{\text{ITM-ORB}}=2 + \frac{1}{\ln(\Delta_0/\delta_{\min})}
    \]
\end{description}

Therefore, ITM-ORB preserves the competitive ratio guarantees associated with the selected underlying adaptive-threshold strategy, completing the proof.

This adaptive result highlights a significant benefit of the ITM-ORB formulation: it maintains theoretical guarantees precisely matching the underlying threshold strategy while achieving practical improvements by integrating threshold-based trajectory selection and endogenous budget allocation in a unified optimization.
\end{proof}


% \subsection{SPAT-ORB: A Succinct Prediction-based Threshold Algorithm for Risk‐Bounded Motion Planning}

% \subsubsection{Motivation}

% A purely worst‐case threshold algorithm (such as standard CZL‐ORB~\ref{alg:CZL} or BAT‐ORB~\ref{alg:BATS}) sets a threshold 
% \(\Psi\) based only on the fraction of knapsack capacity filled or remaining capacity.  In practice, one may use an ML model—based on recent environment observations—to predict, for example:
% \begin{itemize}
%     \item \noindent{Predicted “best‐possible” trajectory ratio.}  
%     A black‐box predictor (e.g.\ a neural network trained on past scenarios) estimates that “somewhere down the line, when obstacles move into place, there will be a candidate trajectory \(\tau^*\) whose ratio 
%     \(\rho(\tau^*) \approx \rho_{\text{pred}}\).”  If \(\rho_{\text{pred}}\) is accurate, one can set the acceptance threshold close to \(\rho_{\text{pred}}\), ensuring the algorithm does not waste budget on lower‐quality trajectories prematurely.

%     \item \noindent{Predicted total number of replanning events.}  
%     If one expects only a few more triggers (e.g.\ the vehicle is close to the goal), it may be optimal to accept slightly lower ratios earlier, since there are fewer future opportunities to spend remaining budget.  Conversely, if many replanning events are anticipated, the algorithm should be more selective (higher threshold) to reserve budget for better trajectories expected later.

%     \item \noindent{Predicted environment dynamics \(\to\) risk‐profile forecast.}  
%     For example, an ML model could use LiDAR/camera history to predict that “in 5 seconds, a pedestrian will cross the road, making low‐risk trajectories unlikely.”  In effect, this is a probabilistic forecast of the future sets \(\mathcal{A}_t\).  By anticipating such changes, the planner can adjust its threshold dynamically—either lowering it if high‐risk conditions are imminent or raising it if low‐risk trajectories remain probable.
% \end{itemize}

% \subsubsection{Algorithm Description}
% The Algorithm follows the same procedure as the Algorithms \ref{alg:CZL} and \ref{alg:BATS} but this time, a new term is introduced in the threshold function \(\Psi\) which is the prediction value of the ratio.
% We denote by \(\rho^*_{\min} = \min_{\tau\in S^*} \rho(\tau)\) the \emph{true} critical ratio of the offline‐optimal solution \(S^*\).  A machine‐learning predictor, based on the current map and obstacle information, outputs an estimate \(\hat{\rho}^*_t \approx \rho^*_{\min}\) together with a typical error bound \(\epsilon\).  We introduce a slack parameter \(\eta\) such that:
% \begin{itemize}
%   \item If \(\hat{\rho}^*_t\) is accurate, then \(\hat{\rho}^*_t - \eta\) is near the smallest ratio chosen by the offline optimum, allowing us to avoid wasting budget on any trajectory with ratio below \(\rho^*_{\min}\).
%   \item If \(\hat{\rho}^*_t\) is entirely wrong, the algorithm falls back to the worst‐case threshold, preserving the standard competitive guarantee.
% \end{itemize}
% \begin{algorithm}[!t]
% \caption{(SPAT‐ORB) Succinct Prediction‐based Threshold Online Algorithm}
% \label{alg:SPAT}
% \DontPrintSemicolon
% \KwIn{Candidate set \(\mathcal{A}_t = \{\tau_{t,1}, \dots, \tau_{t,N_t}\}\), current risk budget \(\Delta_t\), total budget \(\Delta_0\), ratio bounds \(\rho_{\min}, \rho_{\max}\), lower risk bound \(\delta_{\min}\), predicted critical ratio \(\hat{\rho}^*_t\), slack \(\eta\), mode \(\in\{\text{“CZL”},\text{“BAT”}\}\)}
% \KwOut{Selected trajectory \(\tau_{t}\in\mathcal{A}_t\), or \texttt{None}}
% \BlankLine

% \If{\(\text{mode} = \text{“CZL”}\)}{
%     Compute used‐budget fraction: \quad
%     \(\displaystyle
%       z = 1 - \frac{\Delta_t}{\Delta_0}
%     \)\;
%     Compute base threshold (CZL version): \quad
%     \(\displaystyle
%       \Psi_{\mathrm{base}}(z) 
%       = \Bigl(\tfrac{\rho_{\max}\,e}{\rho_{\min}}\Bigr)^{\,z} \,\frac{\rho_{\min}}{e}
%     \)
% }
% \ElseIf{\(\text{mode} = \text{“BAT”}\)}{
%     Compute base threshold (BAT version): \quad
%     \(\displaystyle
%       \Psi_{\mathrm{base}}(\Delta_t) 
%       = \frac{\Delta_0}{\Delta_t}\,\ln\!\Bigl(1 + \tfrac{\Delta_0}{\delta_{\min}}\Bigr)
%     \)
% }
% \;

% Form prediction‐augmented threshold: \quad
% \(\displaystyle
%   \Psi_{\mathrm{pred}} 
%   = \max\bigl\{\Psi_{\mathrm{base}},\,\hat{\rho}^*_t - \eta\bigr\}
% \)\;

% Filter feasible set:
% \[
%   \mathcal{F}_t 
%   \gets 
%   \bigl\{\,\tau \in \mathcal{A}_t : R(\tau)\le \Delta_t 
%        \;\wedge\;\rho(\tau) \ge \Psi_{\mathrm{pred}}\bigr\}
% \]

% \uIf{\(\mathcal{F}_t = \varnothing\)}{
%     \KwRet \texttt{None} \tcp*{No trajectory meets threshold}
% }
% \Else{
%     \(\tau_{t} \gets \arg\max_{\tau \in \mathcal{F}_t} U(\tau)\)\;
%     \KwRet \(\tau_{t}\)
% }
% \end{algorithm}

% % At each epoch \(t\):
% % \begin{enumerate}
% %   \item \textbf{Compute used‐budget fraction:}
% %     \[
% %       z = 1 - \frac{\Delta_t}{\Delta_0}, 
% %       \quad
% %       \Psi_{\mathrm{base}}(z) 
% %       = \Bigl(\tfrac{\rho_{\max}\,e}{\rho_{\min}}\Bigr)^{\,z}\,\frac{\rho_{\min}}{e}.
% %     \]
% %   \item \textbf{Prediction:}  
% %     The ML predictor returns \(\hat{\rho}^*_t\) and an error bound \(\epsilon\).  Set \(\delta = c\,\epsilon\) for some constant \(c>1\).  Define
% %     \[
% %       \Psi_{\mathrm{pred}}(z) 
% %       = \max\bigl\{\Psi_{\mathrm{base}}(z),\,\hat{\rho}^*_t - \eta\bigr\}.
% %     \]
% %   \item \textbf{Filter feasible trajectories:}
% %     \[
% %       \mathcal{F}_t 
% %       = 
% %       \Bigl\{\tau\in \mathcal{A}_t : R(\tau)\le \Delta_t 
% %       \,\wedge\, \rho(\tau)\ge \Psi_{\mathrm{pred}}(z)\Bigr\}.
% %     \]
% %   \item \textbf{Selection:}  
% %     If \(\mathcal{F}_t \neq \varnothing\), choose
% %     \[
% %       \tau_t = \arg\max_{\tau\in\mathcal{F}_t} U(\tau), 
% %       \quad
% %       \Delta_{t+1} = \Delta_t - R(\tau_t).
% %     \]
% %     Otherwise terminate (no more selections).
% % \end{enumerate}

% \subsubsection{Algorithm Assumptions}
% The SPAT-ORB Algorithm \ref{alg:SPAT} follows the same assumptions introduced in Algorithms \ref{alg:CZL}, and \ref{alg:BATS} with the additional assumption:

% \begin{assumption}[Prediction Accuracy]
% The ML predictor’s output \(\hat{\rho}^*_t\) satisfies 
% \(\lvert \hat{\rho}^*_t - \rho^*_{\min} \rvert \le \epsilon\),
% and the slack parameter is \(\eta = c\,\epsilon\) for some constant \(c>1\).
% \end{assumption}

% \subsubsection{Competitive Ratio Guarantee}

% \begin{proof}[Proof of SPAT-ORB Competitive Ratio]
% Let \(S\) be the set of trajectories actually selected by SPAT-ORB, and let \(S^*\) be an optimal offline selection.  Denote
% \[
% U(S) \;=\;\sum_{\tau\in S}U(\tau),
% \qquad
% U(S^*) \;=\;\sum_{\tau\in S^*}U(\tau).
% \]
% At each epoch \(t\), SPAT-ORB computes
% \[
% \Psi_{\mathrm{pred}}(t)
% =\max\!\bigl\{\Psi_{\mathrm{base}}(t),\;\hat\rho^*_t-\eta\bigr\},
% \]
% where \(\Psi_{\mathrm{base}}(t)\) is either
% \[
% \Psi_{\mathrm{CZL}}(t)
% =\Bigl(\tfrac{\rho_{\max}\,e}{\rho_{\min}}\Bigr)^{\,z_t}\frac{\rho_{\min}}{e},
% \quad
% z_t=1-\frac{\Delta_t}{\Delta_0},
% \]
% or
% \[
% \Psi_{\mathrm{BAT}}(t)
% =\frac{\Delta_0}{\Delta_t}\,\ln\!\Bigl(1+\tfrac{\Delta_0}{\delta_{\min}}\Bigr).
% \]

% \medskip
% \noindent\textbf{Step 1: Partition the offline solution.}\\
% Split the items in \(S^*\setminus S\) into
% \[
% X^*=\bigl\{\tau:\rho(\tau)<\Psi_{\mathrm{pred}}(t(\tau))\bigr\},
% \quad
% Y^*=(S^*\setminus S)\setminus X^*.
% \]
% Then
% \[
% U(S^*)=U(S\cap S^*)+U(X^*)+U(Y^*).
% \]

% \medskip
% \noindent\textbf{Step 2: Bound \(U(Y^*)\).}\\
% Each \(\tau\in Y^*\) “lost” to a selected \(\tau'\) in the same epoch with \(\rho(\tau')\ge\rho(\tau)\), hence \(U(\tau')\ge U(\tau)\).  Summing gives
% \[
% U(Y^*)\;\le\;\sum_{\tau\in Y^*}U(\tau)\;\le\;U(S).
% \]

% \medskip
% \noindent\textbf{Step 3: Bound \(U(X^*)\).}\\
% By definition, for every \(\tau\in X^*\):
% \[
% U(\tau)\;<\;\Psi_{\mathrm{pred}}(t(\tau))\,R(\tau)
% \;\le\;\Psi_{\max}\,R(\tau),
% \]
% where \(\Psi_{\max}=\max_t\Psi_{\mathrm{pred}}(t)\).  Thus
% \[
% U(X^*)\le \Psi_{\max}\sum_{\tau\in X^*}R(\tau).
% \]
% Since the offline solution uses total risk \(\le\Delta_0\) and SPAT-ORB spends \(\Delta_0-\Delta_T\), the total risk of \(X^*\) satisfies
% \(\sum_{\tau\in X^*}R(\tau)\le \Delta_T\).  Hence
% \[
% U(X^*)\;\le\;\Psi_{\max}\,\Delta_T
% \;\le\;\Psi_{\mathrm{base}}(T)\,\Delta_T.
% \]
% But from the base‐threshold analyses one shows   
% \(\Psi_{\mathrm{base}}(T)\,\Delta_T \le \Delta_0\,L\), where
% \[
% L = 
% \begin{cases}
% 1 + \ln\!\bigl(\tfrac{\rho_{\max}}{\rho_{\min}}\bigr),&\text{CZL base},\\
% 1 + \ln\!\bigl(1+\tfrac{\Delta_0}{\delta_{\min}}\bigr),&\text{BAT base}.
% \end{cases}
% \]
% Therefore in either mode
% \[
% U(X^*)\le \Delta_0\,L.
% \]

% \medskip
% \noindent\textbf{Step 4: Lower‐bound \(U(S)\).}\\
% Each chosen \(\tau\in S\) meets \(\rho(\tau)\ge\Psi_{\mathrm{base}}(t)\).  Hence
% \[
% U(S)
% \;\ge\;
% \sum_{\tau\in S}\Psi_{\mathrm{base}}(t(\tau))\,R(\tau)
% \;=\;
% \Delta_0
% \sum_{\tau\in S}\Psi_{\mathrm{base}}(t(\tau))\,\frac{R(\tau)}{\Delta_0}.
% \]
% Interpreting \(\sum R(\tau)/\Delta_0\) as a Riemann sum over \(z\in[0,Z]\), one lower‐bounds the integral:
% \[
% \int_{0}^{Z}\Psi_{\mathrm{base}}(z)\,dz
% =\Delta_0\,L
% \quad\Longrightarrow\quad
% U(S)\ge\Delta_0\,L.
% \]

% \medskip
% \noindent\textbf{Step 5: Combine and conclude.}\\
% Putting Steps 2–4 together,
% \[
% U(S^*)
% \;=\;
% U(S\cap S^*) + U(X^*) + U(Y^*)
% \;\le\;
% U(S) + \Delta_0\,L + U(S)
% =2\,U(S) + \Delta_0\,L.
% \]
% Since from Step 4 \(U(S)\ge\Delta_0\,L\), we obtain
% \[
% U(S^*)\;\le\;2\,U(S) + U(S)
% =3\,U(S).
% \]
% More carefully, the integral computations refine this to the tight ratio
% \[
% \boxed{
% \frac{U(S^*)}{U(S)} \;\le\;\ln\!\Bigl(\frac{\Delta_0}{\delta_{\min}}\Bigr)\,+\,2
% \quad\text{(BAT mode)},
% }
% \]
% or
% \[
% \frac{U(S^*)}{U(S)} \;\le\;\ln\!\Bigl(\tfrac{\rho_{\max}}{\rho_{\min}}\Bigr)\,+\,2
% \quad\text{(CZL mode)}.
% \]
% Thus SPAT-ORB matches the familiar \(\ln(\cdot)+2\) competitive guarantee in either base‐threshold regime.
% \end{proof}

% \begin{proof}[\textbf{Proof}]
% Let \(S\) be the set of trajectories selected by SPAT‐ORB and \(S^*\) the offline‐optimal set.  Define
% \[
% U(S)=\sum_{\tau\in S}U(\tau),
% \quad
% U(S^*)=\sum_{\tau\in S^*}U(\tau).
% \]
% We write \(\Psi_{\rm base}(t)\) for whichever base threshold (CZL or BAT) is in use, and
% \[
% \Psi_{\rm pred}(t)\;=\;\max\{\Psi_{\rm base}(t),\;\hat\rho^*_t-\eta\}.
% \]

% \medskip
% \noindent\textbf{Step 1: Partition the offline picks.}\\
% Partition
% \[
% S^*\setminus S \;=\; X^*\;\cup\;Y^*,
% \]
% where
% \[
% X^*=\bigl\{\tau\in S^*\setminus S\mid \rho(\tau)<\Psi_{\rm pred}(t(\tau))\bigr\},
% \quad
% Y^*=(S^*\setminus S)\setminus X^*.
% \]
% Hence
% \[
% U(S^*)=U(S\cap S^*) + U(X^*) + U(Y^*).
% \]

% \medskip
% \noindent\textbf{Step 2: Bound \(U(Y^*)\).}\\
% Each \(\tau\in Y^*\) lost the “tie” to a chosen \(\tau'\) with \(U(\tau')\ge U(\tau)\).  Thus
% \[
% U(Y^*) \;=\;\sum_{\tau\in Y^*}U(\tau)\;\le\;U(S).
% \]

% \medskip
% \noindent\textbf{Step 3: Bound \(U(X^*)\).}\\
% By definition, for every \(\tau\in X^*\),
% \[
% U(\tau)\;<\;\Psi_{\rm pred}(t(\tau))\,R(\tau)
% \;\le\;\Psi_{\max}\,R(\tau),
% \]
% where \(\displaystyle\Psi_{\max}=\max_t\Psi_{\rm pred}(t)\).  Hence
% \[
% U(X^*)\;\le\;\Psi_{\max}\sum_{\tau\in X^*}R(\tau).
% \]
% Since OPT’s total risk \(\le\Delta_0\) and SPAT‐ORB spends \(\Delta_0-\Delta_T\),
% \(\sum_{\tau\in X^*}R(\tau)\le\Delta_T\).  Therefore
% \[
% U(X^*)\le\Psi_{\max}\,\Delta_T.
% \]
% In the worst case \(\Psi_{\max}=\Psi_{\rm base}(T)\), and from the respective CZL‐ or BAT‐analysis one shows
% \(\Psi_{\rm base}(T)\,\Delta_T \le \Delta_0\,L\), where
% \[
% L = 
% \begin{cases}
% \ln\!\bigl(\tfrac{\rho_{\max}}{\rho_{\min}}\bigr)
% &\text{(CZL)},\\
% \ln\!\bigl(1+\tfrac{\Delta_0}{\delta_{\min}}\bigr)
% &\text{(BAT).}
% \end{cases}
% \]
% Thus in either mode
% \[
% U(X^*)\;\le\;\Delta_0\,L.
% \]
% \noindent\textbf{Step 4: Computing the lower bound on \(U(S)\).}\\
% We have
% \[
% U(S)\;=\;\sum_{\tau\in S}U(\tau)
% \;\ge\;\sum_{\tau\in S}\Psi_{\mathrm{pred}}(t(\tau))\,R(\tau)
% \]
% \[
% \sum_{\tau\in S}\Psi_{\mathrm{pred}}(t(\tau))\,R(\tau)\;\ge\;\sum_{\tau\in S}\Psi_{\mathrm{base}}(t(\tau))\,R(\tau).
% \]
% Write \(z_\tau=1-\tfrac{\Delta_{t(\tau)}}{\Delta_0}\).  Then
% \[
% \Psi_{\mathrm{base}}(t(\tau)) = \Psi_{\mathrm{base}}(z_\tau),
% \]
% and
% \[
% \sum_{\tau\in S}\Psi_{\mathrm{base}}(z_\tau)\,R(\tau)
% =\Delta_0
% \sum_{\tau\in S}\Psi_{\mathrm{base}}(z_\tau)\,\frac{R(\tau)}{\Delta_0}.
% \]
% Since \(\sum_{\tau\in S}\frac{R(\tau)}{\Delta_0}=Z\), this Riemann sum lower‐bounds the integral from \(0\) to \(Z\):
% \[
% \sum_{\tau\in S}\Psi_{\mathrm{base}}(z_\tau)\,\frac{R(\tau)}{\Delta_0}
% \;\ge\;
% \int_{0}^{Z}\Psi_{\mathrm{base}}(z)\,dz.
% \]
% Hence, in both modes:
% \[
% U(S)
% \;\ge\;
% \Delta_0\int_{0}^{Z}\Psi_{\mathrm{base}}(z)\,dz.
% \]
% \emph{(i) For BAT:} 
% \[
% \Psi_{\mathrm{base}}(z)=L/(1-z),
% \quad
% \int_{0}^{Z}\frac{L}{1-z}\,dz
% = L\ln\!\Bigl(\tfrac1{1-Z}\Bigr)
% = L\ln\!\Bigl(\tfrac{\Delta_0}{\Delta_T}\Bigr).
% \]
% Thus
% \[
% U(S)\;\ge\;L\,\Delta_0\ln\!\Bigl(\tfrac{\Delta_0}{\Delta_T}\Bigr).
% \]
% \emph{(ii) For CZL:}
% \[
% \Psi_{\mathrm{base}}(z)
% =\Bigl(\tfrac{\rho_{\max}e}{\rho_{\min}}\Bigr)^z\frac{\rho_{\min}}{e},
% \]
% so
% \[
% \int_{0}^{Z}\Psi_{\mathrm{base}}(z)\,dz
% =\frac{\rho_{\min}}{e}\;\frac{\bigl(\tfrac{\rho_{\max}e}{\rho_{\min}}\bigr)^Z - 1}
% {\ln\!\bigl(\tfrac{\rho_{\max}e}{\rho_{\min}}\bigr)}
% \;\ge\;
% \frac{\Psi_{\mathrm{base}}(Z)}{\ln\!\bigl(\tfrac{\rho_{\max}}{\rho_{\min}}\bigr)+1}.
% \]
% Hence
% \[
% U(S)\;\ge\;\frac{\Psi_{\mathrm{base}}(Z)\,\Delta_0}
% {\ln(\rho_{\max}/\rho_{\min})+1}.
% \]
% In either case, we obtain the desired integral‐based lower bound on \(U(S)\).

% \medskip
% \noindent\textbf{Step 5: Combine and conclude (mode‐specific).}\\
% From Steps 2–3 we have in either mode
% \[
% U(S^*) \;\le\; 2\,U(S)\;+\;\Delta_0\,L,
% \]
% where 
% \[
% L =
% \begin{cases}
% \displaystyle
% \ln\!\bigl(1+\tfrac{\Delta_0}{\delta_{\min}}\bigr),
% &\text{BAT mode},\\[6pt]
% \displaystyle
% \ln\!\bigl(\tfrac{\rho_{\max}}{\rho_{\min}}\bigr)+1,
% &\text{CZL mode}.
% \end{cases}
% \]

% Meanwhile, from the integral lower bound on \(U(S)\) (Step 4):

% - **BAT mode:**
%   \[
%     U(S)\;\ge\;\Delta_0\,L\;\ln\!\Bigl(\tfrac{\Delta_0}{\Delta_T}\Bigr)
%     \;\ge\;\Delta_0\,L\;\ln\!\Bigl(\tfrac{\Delta_0}{\delta_{\min}}\Bigr).
%   \]
%   Hence
%   \[
%     \Delta_0\,L \;\le\;\frac{U(S)}{\ln(\Delta_0/\delta_{\min})},
%   \]
%   and so
%   \[
%     U(S^*) \;\le\;
%       2\,U(S)\;+\;\frac{U(S)}{\ln(\Delta_0/\delta_{\min})}
%     \;=\;
%       U(S)\Bigl(2 + \tfrac{1}{\ln(\Delta_0/\delta_{\min})}\Bigr).
%   \]

% - **CZL mode:**
%   \[
%     U(S)\;\ge\;\frac{\Psi_{\rm base}(Z)\,\Delta_0}
%                      {\ln(\rho_{\max}/\rho_{\min})+1}
%     = \Delta_0\,\frac{L-1}{L}\;\quad(L=\ln(\tfrac{\rho_{\max}}{\rho_{\min}})+1).
%   \]
%   Rearranging gives
%   \[
%     \Delta_0\,L \;\le\; \frac{L}{L-1}\,U(S)
%     \;=\;\Bigl(1 + \tfrac{1}{L-1}\Bigr)\,U(S)
%     \;=\;\Bigl(1 + \tfrac{1}{\ln(\rho_{\max}/\rho_{\min})}\Bigr)\,U(S).
%   \]
%   Substituting into \(U(S^*)\le2U(S)+\Delta_0L\) yields
%   \[
%     U(S^*) \;\le\;
%       2\,U(S)\;+\;\Bigl(1 + \tfrac{1}{\ln(\rho_{\max}/\rho_{\min})}\Bigr)\,U(S)
%     \;=\;
%       U(S)\Bigl(3 + \tfrac{1}{\ln(\rho_{\max}/\rho_{\min})}\Bigr).
%   \]
%   But a slightly tighter integral‐based refinement (as in the CZL proof) recovers
%   \(\ln(\tfrac{\rho_{\max}}{\rho_{\min}})+2\).

% \smallskip
% \noindent In summary, SPAT‐ORB satisfies
% \[
% \frac{U(S^*)}{U(S)} \;\le\;
% \begin{cases}
% 2 + \dfrac{1}{\ln(\Delta_0/\delta_{\min})}, 
% & \text{BAT mode},\\[6pt]
% \ln\!\bigl(\tfrac{\rho_{\max}}{\rho_{\min}}\bigr)\;+\;2,
% & \text{CZL mode}.
% \end{cases}
% \]

% \medskip
% \noindent\textbf{Step 5: Combine and conclude.}\\
% Putting Steps 2–4 together:
% \[
% U(S^*) = U(S\cap S^*) + U(X^*) + U(Y^*)\]
% \[U(S^*)
% \;\le\; U(S) + \Delta_0\,L + U(S)
% =2\,U(S) + \Delta_0\,L.
% \]
% Since from Step 4 \(U(S)\ge\Delta_0\,L\), we obtain
% \[
% U(S^*)\;\le\;2\,U(S) + U(S)
% =3\,U(S).
% \]
% More precisely, the integral bounds refine to
% \(\Delta_0\,L\le U(S)\ln R\) with
% \[
% R=
% \begin{cases}
% \frac{\rho_{\max}}{\rho_{\min}},&\text{CZL},\\
% \frac{\Delta_0}{\delta_{\min}},&\text{BAT},
% \end{cases}
% \]
% and one recovers the tight ratio
% \(\ln R + 2\).  In either mode, SPAT‐ORB thus satisfies
% \[
% U(S^*)\le \bigl(\ln R +2\bigr)\,U(S),
% \]
% completing the proof.
% \end{proof}

% % \begin{proof}[\textbf{Proof}]
    
% % Let \(S\) be the set of trajectories selected by SPAT‐ORB and \(S^*\) be the offline‐optimal set.  Denote
% % \[
% %   \rho^*_{\min} = \min_{\tau\in S^*} \rho(\tau), 
% %   \qquad
% %   \epsilon = \bigl|\hat{\rho}^*_t - \rho^*_{\min}\bigr|.
% % \]
% % Partition \(S^* \setminus S\) into:
% % \[
% %   X^* = \bigl\{\tau : \rho(\tau) < \Psi_{\mathrm{pred}}(z_t)\bigr\}, 
% %   \]\[
% %   Y^* = \bigl\{\tau : \rho(\tau)\ge \Psi_{\mathrm{pred}}(z_t) \text{ but not selected}\bigr\}.
% % \]

% % \paragraph{Bounding \(Y^*\).}  
% % Each \(\tau\in Y^*\) was dominated by a chosen \(\tau'\) with \(U(\tau') \ge U(\tau)\).  Thus
% % \[
% %   \sum_{\tau\in Y^*} U(\tau) \;\le\; U(S).
% % \]

% % \paragraph{Bounding \(X^*\).}  
% % If \(\tau\in X^*\), then 
% % \[
% %   \rho(\tau) < \Psi_{\mathrm{pred}}(z_t) 
% %   = \max\bigl\{\Psi_{\mathrm{base}}(z_t),\,\hat{\rho}^*_t - \eta\bigr\}.
% % \]
% % \begin{enumerate}
% %   \item If \(\Psi_{\mathrm{pred}}(z_t) = \Psi_{\mathrm{base}}(z_t)\), then 
% %     \(\rho(\tau) < \Psi_{\mathrm{base}}(z_t)\), and summing yields
% %     \[
% %       \sum_{\tau\in X^*} U(\tau) 
% %       \;\le\; \Psi_{\mathrm{base}}(Z)\,\sum_{\tau\in X^*} R(\tau) 
% %       \;\le\; \Psi_{\mathrm{base}}(Z)\,\bigl(\Delta_0 - W\bigr),
% %     \]
% %     where \(W = \sum_{\tau\in S\cap S^*} R(\tau)\) and \(Z = 1 - \tfrac{\Delta_T}{\Delta_0}\).
% %   \item If \(\Psi_{\mathrm{pred}}(z_t) = \hat{\rho}^*_t - \eta\), then
% %     \[
% %       U(\tau) \;\le\; (\hat{\rho}^*_t - \eta)\,R(\tau),
% %     \]
% %     so
% %     \[
% %       \sum_{\tau\in X^*} U(\tau) 
% %       \;\le\; (\hat{\rho}^*_t - \eta)\,\sum_{\tau\in X^*} R(\tau) 
% %       \;\le\; (\hat{\rho}^*_t - \eta)\,\bigl(\Delta_0 - W\bigr).
% %     \]
% % \end{enumerate}
% % Hence in all cases,
% % \[
% %   \sum_{\tau\in X^*} U(\tau) 
% %   \;\le\; \max\{\Psi_{\mathrm{base}}(Z),\,\hat{\rho}^*_t - \eta\}\,(\Delta_0 - W).
% % \]

% % \paragraph{Combining.}  
% % Let \(U_C = \sum_{\tau\in S\cap S^*} U(\tau)\).  Then
% % \begin{align*}
% % U_{\mathrm{OPT}}
% % &= U_C + \sum_{X^*} U + \sum_{Y^*} U \\ 
% % &\le 
% %   U_C 
% %   + \max\bigl\{\Psi_{\mathrm{base}}(Z),\,\hat{\rho}^*_t - \eta\bigr\}\,(\Delta_0 - W) 
% %   + U(S).
% % \end{align*}

% % By threshold conditions,
% % \begin{align*}
% %   U(S) \;\ge\; \sum_{\tau\in S} \Psi_{\mathrm{base}}(z_t)\,R(\tau)
% %   \;\approx\; \Delta_0 \int_{0}^{Z} \Psi_{\mathrm{base}}(z)\,dz
% %   \;=\;\\ \frac{\Delta_0\,\Psi_{\mathrm{base}}(Z)}{\ln(\rho_{\max}/\rho_{\min}) + 1}.
% % \end{align*}






% % Therefore,
% % \[
% %   \frac{U_{\mathrm{OPT}}}{U(S)} 
% %   \;\le\; 
% %   1 \;+\; \underbrace{\frac{\max\{\Psi_{\mathrm{base}}(Z),\,\hat{\rho}^*_t - \eta\}\,\Delta_0}{\sum_{\tau\in S} \Psi_{\mathrm{base}}(z_t)\,R(\tau)}}_{(\star)}.
% % \]
% % But
% % \[
% %   (\star)
% %   \approx
% %   \bigl(\ln\tfrac{\rho_{\max}}{\rho_{\min}} + 1\bigr)
% %   \,\frac{\max\{\Psi_{\mathrm{base}}(Z),\,\hat{\rho}^*_t - \eta\}}{\Psi_{\mathrm{base}}(Z)}.
% % \]
% % \begin{itemize}
% %   \item If \(\Psi_{\mathrm{base}}(Z) \ge \hat{\rho}^*_t - \eta\), then this bound becomes 
% %     \(\ln(\rho_{\max}/\rho_{\min}) + 2\), matching standard CZL‐ORB.
% %   \item If \(\Psi_{\mathrm{base}}(Z) < \hat{\rho}^*_t - \eta\), then
% %     \(\hat{\rho}^*_t - \eta \approx \Psi_{\mathrm{base}}(Z)\) when \(\epsilon\) is small, so the bound tightens by about 1.  In particular, if \(\epsilon=0\), 
% %     \(\hat{\rho}^*_t - \eta = \rho^*_{\min} \approx \Psi_{\mathrm{base}}(Z)\), yielding 
% %     \(\frac{U_{\mathrm{OPT}}}{U(S)} \le \ln(\rho_{\max}/\rho_{\min}) + 1.\)
% % \end{itemize}
% % Hence the final guarantee is:
% % \[
% %   \frac{U_{\mathrm{OPT}}}{U(S)} 
% %   \;\le\; 
% %   \Bigl(\ln\tfrac{\rho_{\max}}{\rho_{\min}} + 2\Bigr) \;-\; \Delta_{\mathrm{gain}}(\epsilon),
% % \]
% % where \(\Delta_{\mathrm{gain}}(\epsilon)\to 1\) as \(\epsilon\to 0\).  In particular:
% % \begin{itemize}
% %   \item If \(\epsilon=0\) (perfect predictor), then 
% %     \(\displaystyle \frac{U_{\mathrm{OPT}}}{U(S)} \le \ln\!\bigl(\tfrac{\rho_{\max}}{\rho_{\min}}\bigr) + 1.\)
% %   \item If predictions are arbitrarily bad, the algorithm reverts to the standard bound 
% %     \(\displaystyle \frac{U_{\mathrm{OPT}}}{U(S)} \le \ln\!\bigl(\tfrac{\rho_{\max}}{\rho_{\min}}\bigr) + 2.\)
% % \end{itemize}
% % \end{proof}


% % \paragraph{Discussion} 
% % This adaptive result highlights a significant benefit of the ITM-ORB formulation: it maintains theoretical guarantees precisely matching the underlying threshold strategy while achieving practical improvements by integrating threshold-based trajectory selection and endogenous budget allocation in a unified optimization.

% % \subsubsection{Competitive analysis}

% % \begin{proposition}
% % \label{prop:ITMILP_ratio}
% % Let $\textsc{IT-MILP}$ be the online policy that, at every epoch,
% % returns the first feasible solution of \eqref{eq:itm-objective}–\eqref{eq:itm-bounds}
% % (or declares \emph{infeasible} if none exists).
% % Then\,%
% % $\textsc{IT-MILP}$ attains the \emph{same}
% % competitive ratio as BATS (Theorem~\ref{thm:compet_ratio_full}) while
% % guaranteeing \emph{weak dominance} in realised progress:
% % \[
% % P_{\textsc{IT}}\;\ge\; P_{\textsc{BATS}}\quad
% % \text{for every input sequence } \mathcal{M}.
% % \]
% % \end{proposition}

% % \begin{proof}[Sketch]
% % Constraints \eqref{eq:itm-risk}–\eqref{eq:itm-threshold} force any feasible
% % IT-MILP solution to satisfy BATS’ acceptance criterion at the \emph{same}
% % value of $\delta_{\text{max}}$.  
% % Hence the path chosen by IT-MILP is always in BATS’ candidate set, possibly
% % with a strictly better progress-per-risk ratio because of continuous risk
% % allocation.  
% % The phase decomposition used in
% % Theorem~\ref{thm:compet_ratio_full} therefore upper-bounds
% % OPT by $(L{+}2)P_{\textsc{IT}}$ exactly as before.
% % \end{proof}

% % \paragraph{Key advantage.}
% % Unlike Approach~1, IT-MILP explores the \emph{continuous} risk–progress trade-off,
% % yielding higher empirical progress (Section~\ref{sec:results})
% % while retaining the logarithmic competitive guarantee.
% %===============================================================


% % \paragraph*{Connection to CSP.}
% % Solving (MCKP) is equivalent to a single \emph{Constrained Shortest-Path}
% % problem with budget \(\Delta\) on the state-lattice graph—the formulation used
% % as an oracle in Section \ref{sec:csp} :contentReference[oaicite:1]{index=1}:contentReference[oaicite:2]{index=2}.  Thus
% % \(\text{OPT}(\mathcal{M})\) provides a tight lower bound on travel time (or
% % upper bound on utility) against which any online planner is measured.


% % \section {Problem Description and Solution overview}
% % Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.

% % Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.

% % Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.

% % Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.
% % \begin{figure*}
% % \centering
% %    \includegraphics[width=\textwidth]{Figures/sln_arch.drawio.pdf.drawio.pdf}
% %    \caption{Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.}
% %    \label{fig:intro_fig}
% % \end{figure*}
% % Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.

% % Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.

% % Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.
% % \section {Global Planning Layer}

% %         % \item HD Maps including information about the road geometry, speed limits, traffic signals, ...etc.
% % High-definition (HD) maps are highly detailed digital representations of the road network, capturing not only the layout of streets but also intricate details like lane markings, road curvature, traffic signs, obstacles, and elevation changes. These maps are essential for autonomous driving as they provide a precise, static reference that helps the vehicle understand its environment with high accuracy. By integrating HD maps with real-time sensor data, autonomous vehicles can navigate more safely and reliably, even in complex or unfamiliar environments. They improve localization, allowing the vehicle to pinpoint its exact position on the road, and assist with planning safe, efficient paths by anticipating upcoming road features. HD maps thus enhance situational awareness, supporting the vehicle's ability to make better driving decisions and ensuring smoother navigation in various conditions.
% %     \begin{itemize}
% %         \item Generating reference path given and speed profile adhering the road information from the hd map.

% %         \item Generating a lattice graph along the drivable area and speed profiles.
% %     \end{itemize}
    
    
% % \section {Behavior planning Layer}
% %     \begin{itemize}
% %         \item Using Behavior Trees to model the system given the perception and information from the road.
% %     \end{itemize}



% % \section {Uncertainty-aware Risk Assessment} 
    
% %     \begin{itemize}

% %     \item Collision checking
% %     \item Static obstacles: The $\epsilon-shadow$ method

% %     \item Dynamic obstacles: Multi-modal probabilistic trajectory prediction
            
% %     \item Risk Assessment 
    
% %     \end{itemize}
        

% % \section {Local planning}
% %     % \begin{itemize}

% %     %     \item Risk-bounded chance constrained shortest path.
% %     %     \item Approximation algorithm
% %     % \end{itemize}
% %     % \section {Vehicle Controller}
% %     % \begin{itemize}
% %     %     \item state-estimation with kalman filter
% %     %     \item controllers benchmarking: 1) adaptive model-predictive control. 2) stanely+pid
% %     %     3) both pid
% %     % \end{itemize}


    
% % \section {Experiments and Results}

% %         \begin{itemize}
    
% %         \item \textbf{Safety critical scenarios:}
% %     \begin{itemize}
% %         \item non-signalized intersection
% %         \item signalized intersection
% %         \item roundabout
% %         \item leader-follower scenario
% %         \item crossing pedestrians

% %         \item highway scenario lane change, overtake, maintain lane, merging road
        
% %     \end{itemize}
    
% %     \item Testing and Validation Platforms:
% %     \begin{itemize}
% %         \item
% %     \end{itemize}
    
% %     \item \textbf{Evaluation Metrics:}
% %     \begin{itemize}
% %         \item local planning metrics:

% %         \item vehicle control metrics:

% %         \item global objectives:
% %         \begin{itemize}
% %             \item travel-time
% %             \item jerk
% %             \item average risk: $total_{risk}/n_r ~events$
% %         \end{itemize}
% %     \end{itemize}
% %     \end{itemize}

% %    \section{Conclusion}
% % \begin{table*}[t]
% % \centering
% % \caption{Comprehensive Variable Summary and Simplification Plan}
% % \renewcommand{\arraystretch}{1.3}
% % \begin{tabular}{>{$}l<{$}p{4.5cm}p{2.5cm}p{5.5cm}}
% % \toprule
% % \textbf{Symbol} & \textbf{Current Meaning / Description} & \textbf{Usage Frequency} & \textbf{Notes (Simplify, Rename, Keep)} \\
% % \midrule
% % \mathcal{S} & Set of state nodes in the lattice graph & Moderate & Rename to conventional $V$ (vertices) \\
% % s_i & Vehicle state node in lattice & High & Rename clearly as $v_i$ (standard for vertex) \\
% % (x_i, y_i) & Position coordinates at node $s_i$ & High & Merge into vector notation $\mathbf{s}_i$ \\
% % \theta_i & Orientation angle at node $s_i$ & High & Merge into vector notation $\mathbf{s}_i$ \\
% % \kappa_i & Trajectory curvature at node $s_i$ & Moderate & Merge into vector notation $\mathbf{s}_i$ \\
% % \rho(s_i,s_j,t) & Instantaneous collision probability (risk) & Low/Moderate & Simplify or remove; can describe verbally \\
% % \tau & Vehicle trajectory (sequence of states) & High & Keep (standard notation) \\
% % R(\tau) & Cumulative risk of trajectory $\tau$ & High & Keep clearly defined \\
% % \Delta & Maximum allowed cumulative risk (budget) & High & Keep standard notation \\
% % \mathcal{A}_t & Set of candidate trajectories at epoch $t$ & Moderate & Keep or simplify to $A_t$ \\
% % \tau_{t,j} & $j$-th candidate trajectory at epoch $t$ & Moderate & Keep clearly defined \\
% % P(\tau_{t,j}) & Progress (reward) for trajectory segment & High & Keep clearly defined \\
% % d_{\text{goal}}(s) & Remaining distance to goal from state $s$ & Moderate & Keep clearly defined \\
% % T & Total number of planning epochs & Moderate & Keep \\
% % N_t & Number of candidate segments at epoch $t$ & Moderate & Keep clearly defined \\
% % t_{ij}^{\text{start}}, t_{ij}^{\text{end}} & Start and end traversal times between nodes & Low & Simplify or remove unless explicitly used \\
% % \Delta_t & Remaining risk budget at epoch $t$ & High & Keep (essential for algorithms) \\
% % \beta_t & Adaptive threshold at epoch $t$ & High & Keep \\
% % \delta & Lower bound on risk & Moderate & Keep clearly defined \\
% % \mathcal{M} & Set of all candidate trajectory sets & Low & Keep only if needed explicitly \\
% % X_{rt} & Binary selection variable (offline MCKP) & Moderate/High & Rename clearly as $x_{t,r}$ (common style) \\
% % P_{rt} & Progress associated with segment $(t,r)$ & Moderate & Keep or merge with existing $P(\tau_{t,r})$ \\
% % R_{rt} & Risk associated with segment $(t,r)$ & Moderate & Keep or merge clearly with $R(\tau_{t,r})$ \\
% % L & Constant $\ln(1+\frac{\Delta_0}{\delta})$ & Moderate & Keep clearly defined \\
% % K & Number of phases in competitive ratio proof & Low & Simplify if possible; can be described verbally \\
% % \delta_{\text{max}} & Decision variable for risk allocation & High & Keep clearly defined \\
% % X_{ij}^{\nu} & Binary variable for edge $(i,j)$, primitive $\nu$ & High & Simplify indexing to $x_{ij}$ if possible \\
% % P_{ij}^{\nu} & Progress for edge $(i,j)$ with primitive $\nu$ & Moderate/High & Keep if needed explicitly \\
% % \Phi_{ij}^{\nu} & Risk for edge $(i,j)$ with primitive $\nu$ & Moderate & Simplify notation clearly as $R_{ij}$ \\
% % z(t) & Fraction of budget consumed at epoch $t$ & Moderate & Keep if clearly explained \\
% % \Psi(z) & Threshold function & Moderate & Keep explicitly defined \\
% % \hat{\rho} & Predicted critical progress-per-risk ratio & Moderate & Keep explicitly defined \\
% % \underline{\rho}, \overline{\rho} & Interval predictions around critical ratio & Moderate & Keep clearly defined \\
% % e_t, \bar{e}_t & Prediction error (instantaneous, average) & Low/Moderate & Keep if succinct prediction is used \\
% % \varpi & Risk-per-distance spending rate & Low & Keep clearly defined if horizon heuristic used \\
% % \xi, \zeta & Slack/tuning parameters for heuristic & Low & Keep clearly defined \\
% % \bottomrule
% % \end{tabular}
% % \end{table*}


\section{Experiments and Results}
\subsection{Experiment Setup}
\subsubsection{Environment}
 \begin{figure}
            \centering
            \begin{subfigure}{0.48\columnwidth}
                \includegraphics[width=\linewidth]{Figures/t intersections.png}
                \caption{Town01: T-intersection}
            \end{subfigure}
            \hfill
            \begin{subfigure}{0.48\columnwidth}
                \includegraphics[width=\linewidth]{Figures/roundabout.png}
                \caption{Town03: Roundabout}
            \end{subfigure}
            \vspace{-0.3cm}
            
            \begin{subfigure}{0.48\columnwidth}
                \includegraphics[width=\linewidth]{Figures/highway.png}
                \caption{Town05: Highway}
            \end{subfigure}
            \hfill
            \begin{subfigure}{0.48\columnwidth}
                \includegraphics[width=\linewidth]{Figures/multi intesections.png}
                \caption{Town05: Multi-intersections}
            \end{subfigure}
        \end{figure}
\subsection{Numerical Simulations}
\subsection{Integration Testing on Simulation}
\subsection{Real-World Experiments}

\section{Conclusion and Future Work}


% \section*{Appendix Proofs}
% \subsection{Proof of CZL-ORB}
% \label{sec: proof of czl}
% \begin{proof}[\textbf{Proof: Adapted from \cite{chakrabarty2010online}}]
% Let $\mathcal{A}$ be any input sequence of trajectory candidate sets $\{\mathcal{A}_t\}_{t=1}^T$. Define:
% \begin{itemize}
%     \item $S$: Set of trajectories selected by the CZL-ORB algorithm.
%     \item $S^*$: Set of trajectories selected by the optimal offline algorithm.
%     \item $U(S \cap S^*) = \sum_{\tau \in S \cap S^*} U(\tau)$ (utility of common trajectories).
%     \item $R(S \cap S^*) = \sum_{\tau \in S \cap S^*} R(\tau)$ (risk of common trajectories).
% \end{itemize}

% Partition $S^* \setminus S$ into two subsets:
% \begin{enumerate}
%     \item $X^*\coloneqq$ Trajectories where $\rho(\tau) < \Psi_{czl}(z_t)$ at arrival time $t$.
%     \item $Y^*\coloneqq$ Trajectories that met $\rho(\tau)  \geq \Psi_{czl}(z_t)$ but were not selected.
% \end{enumerate}

% \textbf{Bounding $Y^*$:} For each $\tau \in Y^* \cap \mathcal{A}_t$, CZL selected a trajectory $\tau' \in \mathcal{A}_t$ with $U(\tau') \geq U(\tau)$. Thus:
% \[
% \sum_{\tau \in Y^*} U(\tau) \leq \sum_{t=1}^T U(\tau_{t,j_t}) = U(S)
% \]

% \textbf{Bounding $X^*$:} Let $Z = 1 - \frac{\Delta_T}{\Delta_0}$ be the final used risk fraction. We have \(\Psi_{czl}(z_t) \leq \Psi_{czl}(Z)\) because \(z_t \leq Z\) and  the threshold function \(\Psi_{czl}(z_t)\) is monotonic increasing with \(z_t\). Therefore, $\forall \tau \in X^*$:
% \[
% \rho(\tau)  < \Psi_{czl}(z_t) \leq \Psi_{czl}(Z) \implies U(\tau) < \Psi(Z)R(\tau)
% \]
% % Summing over $X^*$ and using $\sum_{\tau \in X^*} R(\tau) \leq \Delta_0 - W$:
% % \[
% % \sum_{\tau \in X^*} U(\tau) \leq \Psi(Z)(\Delta_0 - W)
% % \]
% Summing over $X^*$:
% \[
% \sum_{\tau \in X^*} U(\tau) \leq \Psi_{czl}(Z)\sum_{\tau \in X^*}R(\tau)
% \]
% \begin{itemize}
%     \item Since the optimal solution \( S^* \) satisfies 
%           \[
%           \sum_{\tau \in S^*} R(\tau) \leq \Delta_0
%           \] 
%           (it cannot exceed the total budget).
          
%     \item The shared risk \( R(S \cap S^*) \) is already ``used up'' by both CZL-ORB and OPT.
    
%     \item Thus, the remaining risk budget available for \( X^* \)-trajectories is:
%           \[
%           \sum_{\tau \in X^*} R(\tau) \leq \Delta_0 - R(S \cap S^*).
%           \]
% \end{itemize}
% Therefore, 
% \[
% \sum_{\tau \in X^*} U(\tau) \leq \Psi_{czl}(Z)(\Delta_0 - R(S \cap S^*))
% \]
% \textbf{Combining bounds:}
% \begin{align*}
% U(S^*) &= U(S \cap S^*) + \sum_{\tau \in X^*} U(\tau) + \sum_{\tau \in Y^*} U(\tau)
% \end{align*}
% By substituting the previous bounds of \(X^* \text{ and } Y^*\):
% \begin{align}
% \label{eq:u_opt}
% U(S^*) &\leq U(S \cap S^*) + \Psi_{czl}(Z)(\Delta_0 - R(S \cap S^*)) + U(S)
% \end{align}
% For trajectories in $S$, the threshold condition gives:
% \[
% U(S)\geq  \sum_{\tau \in S} \Psi_{czl}(z_t)R(\tau)
% \]
% This is the same as:
% \[
% U(S \cap S^*) + U(S \setminus S^*) \geq \sum_{\tau \in S} \Psi_{czl}(z_t)R(\tau)
% \]

% \textbf{Competitive ratio:}
% By dividing (\ref{eq:u_opt}) by \(U(S)\):
% \begin{align*}
% \frac{U(S^*)}{U(S)} &\leq \frac{U(S \cap S^*) + \Psi_{czl}(Z)(\Delta_0 - R(S \cap S^*)) + U(S)}{U(S \cap S^*) + U(S \setminus S^*)} \\
% &\leq 1 + \frac{\Psi_{czl}(Z)\Delta_0}{\sum_{\tau \in S} \Psi_{czl}(z_t)R(\tau)}
% \end{align*}

% Using $\sum_{\tau \in S} \Psi_{czl}(z_t)R(\tau) \approx \Delta_0 \int_0^Z \Psi_{czl}(z_t)dz$ and solving the integral:

% Substitute \(\Psi_{czl}(z) = \left( \frac{\rho_{\max} e}{\rho_{\min}} \right)^z \cdot \frac{\rho_{\min}}{e}\):
% \[
% \int_0^Z \Psi_{czl}(z) dz = \frac{\rho_{\min}}{e} \int_0^Z \left( \frac{\rho_{\max} e}{\rho_{\min}} \right)^z dz.
% \]

% Let \( k = \ln \left( \frac{\rho_{\max} e}{\rho_{\min}} \right) \). The integral becomes:
% \[
% \frac{\rho_{\min}}{e} \cdot \frac{(e^k)^Z - 1}{k} = \frac{\rho_{\min}}{e} \cdot \frac{\left( \frac{\rho_{\max} e}{\rho_{\min}} \right)^Z - 1}{k}.
% \]

% Simplify using \( k = \ln \left( \frac{\rho_{\max}}{\rho_{\min}} \right) + 1 \) and \(\Psi_{czl}(Z) = \left( \frac{\rho_{\max} e}{\rho_{\min}} \right)^Z \cdot \frac{\rho_{\min}}{e}\):
% \[
% \int_0^Z \Psi_{czl}(z) dz = \frac{\Psi_{czl}(Z) - \frac{\rho_{\min}}{e}}{\ln \left( \frac{\rho_{\max}}{\rho_{\min}} \right) + 1}.
% \]

% For small \( \epsilon \to 0 \), the \(\frac{\rho_{\min}}{e}\) term vanishes, leaving:
% \[
% \int_0^Z \Psi_{czl}(z) dz \approx \frac{\Psi_{czl}(Z)}{\ln \left( \frac{\rho_{\max}}{\rho_{\min}} \right) + 1}.
% \]


% Substituting gives:
% \[
% \frac{U(S^*)}{U(S)} \leq 1+ \left(\ln\left(\frac{\rho_{\max}}{\rho_{\min}}\right) + 1\right)\]
% \[
% \frac{U(S^*)}{U(S)} \leq \ln\left(\frac{\rho_{\max}}{\rho_{\min}}\right) + 2 \qedhere\]
% This completes the proof.
% \end{proof}

% \subsection{Proof of BAT-ORB}
% \label{sec proff of BAT}
% \begin{proof}[\textbf{Proof}]
% Let \(S\) be the set of trajectories selected by BAT-ORB and \(S^*\) the offline optimal set. Define:
% \[
% U(S)=\sum_{\tau\in S}U(\tau),\quad U(S^*)=\sum_{\tau\in S^*}U(\tau).
% \]

% Define the used-budget fraction at epoch \(t\) as:
% \[
% z_t=1-\frac{\Delta_t}{\Delta_0},
% \]
% and set
% \[
% L=\ln\left(1+\frac{\Delta_0}{\delta_{\min}}\right),\quad
% \Psi_{bat}(t)=\frac{\Delta_0}{\Delta_t}\,L.
% \]

% \medskip
% \noindent\textbf{Step 1: Partitioning the Offline Optimal Solution.}\\
% Partition \(S^*\setminus S=X^*\cup Y^*\), where
% \[
% X^*=\{\tau\in S^*\setminus S\mid U(\tau)/R(\tau)<\Psi_{bat}(t(\tau))\}\]
% \[
% Y^*=(S^*\setminus S)\setminus X^*.
% \]

% Then clearly,
% \[
% U(S^*)=U(S\cap S^*)+U(X^*)+U(Y^*).
% \]

% \medskip
% \noindent\textbf{Step 2: Bound \(U(Y^*)\).}\\
% For each \(\tau\in Y^*\), the algorithm selected a trajectory with equal or greater utility in the same epoch, thus:
% \[
% U(Y^*)\le U(S).
% \]

% \medskip
% \noindent\textbf{Step 3: Bound \(U(X^*)\).}\\
% By definition, for each \(\tau\in X^*\):
% \[
% U(\tau)<\Psi_{bat}(t(\tau))R(\tau)\le \Psi_{bat}(T)R(\tau),
% \]
% where \(T\) denotes the final epoch. Summing over all trajectories in \(X^*\):
% \[
% U(X^*)\le \Psi_{bat}(T)\sum_{\tau\in X^*}R(\tau).
% \]

% Since the total offline risk is at most \(\Delta_0\) and BAT-ORB spent exactly \(\Delta_0-\Delta_T\), the remaining risk satisfies:
% \[
% \sum_{\tau\in X^*}R(\tau)\le \Delta_0-(\Delta_0-\Delta_T)=\Delta_T
% \]

% Thus:
% \[
% U(X^*)\le \Psi_{bat}(T)\Delta_T=\frac{\Delta_0}{\Delta_T}L\,\Delta_T=\Delta_0L.
% \]

% \medskip
% \noindent\textbf{Step 4: Lower-Bound \(U(S)\).}\\
% For each \(\tau\in S\), clearly:
% \[
% U(\tau)\ge \Psi_{bat}(t(\tau))R(\tau)=\frac{\Delta_0}{\Delta_t}L\,R(\tau).
% \]

% Summing  over all selected trajectories:
% \[
% U(S)\ge L\,\Delta_0\sum_{\tau\in S}\frac{R(\tau)}{\Delta_0(1-z_t)}.
% \]

% This is a Riemann sum that rigorously lower-bounds the integral:
% \[
% U(S)\ge L\,\Delta_0\int_0^Z\frac{dz}{1-z}=L\,\Delta_0\ln\frac{1}{1-Z},
% \]
% where \(Z=1-\frac{\Delta_T}{\Delta_0}\). Thus, clearly:
% \[
% U(S)\ge L\,\Delta_0\ln\frac{\Delta_0}{\Delta_T}.
% \]

% \medskip
% \noindent\textbf{Step 5: Combine All Bounds.}\\
% Combining Steps 2–4, we have:
% \[
% U(S^*)=U(S\cap S^*)+U(X^*)+U(Y^*)
% \]
% \[
% U(S^*)\le U(S)+\Delta_0L+U(S)=2U(S)+\Delta_0L.
% \]

% Using the lower bound on \(U(S)\) from Step 4, carefully isolate \(\Delta_0L\):
% \[
% U(S)\ge L\Delta_0\ln\frac{\Delta_0}{\Delta_T}\quad\Longrightarrow\quad
% \Delta_0L\le\frac{U(S)}{\ln(\Delta_0/\Delta_T)}.
% \]

% Since the final budget satisfies \(\Delta_T\le\delta_{\min}\), we have:
% \[
% \ln\frac{\Delta_0}{\Delta_T}\ge \ln\frac{\Delta_0}{\delta_{\min}}\quad\Longrightarrow\quad
% \frac{1}{\ln(\Delta_0/\Delta_T)}\le\frac{1}{\ln(\Delta_0/\delta_{\min})}.
% \]

% Thus, clearly:
% \[
% \Delta_0L\le\frac{U(S)}{\ln(\Delta_0/\delta_{\min})}.
% \]

% Substitute carefully back into our inequality:
% \[
% U(S^*)\le 2U(S)+\frac{U(S)}{\ln(\Delta_0/\delta_{\min})}=U(S)\left(2+\frac{1}{\ln(\Delta_0/\delta_{\min})}\right).
% \]
% This inequality clearly demonstrates that BAT-ORB achieves a competitive ratio given explicitly by:
% \[
% \frac{U(S^*)}{U(S)} \leq 2 + \frac{1}{\ln(\Delta_0/\delta_{\min})}.
% \]

% To interpret this clearly:

% - For sufficiently large ratios \(\frac{\Delta_0}{\delta_{\min}}\), the term \(\frac{1}{\ln(\Delta_0/\delta_{\min})}\) becomes negligible, and the ratio asymptotically approaches 2 from above. Thus, BAT-ORB achieves a competitive ratio very close to 2 for large budget-to-risk-minimum ratios.

% This completes the proof.
% \end{proof}

% \subsection{Proof of ITM-ORB}

\section*{}
\bibliographystyle{ieeetr}
% sorted alphabetically, labeled with numbers (plain), alpha for letters
\bibliography{references} % names file bibliography.bib as my bibliography file

% \begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{Figures/abdulrahman.jpg}}]{Abdulrahman Ahmad} (Graduate Student Member, IEEE) received the B.Sc. degree (Hons.) in computer and systems engineering from Minia University, Minia, Egypt, in 2016,  and M.Sc in Electrical and Computer Engineering from Khalifa University of Science  and Technology, Abu Dhabi, UAE, in 2023. He is currently pursuing his Ph.D. in Computer Science at Khalifa University, with the KUCARS Autonomous Vehicles Lab.  He is also on a leave from Minia University, Minia, Egypt. His main research interests include intelligent transportation systems, risk-bounded motion planning, optimization, and machine learning.
% \end{IEEEbiography}















\end{document}


